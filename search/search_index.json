{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome \u00b6 KubeRay \u00b6 KubeRay is an open source toolkit to run Ray applications on Kubernetes. KubeRay provides several tools to simplify managing Ray clusters on Kubernetes. Ray Operator Backend services to create/delete cluster resources Kubectl plugin/CLI to operate CRD objects Native Job and Serving integration with Clusters Data Scientist centric workspace for fast prototyping (incubating) Kubernetes event dumper for ray clusters/pod/services (future work) Operator Integration with Kubernetes node problem detector (future work) Security \u00b6 If you discover a potential security issue in this project, or think you may have discovered a security issue, we ask that you notify KubeRay Security via our Slack Channel . Please do not create a public GitHub issue. License \u00b6 This project is licensed under the Apache-2.0 License . The Ray docs \u00b6 You can find even more information on deployments of Ray on Kubernetes at the official Ray docs .","title":"Welcome"},{"location":"#welcome","text":"","title":"Welcome"},{"location":"#kuberay","text":"KubeRay is an open source toolkit to run Ray applications on Kubernetes. KubeRay provides several tools to simplify managing Ray clusters on Kubernetes. Ray Operator Backend services to create/delete cluster resources Kubectl plugin/CLI to operate CRD objects Native Job and Serving integration with Clusters Data Scientist centric workspace for fast prototyping (incubating) Kubernetes event dumper for ray clusters/pod/services (future work) Operator Integration with Kubernetes node problem detector (future work)","title":"KubeRay"},{"location":"#security","text":"If you discover a potential security issue in this project, or think you may have discovered a security issue, we ask that you notify KubeRay Security via our Slack Channel . Please do not create a public GitHub issue.","title":"Security"},{"location":"#license","text":"This project is licensed under the Apache-2.0 License .","title":"License"},{"location":"#the-ray-docs","text":"You can find even more information on deployments of Ray on Kubernetes at the official Ray docs .","title":"The Ray docs"},{"location":"troubleshooting/","text":"Troubleshooting handbook \u00b6 Introduction \u00b6 This page will give you some guild on troubleshooting for some situations when you deploy and use the kuberay. Ray Version Compatibility \u00b6 Problem \u00b6 For every running ray cluster, when we try to connect with the client, we must be careful about the python and ray version we used. There are several issues report failures related to version imcompatibility: #148 , #21549 . Therefore there is a reminder for troubleshooting when come up with that situation. Error cases \u00b6 In the ray client initialization, there are several checks will be executed in ray-project/ray/util/client/__init__.py:L115-L137 . Common cases would be like: ... RuntimeError: Python minor versions differ between client and server: client is 3 .8.10, server is 3 .7.7 or: ... RuntimeError: Client Ray installation incompatible with server: client is 2021 -05-20, server is 2021 -12-07 Some cases may not be so clear: ConnectionAbortedError: Initialization failure from server: Traceback ( most recent call last ) : ... 'AttributeError: ''JobConfig'' object has no attribute ''_parsed_runtime_env' ' Traceback (most recent call last): ... RuntimeError: Version mismatch: The cluster was started with: Ray: 1.9.0 Python: 3.7.7 This process on node NODE_ADDRESS was started with: Ray: 1.10.0 Python: 3.7.7 Solution \u00b6 In above cases, you will need to check if the client ray version is compatible with the images version in the ray cluster's configuration. For example, when you deployed kuberay/ray-operator/config/samples/ray-cluster.mini.yaml , you need to be aware that spec.rayVersion and images version is the same with your expect ray release and same with your ray client version. NOTE: In ray code, the version check will only go through major and minor version, so the python and ray image's minor version match is enough. Also the ray upstream community provide different python version support from 3.6 to 3.9, you can choose the image to match your python version.","title":"Guidance"},{"location":"troubleshooting/#troubleshooting-handbook","text":"","title":"Troubleshooting handbook"},{"location":"troubleshooting/#introduction","text":"This page will give you some guild on troubleshooting for some situations when you deploy and use the kuberay.","title":"Introduction"},{"location":"troubleshooting/#ray-version-compatibility","text":"","title":"Ray Version Compatibility"},{"location":"troubleshooting/#problem","text":"For every running ray cluster, when we try to connect with the client, we must be careful about the python and ray version we used. There are several issues report failures related to version imcompatibility: #148 , #21549 . Therefore there is a reminder for troubleshooting when come up with that situation.","title":"Problem"},{"location":"troubleshooting/#error-cases","text":"In the ray client initialization, there are several checks will be executed in ray-project/ray/util/client/__init__.py:L115-L137 . Common cases would be like: ... RuntimeError: Python minor versions differ between client and server: client is 3 .8.10, server is 3 .7.7 or: ... RuntimeError: Client Ray installation incompatible with server: client is 2021 -05-20, server is 2021 -12-07 Some cases may not be so clear: ConnectionAbortedError: Initialization failure from server: Traceback ( most recent call last ) : ... 'AttributeError: ''JobConfig'' object has no attribute ''_parsed_runtime_env' ' Traceback (most recent call last): ... RuntimeError: Version mismatch: The cluster was started with: Ray: 1.9.0 Python: 3.7.7 This process on node NODE_ADDRESS was started with: Ray: 1.10.0 Python: 3.7.7","title":"Error cases"},{"location":"troubleshooting/#solution","text":"In above cases, you will need to check if the client ray version is compatible with the images version in the ray cluster's configuration. For example, when you deployed kuberay/ray-operator/config/samples/ray-cluster.mini.yaml , you need to be aware that spec.rayVersion and images version is the same with your expect ray release and same with your ray client version. NOTE: In ray code, the version check will only go through major and minor version, so the python and ray image's minor version match is enough. Also the ray upstream community provide different python version support from 3.6 to 3.9, you can choose the image to match your python version.","title":"Solution"},{"location":"best-practice/worker-head-reconnection/","text":"Explanation and Best Practice for workers-head Reconnection \u00b6 Problem \u00b6 For a RayCluster with a head and several workers, if a worker is crashed, it will be relaunched immediately and re-join the same cluster quickly; however, when the head is crashed, it will run into the issue #104 that all worker nodes are lost from the head for a long period of time. Explanation \u00b6 When the head pod was deleted, it will be recreated with a new IP by KubeRay controller\uff0cand the GCS server address is changed accordingly. The Raylets of all workers will try to get GCS address from Redis in ReconnectGcsServer , but the redis_clients always use the previous head IP, so they will always fail to get new GCS address. The Raylets will not exit until max retries are reached. There are two configurations determining this long delay: /// The interval at which the gcs rpc client will check if gcs rpc server is ready. RAY_CONFIG(int64_t, ping_gcs_rpc_server_interval_milliseconds, 1000) /// Maximum number of times to retry ping gcs rpc server when gcs server restarts. RAY_CONFIG(int32_t, ping_gcs_rpc_server_max_retries, 600) https://github.com/ray-project/ray/blob/98be9fb5e08befbd6cac3ffbcaa477c5117b0eef/src/ray/gcs/gcs_client/gcs_client.cc#L294-L295 It retries 600 times and each interval is 1s, resulting in total 600s timeout, i.e. 10 min. So immediately after 10-min wait for retries, each client exits and gets restarted while connecting to the new head IP. This issue exists in all stable ray versions (including 1.9.1). This has been reduced to 60s in recent commit in master. Best Practice \u00b6 The GCS Fault-Tolerance (FT) feature is alpha release. To enable GCS FT, please refer to Ray GCS Fault Tolerance To reduce the chances of a lost worker-head connection, there are two other options: Make head more stable: when creating the cluster, allocate sufficient amount of resources on head pod such that it tends to be stable and not easy to crash. You can also set {\"num-cpus\": \"0\"} in \"rayStartParams\" of \"headGroupSpec\" such that Ray scheduler will skip the head node when scheduling workloads. This also helps to maintain the stability of the head. Make reconnection shorter: for version <= 1.9.1, you can set this head param --system-config='{\"ping_gcs_rpc_server_max_retries\": 20}' to reduce the delay from 600s down to 20s before workers reconnect to the new head.","title":"Worker reconnection"},{"location":"best-practice/worker-head-reconnection/#explanation-and-best-practice-for-workers-head-reconnection","text":"","title":"Explanation and Best Practice for workers-head Reconnection"},{"location":"best-practice/worker-head-reconnection/#problem","text":"For a RayCluster with a head and several workers, if a worker is crashed, it will be relaunched immediately and re-join the same cluster quickly; however, when the head is crashed, it will run into the issue #104 that all worker nodes are lost from the head for a long period of time.","title":"Problem"},{"location":"best-practice/worker-head-reconnection/#explanation","text":"When the head pod was deleted, it will be recreated with a new IP by KubeRay controller\uff0cand the GCS server address is changed accordingly. The Raylets of all workers will try to get GCS address from Redis in ReconnectGcsServer , but the redis_clients always use the previous head IP, so they will always fail to get new GCS address. The Raylets will not exit until max retries are reached. There are two configurations determining this long delay: /// The interval at which the gcs rpc client will check if gcs rpc server is ready. RAY_CONFIG(int64_t, ping_gcs_rpc_server_interval_milliseconds, 1000) /// Maximum number of times to retry ping gcs rpc server when gcs server restarts. RAY_CONFIG(int32_t, ping_gcs_rpc_server_max_retries, 600) https://github.com/ray-project/ray/blob/98be9fb5e08befbd6cac3ffbcaa477c5117b0eef/src/ray/gcs/gcs_client/gcs_client.cc#L294-L295 It retries 600 times and each interval is 1s, resulting in total 600s timeout, i.e. 10 min. So immediately after 10-min wait for retries, each client exits and gets restarted while connecting to the new head IP. This issue exists in all stable ray versions (including 1.9.1). This has been reduced to 60s in recent commit in master.","title":"Explanation"},{"location":"best-practice/worker-head-reconnection/#best-practice","text":"The GCS Fault-Tolerance (FT) feature is alpha release. To enable GCS FT, please refer to Ray GCS Fault Tolerance To reduce the chances of a lost worker-head connection, there are two other options: Make head more stable: when creating the cluster, allocate sufficient amount of resources on head pod such that it tends to be stable and not easy to crash. You can also set {\"num-cpus\": \"0\"} in \"rayStartParams\" of \"headGroupSpec\" such that Ray scheduler will skip the head node when scheduling workloads. This also helps to maintain the stability of the head. Make reconnection shorter: for version <= 1.9.1, you can set this head param --system-config='{\"ping_gcs_rpc_server_max_retries\": 20}' to reduce the delay from 600s down to 20s before workers reconnect to the new head.","title":"Best Practice"},{"location":"components/apiserver/","text":"KubeRay APIServer \u00b6 The KubeRay APIServer provides gRPC and HTTP APIs to manage KubeRay resources. Note The KubeRay APIServer is an optional component. It provides a layer of simplified configuration for KubeRay resources. The KubeRay API server is used internally by some organizations to back user interfaces for KubeRay resource management. The KubeRay APIServer is community-managed and is not officially endorsed by the Ray maintainers. At this time, the only officially supported methods for managing KubeRay resources are - Direct management of KubeRay custom resources via kubectl, kustomize, and Kubernetes language clients. - Helm charts. KubeRay APIServer maintainer contacts (GitHub handles): @Jeffwan @scarlet25151 Usage \u00b6 You can install the KubeRay APIServer by using the helm chart or kustomize After the deployment we may use the {{baseUrl}} to access the (default) for nodeport access, we provide the default http port 31888 for connection and you can connect it using. for ingress access, you will need to create your own ingress The requests parameters detail can be seen in KubeRay swagger , here we only present some basic example: Setup end-to-end test \u00b6 (Optional) You may use your local kind cluster or minikube cat <<EOF | kind create cluster --name ray-test --config - kind: Cluster apiVersion: kind.x-k8s.io/v1alpha4 nodes: - role: control-plane kubeadmConfigPatches: - | kind: InitConfiguration nodeRegistration: kubeletExtraArgs: node-labels: \"ingress-ready=true\" extraPortMappings: - containerPort: 30379 hostPort: 6379 listenAddress: \"0.0.0.0\" protocol: tcp - containerPort: 30265 hostPort: 8265 listenAddress: \"0.0.0.0\" protocol: tcp - containerPort: 30001 hostPort: 10001 listenAddress: \"0.0.0.0\" protocol: tcp - containerPort: 8000 hostPort: 8000 listenAddress: \"0.0.0.0\" - containerPort: 31888 hostPort: 31888 listenAddress: \"0.0.0.0\" - role: worker - role: worker EOF Deploy the KubeRay APIServer within the same cluster of KubeRay operator helm -n ray-system install kuberay-apiserver kuberay/helm-chart/kuberay-apiserver The APIServer expose service using NodePort by default. You can test access by your host and port, the default port is set to 31888 . curl localhost:31888 {\"code\":5, \"message\":\"Not Found\"} You can create RayCluster , RayJobs or RayService by dialing the endpoints. The following is a simple example for creating the RayService object, follow swagger support to get the complete definitions of APIs. curl -X POST 'localhost:31888/apis/v1alpha2/namespaces/ray-system/compute_templates' \\ --header 'Content-Type: application/json' \\ --data '{ \"name\": \"default-template\", \"namespace\": \"ray-system\", \"cpu\": 2, \"memory\": 4 }' curl -X POST 'localhost:31888/apis/v1alpha2/namespaces/ray-system/services' \\ --header 'Content-Type: application/json' \\ --data '{ \"name\": \"user-test-1\", \"namespace\": \"ray-system\", \"user\": \"user\", \"serveDeploymentGraphSpec\": { \"importPath\": \"fruit.deployment_graph\", \"runtimeEnv\": \"working_dir: \\\"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\\\"\\n\", \"serveConfigs\": [ { \"deploymentName\": \"OrangeStand\", \"replicas\": 1, \"userConfig\": \"price: 2\", \"actorOptions\": { \"cpusPerActor\": 0.1 } }, { \"deploymentName\": \"PearStand\", \"replicas\": 1, \"userConfig\": \"price: 1\", \"actorOptions\": { \"cpusPerActor\": 0.1 } }, { \"deploymentName\": \"FruitMarket\", \"replicas\": 1, \"actorOptions\": { \"cpusPerActor\": 0.1 } },{ \"deploymentName\": \"DAGDriver\", \"replicas\": 1, \"routePrefix\": \"/\", \"actorOptions\": { \"cpusPerActor\": 0.1 } }] }, \"clusterSpec\": { \"headGroupSpec\": { \"computeTemplate\": \"default-template\", \"image\": \"rayproject/ray:2.1.0\", \"serviceType\": \"NodePort\", \"rayStartParams\": { \"dashboard-host\": \"0.0.0.0\", \"metrics-export-port\": \"8080\" }, \"volumes\": [] }, \"workerGroupSpec\": [ { \"groupName\": \"small-wg\", \"computeTemplate\": \"default-template\", \"image\": \"rayproject/ray:2.1.0\", \"replicas\": 1, \"minReplicas\": 0, \"maxReplicas\": 5, \"rayStartParams\": { \"node-ip-address\": \"$MY_POD_IP\" } } ] } }' The Ray resource will then be created in your Kubernetes cluster. Full definition of payload \u00b6 Compute Template \u00b6 For the purpose to simplify the setting of resource, we abstract the resource of the pods template resource to the compute template for usage, you can define the resource in the compute template and then choose the appropriate template for your head and workergroup when you are creating the real objects of RayCluster , RayJobs or RayService . Create compute templates in a given namespace \u00b6 POST {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/compute_templates { \"name\" : \"default-template\" , \"namespace\" : \"<namespace>\" , \"cpu\" : 2 , \"memory\" : 4 , \"gpu\" : 1 , \"gpuAccelerator\" : \"Tesla-V100\" } List all compute templates in a given namespace \u00b6 GET {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/compute_templates { \"compute_templates\" : [ { \"name\" : \"default-template\" , \"namespace\" : \"<namespace>\" , \"cpu\" : 2 , \"memory\" : 4 , \"gpu\" : 1 , \"gpu_accelerator\" : \"Tesla-V100\" } ] } List all compute templates in all namespaces \u00b6 GET {{baseUrl}}/apis/v1alpha2/compute_templates Get compute template by name \u00b6 GET {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/compute_templates/<compute_template_name> Delete compute template by name \u00b6 DELETE {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/compute_templates/<compute_template_name> Clusters \u00b6 Create cluster in a given namespace \u00b6 POST {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/clusters payload { \"name\" : \"test-cluster\" , \"namespace\" : \"<namespace>\" , \"user\" : \"jiaxin.shan\" , \"version\" : \"1.9.2\" , \"environment\" : \"DEV\" , \"clusterSpec\" : { \"headGroupSpec\" : { \"computeTemplate\" : \"head-template\" , \"image\" : \"ray.io/ray:1.9.2\" , \"serviceType\" : \"NodePort\" , \"rayStartParams\" : {} }, \"workerGroupSpec\" : [ { \"groupName\" : \"small-wg\" , \"computeTemplate\" : \"worker-template\" , \"image\" : \"ray.io/ray:1.9.2\" , \"replicas\" : 2 , \"minReplicas\" : 0 , \"maxReplicas\" : 5 , \"rayStartParams\" : {} } ] } } List all clusters in a given namespace \u00b6 GET {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/clusters { \"clusters\" : [ { \"name\" : \"test-cluster\" , \"namespace\" : \"<namespace>\" , \"user\" : \"jiaxin.shan\" , \"version\" : \"1.9.2\" , \"environment\" : \"DEV\" , \"cluster_spec\" : { \"head_group_spec\" : { \"compute_template\" : \"head-template\" , \"image\" : \"rayproject/ray:1.9.2\" , \"service_type\" : \"NodePort\" , \"ray_start_params\" : { \"dashboard-host\" : \"0.0.0.0\" , \"node-ip-address\" : \"$MY_POD_IP\" , \"port\" : \"6379\" } }, \"worker_group_spec\" : [ { \"group_name\" : \"small-wg\" , \"compute_template\" : \"worker-template\" , \"image\" : \"rayproject/ray:1.9.2\" , \"replicas\" : 2 , \"min_replicas\" : 0 , \"max_replicas\" : 5 , \"ray_start_params\" : { \"node-ip-address\" : \"$MY_POD_IP\" , } } ] }, \"created_at\" : \"2022-03-13T15:13:09Z\" , \"deleted_at\" : null }, ] } List all clusters in all namespaces \u00b6 GET {{baseUrl}}/apis/v1alpha2/clusters Get cluster by its name and namespace \u00b6 GET {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/clusters/<cluster_name> Delete cluster by its name and namespace \u00b6 DELETE {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/clusters/<cluster_name> RayJob \u00b6 Create ray job in a given namespace \u00b6 POST {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/jobs payload { \"name\" : \"string\" , \"namespace\" : \"string\" , \"user\" : \"string\" , \"entrypoint\" : \"string\" , \"metadata\" : { \"additionalProp1\" : \"string\" , \"additionalProp2\" : \"string\" , \"additionalProp3\" : \"string\" }, \"runtimeEnv\" : \"string\" , \"jobId\" : \"string\" , \"shutdownAfterJobFinishes\" : true , \"clusterSelector\" : { \"additionalProp1\" : \"string\" , \"additionalProp2\" : \"string\" , \"additionalProp3\" : \"string\" }, \"clusterSpec\" : { \"headGroupSpec\" : { \"computeTemplate\" : \"string\" , \"image\" : \"string\" , \"serviceType\" : \"string\" , \"rayStartParams\" : { \"additionalProp1\" : \"string\" , \"additionalProp2\" : \"string\" , \"additionalProp3\" : \"string\" }, \"volumes\" : [ { \"mountPath\" : \"string\" , \"volumeType\" : \"PERSISTENT_VOLUME_CLAIM\" , \"name\" : \"string\" , \"source\" : \"string\" , \"readOnly\" : true , \"hostPathType\" : \"DIRECTORY\" , \"mountPropagationMode\" : \"NONE\" } ] }, \"workerGroupSpec\" : [ { \"groupName\" : \"string\" , \"computeTemplate\" : \"string\" , \"image\" : \"string\" , \"replicas\" : 0 , \"minReplicas\" : 0 , \"maxReplicas\" : 0 , \"rayStartParams\" : { \"additionalProp1\" : \"string\" , \"additionalProp2\" : \"string\" , \"additionalProp3\" : \"string\" }, \"volumes\" : [ { \"mountPath\" : \"string\" , \"volumeType\" : \"PERSISTENT_VOLUME_CLAIM\" , \"name\" : \"string\" , \"source\" : \"string\" , \"readOnly\" : true , \"hostPathType\" : \"DIRECTORY\" , \"mountPropagationMode\" : \"NONE\" } ] } ] }, \"ttlSecondsAfterFinished\" : 0 , \"createdAt\" : \"2022-08-19T21:20:30.494Z\" , \"deleteAt\" : \"2022-08-19T21:20:30.494Z\" , \"jobStatus\" : \"string\" , \"jobDeploymentStatus\" : \"string\" , \"message\" : \"string\" } List all jobs in a given namespace \u00b6 GET {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/jobs Response { \"jobs\" : [ { \"name\" : \"string\" , \"namespace\" : \"string\" , \"user\" : \"string\" , \"entrypoint\" : \"string\" , \"metadata\" : { \"additionalProp1\" : \"string\" , \"additionalProp2\" : \"string\" , \"additionalProp3\" : \"string\" }, \"runtimeEnv\" : \"string\" , \"jobId\" : \"string\" , \"shutdownAfterJobFinishes\" : true , \"clusterSelector\" : { \"additionalProp1\" : \"string\" , \"additionalProp2\" : \"string\" , \"additionalProp3\" : \"string\" }, \"clusterSpec\" : { \"headGroupSpec\" : { \"computeTemplate\" : \"string\" , \"image\" : \"string\" , \"serviceType\" : \"string\" , \"rayStartParams\" : { \"additionalProp1\" : \"string\" , \"additionalProp2\" : \"string\" , \"additionalProp3\" : \"string\" }, \"volumes\" : [ { \"mountPath\" : \"string\" , \"volumeType\" : \"PERSISTENT_VOLUME_CLAIM\" , \"name\" : \"string\" , \"source\" : \"string\" , \"readOnly\" : true , \"hostPathType\" : \"DIRECTORY\" , \"mountPropagationMode\" : \"NONE\" } ] }, \"workerGroupSpec\" : [ { \"groupName\" : \"string\" , \"computeTemplate\" : \"string\" , \"image\" : \"string\" , \"replicas\" : 0 , \"minReplicas\" : 0 , \"maxReplicas\" : 0 , \"rayStartParams\" : { \"additionalProp1\" : \"string\" , \"additionalProp2\" : \"string\" , \"additionalProp3\" : \"string\" }, \"volumes\" : [ { \"mountPath\" : \"string\" , \"volumeType\" : \"PERSISTENT_VOLUME_CLAIM\" , \"name\" : \"string\" , \"source\" : \"string\" , \"readOnly\" : true , \"hostPathType\" : \"DIRECTORY\" , \"mountPropagationMode\" : \"NONE\" } ] } ] }, \"ttlSecondsAfterFinished\" : 0 , \"createdAt\" : \"2022-08-19T21:31:24.352Z\" , \"deleteAt\" : \"2022-08-19T21:31:24.352Z\" , \"jobStatus\" : \"string\" , \"jobDeploymentStatus\" : \"string\" , \"message\" : \"string\" } ] } List all jobs in all namespaces \u00b6 GET {{baseUrl}}/apis/v1alpha2/jobs Get job by its name and namespace \u00b6 GET {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/jobs/<job_name> Delete job by its name and namespace \u00b6 DELETE {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/jobs/<job_name> RayService \u00b6 Create ray service in a given namespace \u00b6 POST {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/services payload { \"name\" : \"string\" , \"namespace\" : \"string\" , \"user\" : \"string\" , \"serveDeploymentGraphSpec\" : { \"importPath\" : \"string\" , \"runtimeEnv\" : \"string\" , \"serveConfigs\" : [ { \"deploymentName\" : \"string\" , \"replicas\" : 0 , \"routePrefix\" : \"string\" , \"maxConcurrentQueries\" : 0 , \"userConfig\" : \"string\" , \"autoscalingConfig\" : \"string\" , \"actorOptions\" : { \"runtimeEnv\" : \"string\" , \"cpus\" : 0 , \"gpu\" : 0 , \"memory\" : 0 , \"objectStoreMemory\" : 0 , \"resource\" : \"string\" , \"accceleratorType\" : \"string\" } } ] }, \"clusterSpec\" : { \"headGroupSpec\" : { \"computeTemplate\" : \"string\" , \"image\" : \"string\" , \"serviceType\" : \"string\" , \"rayStartParams\" : { \"additionalProp1\" : \"string\" , \"additionalProp2\" : \"string\" , \"additionalProp3\" : \"string\" }, \"volumes\" : [ { \"mountPath\" : \"string\" , \"volumeType\" : \"PERSISTENT_VOLUME_CLAIM\" , \"name\" : \"string\" , \"source\" : \"string\" , \"readOnly\" : true , \"hostPathType\" : \"DIRECTORY\" , \"mountPropagationMode\" : \"NONE\" } ] }, \"workerGroupSpec\" : [ { \"groupName\" : \"string\" , \"computeTemplate\" : \"string\" , \"image\" : \"string\" , \"replicas\" : 0 , \"minReplicas\" : 0 , \"maxReplicas\" : 0 , \"rayStartParams\" : { \"additionalProp1\" : \"string\" , \"additionalProp2\" : \"string\" , \"additionalProp3\" : \"string\" }, \"volumes\" : [ { \"mountPath\" : \"string\" , \"volumeType\" : \"PERSISTENT_VOLUME_CLAIM\" , \"name\" : \"string\" , \"source\" : \"string\" , \"readOnly\" : true , \"hostPathType\" : \"DIRECTORY\" , \"mountPropagationMode\" : \"NONE\" } ] } ] }, \"rayServiceStatus\" : { \"applicationStatus\" : \"string\" , \"applicationMessage\" : \"string\" , \"serveDeploymentStatus\" : [ { \"deploymentName\" : \"string\" , \"status\" : \"string\" , \"message\" : \"string\" } ], \"rayServiceEvent\" : [ { \"id\" : \"string\" , \"name\" : \"string\" , \"createdAt\" : \"2022-08-19T21:30:01.097Z\" , \"firstTimestamp\" : \"2022-08-19T21:30:01.097Z\" , \"lastTimestamp\" : \"2022-08-19T21:30:01.097Z\" , \"reason\" : \"string\" , \"message\" : \"string\" , \"type\" : \"string\" , \"count\" : 0 } ], \"rayClusterName\" : \"string\" , \"rayClusterState\" : \"string\" , \"serviceEndpoint\" : { \"additionalProp1\" : \"string\" , \"additionalProp2\" : \"string\" , \"additionalProp3\" : \"string\" } }, \"createdAt\" : \"2022-08-19T21:30:01.097Z\" , \"deleteAt\" : \"2022-08-19T21:30:01.097Z\" } List all services in a given namespace \u00b6 GET {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/services Response \"name\" : \"string\" , \"namespace\" : \"string\" , \"user\" : \"string\" , \"serveDeploymentGraphSpec\" : { \"importPath\" : \"string\" , \"runtimeEnv\" : \"string\" , \"serveConfigs\" : [ { \"deploymentName\" : \"string\" , \"replicas\" : 0 , \"routePrefix\" : \"string\" , \"maxConcurrentQueries\" : 0 , \"userConfig\" : \"string\" , \"autoscalingConfig\" : \"string\" , \"actorOptions\" : { \"runtimeEnv\" : \"string\" , \"cpus\" : 0 , \"gpu\" : 0 , \"memory\" : 0 , \"objectStoreMemory\" : 0 , \"resource\" : \"string\" , \"accceleratorType\" : \"string\" } } ] }, \"clusterSpec\" : { \"headGroupSpec\" : { \"computeTemplate\" : \"string\" , \"image\" : \"string\" , \"serviceType\" : \"string\" , \"rayStartParams\" : { \"additionalProp1\" : \"string\" , \"additionalProp2\" : \"string\" , \"additionalProp3\" : \"string\" }, \"volumes\" : [ { \"mountPath\" : \"string\" , \"volumeType\" : \"PERSISTENT_VOLUME_CLAIM\" , \"name\" : \"string\" , \"source\" : \"string\" , \"readOnly\" : true , \"hostPathType\" : \"DIRECTORY\" , \"mountPropagationMode\" : \"NONE\" } ] }, \"workerGroupSpec\" : [ { \"groupName\" : \"string\" , \"computeTemplate\" : \"string\" , \"image\" : \"string\" , \"replicas\" : 0 , \"minReplicas\" : 0 , \"maxReplicas\" : 0 , \"rayStartParams\" : { \"additionalProp1\" : \"string\" , \"additionalProp2\" : \"string\" , \"additionalProp3\" : \"string\" }, \"volumes\" : [ { \"mountPath\" : \"string\" , \"volumeType\" : \"PERSISTENT_VOLUME_CLAIM\" , \"name\" : \"string\" , \"source\" : \"string\" , \"readOnly\" : true , \"hostPathType\" : \"DIRECTORY\" , \"mountPropagationMode\" : \"NONE\" } ] } ] }, \"rayServiceStatus\" : { \"applicationStatus\" : \"string\" , \"applicationMessage\" : \"string\" , \"serveDeploymentStatus\" : [ { \"deploymentName\" : \"string\" , \"status\" : \"string\" , \"message\" : \"string\" } ], \"rayServiceEvent\" : [ { \"id\" : \"string\" , \"name\" : \"string\" , \"createdAt\" : \"2022-08-19T21:33:15.485Z\" , \"firstTimestamp\" : \"2022-08-19T21:33:15.485Z\" , \"lastTimestamp\" : \"2022-08-19T21:33:15.485Z\" , \"reason\" : \"string\" , \"message\" : \"string\" , \"type\" : \"string\" , \"count\" : 0 } ], \"rayClusterName\" : \"string\" , \"rayClusterState\" : \"string\" , \"serviceEndpoint\" : { \"additionalProp1\" : \"string\" , \"additionalProp2\" : \"string\" , \"additionalProp3\" : \"string\" } }, \"createdAt\" : \"2022-08-19T21:33:15.485Z\" , \"deleteAt\" : \"2022-08-19T21:33:15.485Z\" } List all services in all namespaces \u00b6 GET {{baseUrl}}/apis/v1alpha2/services Get service by its name and namespace \u00b6 GET {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/services/<service_name> Delete service by its name and namespace \u00b6 DELETE {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/services/<service_name> Swagger Support \u00b6 Download Swagger UI from Swagger-UI . In this case, we use swagger-ui-3.51.2.tar.gz Unzip package and copy dist folder to third_party folder Use go-bindata to generate go code from static files. mkdir third_party tar -zvxf ~/Downloads/swagger-ui-3.51.2.tar.gz /tmp mv /tmp/swagger-ui-3.51.2/dist third_party/swagger-ui cd apiserver/ go-bindata --nocompress --pkg swagger -o pkg/swagger/datafile.go ./third_party/swagger-ui/...","title":"KubeRay ApiServer"},{"location":"components/apiserver/#kuberay-apiserver","text":"The KubeRay APIServer provides gRPC and HTTP APIs to manage KubeRay resources. Note The KubeRay APIServer is an optional component. It provides a layer of simplified configuration for KubeRay resources. The KubeRay API server is used internally by some organizations to back user interfaces for KubeRay resource management. The KubeRay APIServer is community-managed and is not officially endorsed by the Ray maintainers. At this time, the only officially supported methods for managing KubeRay resources are - Direct management of KubeRay custom resources via kubectl, kustomize, and Kubernetes language clients. - Helm charts. KubeRay APIServer maintainer contacts (GitHub handles): @Jeffwan @scarlet25151","title":"KubeRay APIServer"},{"location":"components/apiserver/#usage","text":"You can install the KubeRay APIServer by using the helm chart or kustomize After the deployment we may use the {{baseUrl}} to access the (default) for nodeport access, we provide the default http port 31888 for connection and you can connect it using. for ingress access, you will need to create your own ingress The requests parameters detail can be seen in KubeRay swagger , here we only present some basic example:","title":"Usage"},{"location":"components/apiserver/#setup-end-to-end-test","text":"(Optional) You may use your local kind cluster or minikube cat <<EOF | kind create cluster --name ray-test --config - kind: Cluster apiVersion: kind.x-k8s.io/v1alpha4 nodes: - role: control-plane kubeadmConfigPatches: - | kind: InitConfiguration nodeRegistration: kubeletExtraArgs: node-labels: \"ingress-ready=true\" extraPortMappings: - containerPort: 30379 hostPort: 6379 listenAddress: \"0.0.0.0\" protocol: tcp - containerPort: 30265 hostPort: 8265 listenAddress: \"0.0.0.0\" protocol: tcp - containerPort: 30001 hostPort: 10001 listenAddress: \"0.0.0.0\" protocol: tcp - containerPort: 8000 hostPort: 8000 listenAddress: \"0.0.0.0\" - containerPort: 31888 hostPort: 31888 listenAddress: \"0.0.0.0\" - role: worker - role: worker EOF Deploy the KubeRay APIServer within the same cluster of KubeRay operator helm -n ray-system install kuberay-apiserver kuberay/helm-chart/kuberay-apiserver The APIServer expose service using NodePort by default. You can test access by your host and port, the default port is set to 31888 . curl localhost:31888 {\"code\":5, \"message\":\"Not Found\"} You can create RayCluster , RayJobs or RayService by dialing the endpoints. The following is a simple example for creating the RayService object, follow swagger support to get the complete definitions of APIs. curl -X POST 'localhost:31888/apis/v1alpha2/namespaces/ray-system/compute_templates' \\ --header 'Content-Type: application/json' \\ --data '{ \"name\": \"default-template\", \"namespace\": \"ray-system\", \"cpu\": 2, \"memory\": 4 }' curl -X POST 'localhost:31888/apis/v1alpha2/namespaces/ray-system/services' \\ --header 'Content-Type: application/json' \\ --data '{ \"name\": \"user-test-1\", \"namespace\": \"ray-system\", \"user\": \"user\", \"serveDeploymentGraphSpec\": { \"importPath\": \"fruit.deployment_graph\", \"runtimeEnv\": \"working_dir: \\\"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\\\"\\n\", \"serveConfigs\": [ { \"deploymentName\": \"OrangeStand\", \"replicas\": 1, \"userConfig\": \"price: 2\", \"actorOptions\": { \"cpusPerActor\": 0.1 } }, { \"deploymentName\": \"PearStand\", \"replicas\": 1, \"userConfig\": \"price: 1\", \"actorOptions\": { \"cpusPerActor\": 0.1 } }, { \"deploymentName\": \"FruitMarket\", \"replicas\": 1, \"actorOptions\": { \"cpusPerActor\": 0.1 } },{ \"deploymentName\": \"DAGDriver\", \"replicas\": 1, \"routePrefix\": \"/\", \"actorOptions\": { \"cpusPerActor\": 0.1 } }] }, \"clusterSpec\": { \"headGroupSpec\": { \"computeTemplate\": \"default-template\", \"image\": \"rayproject/ray:2.1.0\", \"serviceType\": \"NodePort\", \"rayStartParams\": { \"dashboard-host\": \"0.0.0.0\", \"metrics-export-port\": \"8080\" }, \"volumes\": [] }, \"workerGroupSpec\": [ { \"groupName\": \"small-wg\", \"computeTemplate\": \"default-template\", \"image\": \"rayproject/ray:2.1.0\", \"replicas\": 1, \"minReplicas\": 0, \"maxReplicas\": 5, \"rayStartParams\": { \"node-ip-address\": \"$MY_POD_IP\" } } ] } }' The Ray resource will then be created in your Kubernetes cluster.","title":"Setup end-to-end test"},{"location":"components/apiserver/#full-definition-of-payload","text":"","title":"Full definition of payload"},{"location":"components/apiserver/#compute-template","text":"For the purpose to simplify the setting of resource, we abstract the resource of the pods template resource to the compute template for usage, you can define the resource in the compute template and then choose the appropriate template for your head and workergroup when you are creating the real objects of RayCluster , RayJobs or RayService .","title":"Compute Template"},{"location":"components/apiserver/#create-compute-templates-in-a-given-namespace","text":"POST {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/compute_templates { \"name\" : \"default-template\" , \"namespace\" : \"<namespace>\" , \"cpu\" : 2 , \"memory\" : 4 , \"gpu\" : 1 , \"gpuAccelerator\" : \"Tesla-V100\" }","title":"Create compute templates in a given namespace"},{"location":"components/apiserver/#list-all-compute-templates-in-a-given-namespace","text":"GET {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/compute_templates { \"compute_templates\" : [ { \"name\" : \"default-template\" , \"namespace\" : \"<namespace>\" , \"cpu\" : 2 , \"memory\" : 4 , \"gpu\" : 1 , \"gpu_accelerator\" : \"Tesla-V100\" } ] }","title":"List all compute templates in a given namespace"},{"location":"components/apiserver/#list-all-compute-templates-in-all-namespaces","text":"GET {{baseUrl}}/apis/v1alpha2/compute_templates","title":"List all compute templates in all namespaces"},{"location":"components/apiserver/#get-compute-template-by-name","text":"GET {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/compute_templates/<compute_template_name>","title":"Get compute template by name"},{"location":"components/apiserver/#delete-compute-template-by-name","text":"DELETE {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/compute_templates/<compute_template_name>","title":"Delete compute template by name"},{"location":"components/apiserver/#clusters","text":"","title":"Clusters"},{"location":"components/apiserver/#create-cluster-in-a-given-namespace","text":"POST {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/clusters payload { \"name\" : \"test-cluster\" , \"namespace\" : \"<namespace>\" , \"user\" : \"jiaxin.shan\" , \"version\" : \"1.9.2\" , \"environment\" : \"DEV\" , \"clusterSpec\" : { \"headGroupSpec\" : { \"computeTemplate\" : \"head-template\" , \"image\" : \"ray.io/ray:1.9.2\" , \"serviceType\" : \"NodePort\" , \"rayStartParams\" : {} }, \"workerGroupSpec\" : [ { \"groupName\" : \"small-wg\" , \"computeTemplate\" : \"worker-template\" , \"image\" : \"ray.io/ray:1.9.2\" , \"replicas\" : 2 , \"minReplicas\" : 0 , \"maxReplicas\" : 5 , \"rayStartParams\" : {} } ] } }","title":"Create cluster in a given namespace"},{"location":"components/apiserver/#list-all-clusters-in-a-given-namespace","text":"GET {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/clusters { \"clusters\" : [ { \"name\" : \"test-cluster\" , \"namespace\" : \"<namespace>\" , \"user\" : \"jiaxin.shan\" , \"version\" : \"1.9.2\" , \"environment\" : \"DEV\" , \"cluster_spec\" : { \"head_group_spec\" : { \"compute_template\" : \"head-template\" , \"image\" : \"rayproject/ray:1.9.2\" , \"service_type\" : \"NodePort\" , \"ray_start_params\" : { \"dashboard-host\" : \"0.0.0.0\" , \"node-ip-address\" : \"$MY_POD_IP\" , \"port\" : \"6379\" } }, \"worker_group_spec\" : [ { \"group_name\" : \"small-wg\" , \"compute_template\" : \"worker-template\" , \"image\" : \"rayproject/ray:1.9.2\" , \"replicas\" : 2 , \"min_replicas\" : 0 , \"max_replicas\" : 5 , \"ray_start_params\" : { \"node-ip-address\" : \"$MY_POD_IP\" , } } ] }, \"created_at\" : \"2022-03-13T15:13:09Z\" , \"deleted_at\" : null }, ] }","title":"List all clusters in a given namespace"},{"location":"components/apiserver/#list-all-clusters-in-all-namespaces","text":"GET {{baseUrl}}/apis/v1alpha2/clusters","title":"List all clusters in all namespaces"},{"location":"components/apiserver/#get-cluster-by-its-name-and-namespace","text":"GET {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/clusters/<cluster_name>","title":"Get cluster by its name and namespace"},{"location":"components/apiserver/#delete-cluster-by-its-name-and-namespace","text":"DELETE {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/clusters/<cluster_name>","title":"Delete cluster by its name and namespace"},{"location":"components/apiserver/#rayjob","text":"","title":"RayJob"},{"location":"components/apiserver/#create-ray-job-in-a-given-namespace","text":"POST {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/jobs payload { \"name\" : \"string\" , \"namespace\" : \"string\" , \"user\" : \"string\" , \"entrypoint\" : \"string\" , \"metadata\" : { \"additionalProp1\" : \"string\" , \"additionalProp2\" : \"string\" , \"additionalProp3\" : \"string\" }, \"runtimeEnv\" : \"string\" , \"jobId\" : \"string\" , \"shutdownAfterJobFinishes\" : true , \"clusterSelector\" : { \"additionalProp1\" : \"string\" , \"additionalProp2\" : \"string\" , \"additionalProp3\" : \"string\" }, \"clusterSpec\" : { \"headGroupSpec\" : { \"computeTemplate\" : \"string\" , \"image\" : \"string\" , \"serviceType\" : \"string\" , \"rayStartParams\" : { \"additionalProp1\" : \"string\" , \"additionalProp2\" : \"string\" , \"additionalProp3\" : \"string\" }, \"volumes\" : [ { \"mountPath\" : \"string\" , \"volumeType\" : \"PERSISTENT_VOLUME_CLAIM\" , \"name\" : \"string\" , \"source\" : \"string\" , \"readOnly\" : true , \"hostPathType\" : \"DIRECTORY\" , \"mountPropagationMode\" : \"NONE\" } ] }, \"workerGroupSpec\" : [ { \"groupName\" : \"string\" , \"computeTemplate\" : \"string\" , \"image\" : \"string\" , \"replicas\" : 0 , \"minReplicas\" : 0 , \"maxReplicas\" : 0 , \"rayStartParams\" : { \"additionalProp1\" : \"string\" , \"additionalProp2\" : \"string\" , \"additionalProp3\" : \"string\" }, \"volumes\" : [ { \"mountPath\" : \"string\" , \"volumeType\" : \"PERSISTENT_VOLUME_CLAIM\" , \"name\" : \"string\" , \"source\" : \"string\" , \"readOnly\" : true , \"hostPathType\" : \"DIRECTORY\" , \"mountPropagationMode\" : \"NONE\" } ] } ] }, \"ttlSecondsAfterFinished\" : 0 , \"createdAt\" : \"2022-08-19T21:20:30.494Z\" , \"deleteAt\" : \"2022-08-19T21:20:30.494Z\" , \"jobStatus\" : \"string\" , \"jobDeploymentStatus\" : \"string\" , \"message\" : \"string\" }","title":"Create ray job in a given namespace"},{"location":"components/apiserver/#list-all-jobs-in-a-given-namespace","text":"GET {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/jobs Response { \"jobs\" : [ { \"name\" : \"string\" , \"namespace\" : \"string\" , \"user\" : \"string\" , \"entrypoint\" : \"string\" , \"metadata\" : { \"additionalProp1\" : \"string\" , \"additionalProp2\" : \"string\" , \"additionalProp3\" : \"string\" }, \"runtimeEnv\" : \"string\" , \"jobId\" : \"string\" , \"shutdownAfterJobFinishes\" : true , \"clusterSelector\" : { \"additionalProp1\" : \"string\" , \"additionalProp2\" : \"string\" , \"additionalProp3\" : \"string\" }, \"clusterSpec\" : { \"headGroupSpec\" : { \"computeTemplate\" : \"string\" , \"image\" : \"string\" , \"serviceType\" : \"string\" , \"rayStartParams\" : { \"additionalProp1\" : \"string\" , \"additionalProp2\" : \"string\" , \"additionalProp3\" : \"string\" }, \"volumes\" : [ { \"mountPath\" : \"string\" , \"volumeType\" : \"PERSISTENT_VOLUME_CLAIM\" , \"name\" : \"string\" , \"source\" : \"string\" , \"readOnly\" : true , \"hostPathType\" : \"DIRECTORY\" , \"mountPropagationMode\" : \"NONE\" } ] }, \"workerGroupSpec\" : [ { \"groupName\" : \"string\" , \"computeTemplate\" : \"string\" , \"image\" : \"string\" , \"replicas\" : 0 , \"minReplicas\" : 0 , \"maxReplicas\" : 0 , \"rayStartParams\" : { \"additionalProp1\" : \"string\" , \"additionalProp2\" : \"string\" , \"additionalProp3\" : \"string\" }, \"volumes\" : [ { \"mountPath\" : \"string\" , \"volumeType\" : \"PERSISTENT_VOLUME_CLAIM\" , \"name\" : \"string\" , \"source\" : \"string\" , \"readOnly\" : true , \"hostPathType\" : \"DIRECTORY\" , \"mountPropagationMode\" : \"NONE\" } ] } ] }, \"ttlSecondsAfterFinished\" : 0 , \"createdAt\" : \"2022-08-19T21:31:24.352Z\" , \"deleteAt\" : \"2022-08-19T21:31:24.352Z\" , \"jobStatus\" : \"string\" , \"jobDeploymentStatus\" : \"string\" , \"message\" : \"string\" } ] }","title":"List all jobs in a given namespace"},{"location":"components/apiserver/#list-all-jobs-in-all-namespaces","text":"GET {{baseUrl}}/apis/v1alpha2/jobs","title":"List all jobs in all namespaces"},{"location":"components/apiserver/#get-job-by-its-name-and-namespace","text":"GET {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/jobs/<job_name>","title":"Get job by its name and namespace"},{"location":"components/apiserver/#delete-job-by-its-name-and-namespace","text":"DELETE {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/jobs/<job_name>","title":"Delete job by its name and namespace"},{"location":"components/apiserver/#rayservice","text":"","title":"RayService"},{"location":"components/apiserver/#create-ray-service-in-a-given-namespace","text":"POST {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/services payload { \"name\" : \"string\" , \"namespace\" : \"string\" , \"user\" : \"string\" , \"serveDeploymentGraphSpec\" : { \"importPath\" : \"string\" , \"runtimeEnv\" : \"string\" , \"serveConfigs\" : [ { \"deploymentName\" : \"string\" , \"replicas\" : 0 , \"routePrefix\" : \"string\" , \"maxConcurrentQueries\" : 0 , \"userConfig\" : \"string\" , \"autoscalingConfig\" : \"string\" , \"actorOptions\" : { \"runtimeEnv\" : \"string\" , \"cpus\" : 0 , \"gpu\" : 0 , \"memory\" : 0 , \"objectStoreMemory\" : 0 , \"resource\" : \"string\" , \"accceleratorType\" : \"string\" } } ] }, \"clusterSpec\" : { \"headGroupSpec\" : { \"computeTemplate\" : \"string\" , \"image\" : \"string\" , \"serviceType\" : \"string\" , \"rayStartParams\" : { \"additionalProp1\" : \"string\" , \"additionalProp2\" : \"string\" , \"additionalProp3\" : \"string\" }, \"volumes\" : [ { \"mountPath\" : \"string\" , \"volumeType\" : \"PERSISTENT_VOLUME_CLAIM\" , \"name\" : \"string\" , \"source\" : \"string\" , \"readOnly\" : true , \"hostPathType\" : \"DIRECTORY\" , \"mountPropagationMode\" : \"NONE\" } ] }, \"workerGroupSpec\" : [ { \"groupName\" : \"string\" , \"computeTemplate\" : \"string\" , \"image\" : \"string\" , \"replicas\" : 0 , \"minReplicas\" : 0 , \"maxReplicas\" : 0 , \"rayStartParams\" : { \"additionalProp1\" : \"string\" , \"additionalProp2\" : \"string\" , \"additionalProp3\" : \"string\" }, \"volumes\" : [ { \"mountPath\" : \"string\" , \"volumeType\" : \"PERSISTENT_VOLUME_CLAIM\" , \"name\" : \"string\" , \"source\" : \"string\" , \"readOnly\" : true , \"hostPathType\" : \"DIRECTORY\" , \"mountPropagationMode\" : \"NONE\" } ] } ] }, \"rayServiceStatus\" : { \"applicationStatus\" : \"string\" , \"applicationMessage\" : \"string\" , \"serveDeploymentStatus\" : [ { \"deploymentName\" : \"string\" , \"status\" : \"string\" , \"message\" : \"string\" } ], \"rayServiceEvent\" : [ { \"id\" : \"string\" , \"name\" : \"string\" , \"createdAt\" : \"2022-08-19T21:30:01.097Z\" , \"firstTimestamp\" : \"2022-08-19T21:30:01.097Z\" , \"lastTimestamp\" : \"2022-08-19T21:30:01.097Z\" , \"reason\" : \"string\" , \"message\" : \"string\" , \"type\" : \"string\" , \"count\" : 0 } ], \"rayClusterName\" : \"string\" , \"rayClusterState\" : \"string\" , \"serviceEndpoint\" : { \"additionalProp1\" : \"string\" , \"additionalProp2\" : \"string\" , \"additionalProp3\" : \"string\" } }, \"createdAt\" : \"2022-08-19T21:30:01.097Z\" , \"deleteAt\" : \"2022-08-19T21:30:01.097Z\" }","title":"Create ray service in a given namespace"},{"location":"components/apiserver/#list-all-services-in-a-given-namespace","text":"GET {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/services Response \"name\" : \"string\" , \"namespace\" : \"string\" , \"user\" : \"string\" , \"serveDeploymentGraphSpec\" : { \"importPath\" : \"string\" , \"runtimeEnv\" : \"string\" , \"serveConfigs\" : [ { \"deploymentName\" : \"string\" , \"replicas\" : 0 , \"routePrefix\" : \"string\" , \"maxConcurrentQueries\" : 0 , \"userConfig\" : \"string\" , \"autoscalingConfig\" : \"string\" , \"actorOptions\" : { \"runtimeEnv\" : \"string\" , \"cpus\" : 0 , \"gpu\" : 0 , \"memory\" : 0 , \"objectStoreMemory\" : 0 , \"resource\" : \"string\" , \"accceleratorType\" : \"string\" } } ] }, \"clusterSpec\" : { \"headGroupSpec\" : { \"computeTemplate\" : \"string\" , \"image\" : \"string\" , \"serviceType\" : \"string\" , \"rayStartParams\" : { \"additionalProp1\" : \"string\" , \"additionalProp2\" : \"string\" , \"additionalProp3\" : \"string\" }, \"volumes\" : [ { \"mountPath\" : \"string\" , \"volumeType\" : \"PERSISTENT_VOLUME_CLAIM\" , \"name\" : \"string\" , \"source\" : \"string\" , \"readOnly\" : true , \"hostPathType\" : \"DIRECTORY\" , \"mountPropagationMode\" : \"NONE\" } ] }, \"workerGroupSpec\" : [ { \"groupName\" : \"string\" , \"computeTemplate\" : \"string\" , \"image\" : \"string\" , \"replicas\" : 0 , \"minReplicas\" : 0 , \"maxReplicas\" : 0 , \"rayStartParams\" : { \"additionalProp1\" : \"string\" , \"additionalProp2\" : \"string\" , \"additionalProp3\" : \"string\" }, \"volumes\" : [ { \"mountPath\" : \"string\" , \"volumeType\" : \"PERSISTENT_VOLUME_CLAIM\" , \"name\" : \"string\" , \"source\" : \"string\" , \"readOnly\" : true , \"hostPathType\" : \"DIRECTORY\" , \"mountPropagationMode\" : \"NONE\" } ] } ] }, \"rayServiceStatus\" : { \"applicationStatus\" : \"string\" , \"applicationMessage\" : \"string\" , \"serveDeploymentStatus\" : [ { \"deploymentName\" : \"string\" , \"status\" : \"string\" , \"message\" : \"string\" } ], \"rayServiceEvent\" : [ { \"id\" : \"string\" , \"name\" : \"string\" , \"createdAt\" : \"2022-08-19T21:33:15.485Z\" , \"firstTimestamp\" : \"2022-08-19T21:33:15.485Z\" , \"lastTimestamp\" : \"2022-08-19T21:33:15.485Z\" , \"reason\" : \"string\" , \"message\" : \"string\" , \"type\" : \"string\" , \"count\" : 0 } ], \"rayClusterName\" : \"string\" , \"rayClusterState\" : \"string\" , \"serviceEndpoint\" : { \"additionalProp1\" : \"string\" , \"additionalProp2\" : \"string\" , \"additionalProp3\" : \"string\" } }, \"createdAt\" : \"2022-08-19T21:33:15.485Z\" , \"deleteAt\" : \"2022-08-19T21:33:15.485Z\" }","title":"List all services in a given namespace"},{"location":"components/apiserver/#list-all-services-in-all-namespaces","text":"GET {{baseUrl}}/apis/v1alpha2/services","title":"List all services in all namespaces"},{"location":"components/apiserver/#get-service-by-its-name-and-namespace","text":"GET {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/services/<service_name>","title":"Get service by its name and namespace"},{"location":"components/apiserver/#delete-service-by-its-name-and-namespace","text":"DELETE {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/services/<service_name>","title":"Delete service by its name and namespace"},{"location":"components/apiserver/#swagger-support","text":"Download Swagger UI from Swagger-UI . In this case, we use swagger-ui-3.51.2.tar.gz Unzip package and copy dist folder to third_party folder Use go-bindata to generate go code from static files. mkdir third_party tar -zvxf ~/Downloads/swagger-ui-3.51.2.tar.gz /tmp mv /tmp/swagger-ui-3.51.2/dist third_party/swagger-ui cd apiserver/ go-bindata --nocompress --pkg swagger -o pkg/swagger/datafile.go ./third_party/swagger-ui/...","title":"Swagger Support"},{"location":"components/cli/","text":"KubeRay CLI \u00b6 KubeRay CLI provides the ability to manage kuberay resources (ray clusters, compute templates etc) through command line interface. Note The KubeRay CLI is an optional interface backed by the KubeRay API server. It provides a layer of simplified configuration for KubeRay resources. The KubeRay CLI is community-managed and is not officially endorsed by the Ray maintainers. At this time, the only officially supported methods for managing KubeRay resources are Direct management of KubeRay custom resources via kubectl, kustomize, and Kubernetes language clients. Helm charts. KubeRay CLI maintainer contacts (GitHub handles): @Jeffwan @scarlet25151 Installation \u00b6 Please check release page and download the binaries. Prerequisites \u00b6 Kuberay operator needs to be running. Kuberay apiserver needs to be running and accessible. Development \u00b6 Kuberay CLI uses Cobra framework for the CLI application. Kuberay CLI depends on kuberay apiserver to manage these resources by sending grpc requests to the kuberay apiserver. You can build kuberay binary following this way. cd kuberay/cli go build -o kuberay -a main.go Usage \u00b6 Configure kuberay apiserver endpoint \u00b6 Default kuberay apiserver endpoint: 127.0.0.1:8887 . If kuberay apiserver is not run locally, this must be set in order to manage ray clusters and ray compute templates. Read current kuberay apiserver endpoint \u00b6 ./kuberay config get endpoint Reset kuberay apiserver endpoint to default ( 127.0.0.1:8887 ) \u00b6 ./kuberay config reset endpoint Set kuberay apiserver endpoint \u00b6 ./kuberay config set endpoint <kuberay apiserver endpoint> Manage Ray Clusters \u00b6 Create a Ray Cluster \u00b6 Usage: kuberay cluster create [flags] Flags: --environment string environment of the cluster (valid values: DEV, TESTING, STAGING, PRODUCTION) (default \"DEV\") --head-compute-template string compute template name for ray head --head-image string ray head image --head-service-type string ray head service type (ClusterIP, NodePort, LoadBalancer) (default \"ClusterIP\") --name string name of the cluster -n, --namespace string kubernetes namespace where the cluster will be --user string SSO username of ray cluster creator --version string version of the ray cluster (default \"1.9.0\") --worker-compute-template string compute template name of worker in the first worker group --worker-group-name string first worker group name --worker-image string image of worker in the first worker group --worker-replicas uint32 pod replicas of workers in the first worker group (default 1) Known Limitation: Currently only one worker compute template is supported during creation. Get a Ray Cluster \u00b6 ./kuberay cluster get -n <namespace> <cluster name> List Ray Clusters \u00b6 ./kuberay cluster -n <namespace> list Delete a Ray Cluster \u00b6 ./kuberay cluster delete -n <namespace> <cluster name> Manage Ray Compute Template \u00b6 Create a Compute Template \u00b6 Usage: kuberay template compute create [flags] Flags: --cpu uint32 ray pod CPU (default 1) --gpu uint32 ray head GPU --gpu-accelerator string GPU Accelerator type --memory uint32 ray pod memory in GB (default 1) --name string name of the compute template -n, --namespace string kubernetes namespace where the compute template will be stored Get a Ray Compute Template \u00b6 ./kuberay template compute get -n <namespace> <compute template name> List Ray Compute Templates \u00b6 ./kuberay template compute list -n <namespace> Delete a Ray Compute Template \u00b6 ./kuberay template compute delete -n <namespace> <compute template name> End to end example \u00b6 Configure the endpoints kubectl port-forward svc/kuberay-apiserver-service 8887:8887 -n ray-system ./kuberay config set endpoint 127.0.0.1:8887 Create compute templates ./kuberay template compute create -n <namespace> --cpu 2 --memory 4 --name \"worker-template\" ./kuberay template compute create -n <namespace> --cpu 1 --memory 2 --name \"head-template\" List compute templates created ./kuberay template compute list Create the cluster ./kuberay cluster create -n <namespace> --name test-cluster --user jiaxin.shan \\ --head-compute-template head-template \\ --head-image rayproject/ray:1.9.2 \\ --worker-group-name small-wg \\ --worker-compute-template worker-template \\ --worker-image rayproject/ray:1.9.2 List the clusters ./kuberay cluster list","title":"KubeRay CLI"},{"location":"components/cli/#kuberay-cli","text":"KubeRay CLI provides the ability to manage kuberay resources (ray clusters, compute templates etc) through command line interface. Note The KubeRay CLI is an optional interface backed by the KubeRay API server. It provides a layer of simplified configuration for KubeRay resources. The KubeRay CLI is community-managed and is not officially endorsed by the Ray maintainers. At this time, the only officially supported methods for managing KubeRay resources are Direct management of KubeRay custom resources via kubectl, kustomize, and Kubernetes language clients. Helm charts. KubeRay CLI maintainer contacts (GitHub handles): @Jeffwan @scarlet25151","title":"KubeRay CLI"},{"location":"components/cli/#installation","text":"Please check release page and download the binaries.","title":"Installation"},{"location":"components/cli/#prerequisites","text":"Kuberay operator needs to be running. Kuberay apiserver needs to be running and accessible.","title":"Prerequisites"},{"location":"components/cli/#development","text":"Kuberay CLI uses Cobra framework for the CLI application. Kuberay CLI depends on kuberay apiserver to manage these resources by sending grpc requests to the kuberay apiserver. You can build kuberay binary following this way. cd kuberay/cli go build -o kuberay -a main.go","title":"Development"},{"location":"components/cli/#usage","text":"","title":"Usage"},{"location":"components/cli/#configure-kuberay-apiserver-endpoint","text":"Default kuberay apiserver endpoint: 127.0.0.1:8887 . If kuberay apiserver is not run locally, this must be set in order to manage ray clusters and ray compute templates.","title":"Configure kuberay apiserver endpoint"},{"location":"components/cli/#read-current-kuberay-apiserver-endpoint","text":"./kuberay config get endpoint","title":"Read current kuberay apiserver endpoint"},{"location":"components/cli/#reset-kuberay-apiserver-endpoint-to-default-1270018887","text":"./kuberay config reset endpoint","title":"Reset kuberay apiserver endpoint to default (127.0.0.1:8887)"},{"location":"components/cli/#set-kuberay-apiserver-endpoint","text":"./kuberay config set endpoint <kuberay apiserver endpoint>","title":"Set kuberay apiserver endpoint"},{"location":"components/cli/#manage-ray-clusters","text":"","title":"Manage Ray Clusters"},{"location":"components/cli/#create-a-ray-cluster","text":"Usage: kuberay cluster create [flags] Flags: --environment string environment of the cluster (valid values: DEV, TESTING, STAGING, PRODUCTION) (default \"DEV\") --head-compute-template string compute template name for ray head --head-image string ray head image --head-service-type string ray head service type (ClusterIP, NodePort, LoadBalancer) (default \"ClusterIP\") --name string name of the cluster -n, --namespace string kubernetes namespace where the cluster will be --user string SSO username of ray cluster creator --version string version of the ray cluster (default \"1.9.0\") --worker-compute-template string compute template name of worker in the first worker group --worker-group-name string first worker group name --worker-image string image of worker in the first worker group --worker-replicas uint32 pod replicas of workers in the first worker group (default 1) Known Limitation: Currently only one worker compute template is supported during creation.","title":"Create a Ray Cluster"},{"location":"components/cli/#get-a-ray-cluster","text":"./kuberay cluster get -n <namespace> <cluster name>","title":"Get a Ray Cluster"},{"location":"components/cli/#list-ray-clusters","text":"./kuberay cluster -n <namespace> list","title":"List Ray Clusters"},{"location":"components/cli/#delete-a-ray-cluster","text":"./kuberay cluster delete -n <namespace> <cluster name>","title":"Delete a Ray Cluster"},{"location":"components/cli/#manage-ray-compute-template","text":"","title":"Manage Ray Compute Template"},{"location":"components/cli/#create-a-compute-template","text":"Usage: kuberay template compute create [flags] Flags: --cpu uint32 ray pod CPU (default 1) --gpu uint32 ray head GPU --gpu-accelerator string GPU Accelerator type --memory uint32 ray pod memory in GB (default 1) --name string name of the compute template -n, --namespace string kubernetes namespace where the compute template will be stored","title":"Create a Compute Template"},{"location":"components/cli/#get-a-ray-compute-template","text":"./kuberay template compute get -n <namespace> <compute template name>","title":"Get a Ray Compute Template"},{"location":"components/cli/#list-ray-compute-templates","text":"./kuberay template compute list -n <namespace>","title":"List Ray Compute Templates"},{"location":"components/cli/#delete-a-ray-compute-template","text":"./kuberay template compute delete -n <namespace> <compute template name>","title":"Delete a Ray Compute Template"},{"location":"components/cli/#end-to-end-example","text":"Configure the endpoints kubectl port-forward svc/kuberay-apiserver-service 8887:8887 -n ray-system ./kuberay config set endpoint 127.0.0.1:8887 Create compute templates ./kuberay template compute create -n <namespace> --cpu 2 --memory 4 --name \"worker-template\" ./kuberay template compute create -n <namespace> --cpu 1 --memory 2 --name \"head-template\" List compute templates created ./kuberay template compute list Create the cluster ./kuberay cluster create -n <namespace> --name test-cluster --user jiaxin.shan \\ --head-compute-template head-template \\ --head-image rayproject/ray:1.9.2 \\ --worker-group-name small-wg \\ --worker-compute-template worker-template \\ --worker-image rayproject/ray:1.9.2 List the clusters ./kuberay cluster list","title":"End to end example"},{"location":"components/operator/","text":"Ray Kubernetes Operator \u00b6 The KubeRay Operator makes deploying and managing Ray clusters on top of Kubernetes painless. Clusters are defined as a custom RayCluster resource and managed by a fault-tolerant Ray controller. The KubeRay Operator automates Ray cluster lifecycle management, autoscaling, and other critical functions. Below are some of the main features of the KubeRay operator: Management of first-class RayClusters via a custom resource . Support for heterogenous worker types in a single Ray cluster. Optional Ray Autoscaler integration; autoscaling based on Ray application semantics. Use of Kubernetes PodTemplates to configure Ray pods. Use of ScaleStrategy to remove specific Ray worker pods. Automatated management of critical configuration, such as required environment variables , the ray start entrypoint, and a dev/shm volume mount for Ray's shared memory. Built-in monitoring via Prometheus. Each RayCluster 's Status is updated based on the state of running Ray pods. Kubernetes Events concerning RayCluster instances are emitted to aid observability. Overview \u00b6 When deployed, the KubeRay Operator will watch for K8s events (Create/Delete/Update) for RayCluster resources. The KubeRay Operator can create a Ray cluster (Ray head pod + multiple Ray worker pods), delete a Ray cluster, or update the Ray cluster by adding or removing worker pods. Ray cluster creation \u00b6 Once a RayCluster resource is created, the operator will configure and create the Ray head pod and the Ray worker pods specified in the raycluster manifest as shown below. Ray cluster update \u00b6 You can update the number of replicas in a worker group, and specify which exact replica to remove by updating the RayCluster resource manifest: Note While updating replicas and workersToDeleteUpdate is supported, updating other fields in RayCluster manifests is not supported. In particular, updating Ray head pod and Ray worker pod configuration is not supported. To update pod configuration, delete the RayCluster, edit its configuration and then re-create the cluster. In other words, use kubectl delete and kubectl create to update a RayCluster's pod configuration, rather than kubectl apply . Support for in-place updates of pod configuration is tracked in KubeRay issue #527 . Deploy the operator \u00b6 kubectl create -k \"github.com/ray-project/kuberay/ray-operator/config/default?ref=v0.3.0&timeout=90s\" Check that the controller is running. $ kubectl get deployments -n ray-system NAME READY UP-TO-DATE AVAILABLE AGE ray-operator 1 /1 1 1 40s $ kubectl get pods -n ray-system NAME READY STATUS RESTARTS AGE ray-operator-75dbbf8587-5lrvn 1 /1 Running 0 31s Delete the operator. kubectl delete -k \"github.com/ray-project/kuberay/ray-operator/config/default\" Running an example cluster \u00b6 We include a few example config files to deploy RayClusters: Sample Description ray-cluster.mini.yaml Small example consisting of 1 head pod. ray-cluster.heterogeneous.yaml Example with heterogenous worker types. 1 head pod and 2 worker pods, each of which has a different resource quota. ray-cluster.complete.yaml Shows all available custom resource properties. ray-cluster.autoscaler.yaml Shows all available custom resource properties and demonstrates autoscaling. ray-cluster.complete.large.yaml Demonstrates resource configuration for production use-cases. ray-cluster.autoscaler.large.yaml Demonstrates resource configuration for autoscaling Ray clusters in production. Note For production use-cases, make sure to allocate sufficient resources for your Ray pods; it usually makes sense to run one large Ray pod per Kubernetes node. We do not recommend allocating less than 8Gb memory for a Ray pod running in production. Always set limits for memory and CPU. When possible, set requests equal to limits. See the Ray documentation for further guidance. See ray-cluster.complete.large.yaml and ray-cluster.autoscaler.large.yaml for examples of RayCluster resource configurations suitable for production. The rest of the sample configs above are meant only for experimentation in local kind or minikube environments. The memory usage of the KubeRay Operator depends on the number of pods and Ray clusters being managed. Anecdotally, managing 500 Ray pods requires roughly 500MB memory. Monitor memory usage and adjust requests and limits as needed. We recommend running the following example in a kind or minikube environment with a resource capacity of at least 4CPU and 4Gb memory. Run the following commands from the root of your cloned kuberay repo. # Clone the kuberay repo if you haven't already. $ git clone https://github.com/ray-project/kuberay # Enter the root of the repo $ cd kuberay/ # If you haven't already done so, deploy the KubeRay operator. $ kubectl create -k ray-operator/config/default # Create a RayCluster and a ConfigMap with hello world Ray code. $ kubectl create -f ray-operator/config/samples/ray-cluster.heterogeneous.yaml configmap/ray-code created raycluster.ray.io/raycluster-heterogeneous created # List running clusters. $ kubectl get rayclusters NAME AGE raycluster-heterogeneous 2m48s # The created cluster should include a head pod, worker pod, and a head service. # It may take a few minutes for the pods to enter Running status. # If you're on minikube or kind, a Pending status indicates that your local Kubernetes environment # may not have sufficient CPU or memory capacity -- try adjusting your Docker settings. $ kubectl get pods NAME READY STATUS RESTARTS AGE raycluster-heterogeneous-head-9t28q 1 /1 Running 0 97s raycluster-heterogeneous-worker-medium-group-l9x9n 1 /1 Running 0 97s raycluster-heterogeneous-worker-small-group-hldxz 1 /1 Running 0 97s raycluster-heterogeneous-worker-small-group-tmgtq 1 /1 Running 0 97s raycluster-heterogeneous-worker-small-group-zc5dh 1 /1 Running 0 97s $ kubectl get services NAME TYPE CLUSTER-IP EXTERNAL-IP PORT ( S ) AGE kubernetes ClusterIP 10 .96.0.1 <none> 443 /TCP 22h raycluster-heterogeneous-head-svc ClusterIP 10 .96.47.129 <none> 6379 /TCP,8265/TCP,10001/TCP 2m18s # Check the logs of the head pod. (Substitute the name of your head pod in this step.) $ kubectl logs raycluster-heterogeneous-head-9t28q 2022 -09-21 13 :21:57,505 INFO usage_lib.py:479 -- Usage stats collection is enabled by default without user confirmation because this terminal is detected to be non-interactive. To disable this, add ` --disable-usage-stats ` to the command that starts the cluster, or run the following command: ` ray disable-usage-stats ` before starting the cluster. See https://docs.ray.io/en/master/cluster/usage-stats.html for more details. 2022 -09-21 13 :21:57,505 INFO scripts.py:719 -- Local node IP: 10 .244.0.144 2022 -09-21 13 :22:00,513 SUCC scripts.py:756 -- -------------------- 2022 -09-21 13 :22:00,514 SUCC scripts.py:757 -- Ray runtime started. 2022 -09-21 13 :22:00,514 SUCC scripts.py:758 -- -------------------- 2022 -09-21 13 :22:00,514 INFO scripts.py:760 -- Next steps 2022 -09-21 13 :22:00,514 INFO scripts.py:761 -- To connect to this Ray runtime from another node, run 2022 -09-21 13 :22:00,514 INFO scripts.py:766 -- ray start --address = '10.244.0.144:6379' 2022 -09-21 13 :22:00,514 INFO scripts.py:780 -- Alternatively, use the following Python code: 2022 -09-21 13 :22:00,514 INFO scripts.py:782 -- import ray 2022 -09-21 13 :22:00,514 INFO scripts.py:795 -- ray.init ( address = 'auto' , _node_ip_address = '10.244.0.144' ) 2022 -09-21 13 :22:00,515 INFO scripts.py:799 -- To connect to this Ray runtime from outside of the cluster, for example to 2022 -09-21 13 :22:00,515 INFO scripts.py:803 -- connect to a remote cluster from your laptop directly, use the following 2022 -09-21 13 :22:00,515 INFO scripts.py:806 -- Python code: 2022 -09-21 13 :22:00,515 INFO scripts.py:808 -- import ray 2022 -09-21 13 :22:00,515 INFO scripts.py:814 -- ray.init ( address = 'ray://<head_node_ip_address>:10001' ) 2022 -09-21 13 :22:00,515 INFO scripts.py:820 -- If connection fails, check your firewall settings and network configuration. 2022 -09-21 13 :22:00,515 INFO scripts.py:826 -- To terminate the Ray runtime, run 2022 -09-21 13 :22:00,515 INFO scripts.py:827 -- ray stop 2022 -09-21 13 :22:00,515 INFO scripts.py:905 -- --block 2022 -09-21 13 :22:00,515 INFO scripts.py:907 -- This command will now block forever until terminated by a signal. 2022 -09-21 13 :22:00,515 INFO scripts.py:910 -- Running subprocesses are monitored and a message will be printed if any of them terminate unexpectedly. Subprocesses exit with SIGTERM will be treated as graceful, thus NOT reported. Now, we can run the hello world Ray code mounted from the config map created above. # Substitute the name of your head pod in this step. $ kubectl exec raycluster-heterogeneous-head-9t28q -- python /opt/sample_code.py 2022 -09-21 13 :28:41,176 INFO worker.py:1224 -- Using address 127 .0.0.1:6379 set in the environment variable RAY_ADDRESS 2022 -09-21 13 :28:41,176 INFO worker.py:1333 -- Connecting to existing Ray cluster at address: 10 .244.0.144:6379... 2022 -09-21 13 :28:41,183 INFO worker.py:1515 -- Connected to Ray cluster. View the dashboard at http://10.244.0.144:8265 trying to connect to Ray! now executing some code with Ray! Ray Nodes: { '10.244.0.145' , '10.244.0.143' , '10.244.0.146' , '10.244.0.144' , '10.244.0.147' } Execution time = 4 .855740308761597 The output of the hello world Ray code shows 5 nodes in the Ray cluster. Ray Nodes: {'10.244.0.145', '10.244.0.143', '10.244.0.146', '10.244.0.144', '10.244.0.147'} # Delete the cluster. $ kubectl delete raycluster raycluster-heterogeneous","title":"KubeRay Operator"},{"location":"components/operator/#ray-kubernetes-operator","text":"The KubeRay Operator makes deploying and managing Ray clusters on top of Kubernetes painless. Clusters are defined as a custom RayCluster resource and managed by a fault-tolerant Ray controller. The KubeRay Operator automates Ray cluster lifecycle management, autoscaling, and other critical functions. Below are some of the main features of the KubeRay operator: Management of first-class RayClusters via a custom resource . Support for heterogenous worker types in a single Ray cluster. Optional Ray Autoscaler integration; autoscaling based on Ray application semantics. Use of Kubernetes PodTemplates to configure Ray pods. Use of ScaleStrategy to remove specific Ray worker pods. Automatated management of critical configuration, such as required environment variables , the ray start entrypoint, and a dev/shm volume mount for Ray's shared memory. Built-in monitoring via Prometheus. Each RayCluster 's Status is updated based on the state of running Ray pods. Kubernetes Events concerning RayCluster instances are emitted to aid observability.","title":"Ray Kubernetes Operator"},{"location":"components/operator/#overview","text":"When deployed, the KubeRay Operator will watch for K8s events (Create/Delete/Update) for RayCluster resources. The KubeRay Operator can create a Ray cluster (Ray head pod + multiple Ray worker pods), delete a Ray cluster, or update the Ray cluster by adding or removing worker pods.","title":"Overview"},{"location":"components/operator/#ray-cluster-creation","text":"Once a RayCluster resource is created, the operator will configure and create the Ray head pod and the Ray worker pods specified in the raycluster manifest as shown below.","title":"Ray cluster creation"},{"location":"components/operator/#ray-cluster-update","text":"You can update the number of replicas in a worker group, and specify which exact replica to remove by updating the RayCluster resource manifest: Note While updating replicas and workersToDeleteUpdate is supported, updating other fields in RayCluster manifests is not supported. In particular, updating Ray head pod and Ray worker pod configuration is not supported. To update pod configuration, delete the RayCluster, edit its configuration and then re-create the cluster. In other words, use kubectl delete and kubectl create to update a RayCluster's pod configuration, rather than kubectl apply . Support for in-place updates of pod configuration is tracked in KubeRay issue #527 .","title":"Ray cluster update"},{"location":"components/operator/#deploy-the-operator","text":"kubectl create -k \"github.com/ray-project/kuberay/ray-operator/config/default?ref=v0.3.0&timeout=90s\" Check that the controller is running. $ kubectl get deployments -n ray-system NAME READY UP-TO-DATE AVAILABLE AGE ray-operator 1 /1 1 1 40s $ kubectl get pods -n ray-system NAME READY STATUS RESTARTS AGE ray-operator-75dbbf8587-5lrvn 1 /1 Running 0 31s Delete the operator. kubectl delete -k \"github.com/ray-project/kuberay/ray-operator/config/default\"","title":"Deploy the operator"},{"location":"components/operator/#running-an-example-cluster","text":"We include a few example config files to deploy RayClusters: Sample Description ray-cluster.mini.yaml Small example consisting of 1 head pod. ray-cluster.heterogeneous.yaml Example with heterogenous worker types. 1 head pod and 2 worker pods, each of which has a different resource quota. ray-cluster.complete.yaml Shows all available custom resource properties. ray-cluster.autoscaler.yaml Shows all available custom resource properties and demonstrates autoscaling. ray-cluster.complete.large.yaml Demonstrates resource configuration for production use-cases. ray-cluster.autoscaler.large.yaml Demonstrates resource configuration for autoscaling Ray clusters in production. Note For production use-cases, make sure to allocate sufficient resources for your Ray pods; it usually makes sense to run one large Ray pod per Kubernetes node. We do not recommend allocating less than 8Gb memory for a Ray pod running in production. Always set limits for memory and CPU. When possible, set requests equal to limits. See the Ray documentation for further guidance. See ray-cluster.complete.large.yaml and ray-cluster.autoscaler.large.yaml for examples of RayCluster resource configurations suitable for production. The rest of the sample configs above are meant only for experimentation in local kind or minikube environments. The memory usage of the KubeRay Operator depends on the number of pods and Ray clusters being managed. Anecdotally, managing 500 Ray pods requires roughly 500MB memory. Monitor memory usage and adjust requests and limits as needed. We recommend running the following example in a kind or minikube environment with a resource capacity of at least 4CPU and 4Gb memory. Run the following commands from the root of your cloned kuberay repo. # Clone the kuberay repo if you haven't already. $ git clone https://github.com/ray-project/kuberay # Enter the root of the repo $ cd kuberay/ # If you haven't already done so, deploy the KubeRay operator. $ kubectl create -k ray-operator/config/default # Create a RayCluster and a ConfigMap with hello world Ray code. $ kubectl create -f ray-operator/config/samples/ray-cluster.heterogeneous.yaml configmap/ray-code created raycluster.ray.io/raycluster-heterogeneous created # List running clusters. $ kubectl get rayclusters NAME AGE raycluster-heterogeneous 2m48s # The created cluster should include a head pod, worker pod, and a head service. # It may take a few minutes for the pods to enter Running status. # If you're on minikube or kind, a Pending status indicates that your local Kubernetes environment # may not have sufficient CPU or memory capacity -- try adjusting your Docker settings. $ kubectl get pods NAME READY STATUS RESTARTS AGE raycluster-heterogeneous-head-9t28q 1 /1 Running 0 97s raycluster-heterogeneous-worker-medium-group-l9x9n 1 /1 Running 0 97s raycluster-heterogeneous-worker-small-group-hldxz 1 /1 Running 0 97s raycluster-heterogeneous-worker-small-group-tmgtq 1 /1 Running 0 97s raycluster-heterogeneous-worker-small-group-zc5dh 1 /1 Running 0 97s $ kubectl get services NAME TYPE CLUSTER-IP EXTERNAL-IP PORT ( S ) AGE kubernetes ClusterIP 10 .96.0.1 <none> 443 /TCP 22h raycluster-heterogeneous-head-svc ClusterIP 10 .96.47.129 <none> 6379 /TCP,8265/TCP,10001/TCP 2m18s # Check the logs of the head pod. (Substitute the name of your head pod in this step.) $ kubectl logs raycluster-heterogeneous-head-9t28q 2022 -09-21 13 :21:57,505 INFO usage_lib.py:479 -- Usage stats collection is enabled by default without user confirmation because this terminal is detected to be non-interactive. To disable this, add ` --disable-usage-stats ` to the command that starts the cluster, or run the following command: ` ray disable-usage-stats ` before starting the cluster. See https://docs.ray.io/en/master/cluster/usage-stats.html for more details. 2022 -09-21 13 :21:57,505 INFO scripts.py:719 -- Local node IP: 10 .244.0.144 2022 -09-21 13 :22:00,513 SUCC scripts.py:756 -- -------------------- 2022 -09-21 13 :22:00,514 SUCC scripts.py:757 -- Ray runtime started. 2022 -09-21 13 :22:00,514 SUCC scripts.py:758 -- -------------------- 2022 -09-21 13 :22:00,514 INFO scripts.py:760 -- Next steps 2022 -09-21 13 :22:00,514 INFO scripts.py:761 -- To connect to this Ray runtime from another node, run 2022 -09-21 13 :22:00,514 INFO scripts.py:766 -- ray start --address = '10.244.0.144:6379' 2022 -09-21 13 :22:00,514 INFO scripts.py:780 -- Alternatively, use the following Python code: 2022 -09-21 13 :22:00,514 INFO scripts.py:782 -- import ray 2022 -09-21 13 :22:00,514 INFO scripts.py:795 -- ray.init ( address = 'auto' , _node_ip_address = '10.244.0.144' ) 2022 -09-21 13 :22:00,515 INFO scripts.py:799 -- To connect to this Ray runtime from outside of the cluster, for example to 2022 -09-21 13 :22:00,515 INFO scripts.py:803 -- connect to a remote cluster from your laptop directly, use the following 2022 -09-21 13 :22:00,515 INFO scripts.py:806 -- Python code: 2022 -09-21 13 :22:00,515 INFO scripts.py:808 -- import ray 2022 -09-21 13 :22:00,515 INFO scripts.py:814 -- ray.init ( address = 'ray://<head_node_ip_address>:10001' ) 2022 -09-21 13 :22:00,515 INFO scripts.py:820 -- If connection fails, check your firewall settings and network configuration. 2022 -09-21 13 :22:00,515 INFO scripts.py:826 -- To terminate the Ray runtime, run 2022 -09-21 13 :22:00,515 INFO scripts.py:827 -- ray stop 2022 -09-21 13 :22:00,515 INFO scripts.py:905 -- --block 2022 -09-21 13 :22:00,515 INFO scripts.py:907 -- This command will now block forever until terminated by a signal. 2022 -09-21 13 :22:00,515 INFO scripts.py:910 -- Running subprocesses are monitored and a message will be printed if any of them terminate unexpectedly. Subprocesses exit with SIGTERM will be treated as graceful, thus NOT reported. Now, we can run the hello world Ray code mounted from the config map created above. # Substitute the name of your head pod in this step. $ kubectl exec raycluster-heterogeneous-head-9t28q -- python /opt/sample_code.py 2022 -09-21 13 :28:41,176 INFO worker.py:1224 -- Using address 127 .0.0.1:6379 set in the environment variable RAY_ADDRESS 2022 -09-21 13 :28:41,176 INFO worker.py:1333 -- Connecting to existing Ray cluster at address: 10 .244.0.144:6379... 2022 -09-21 13 :28:41,183 INFO worker.py:1515 -- Connected to Ray cluster. View the dashboard at http://10.244.0.144:8265 trying to connect to Ray! now executing some code with Ray! Ray Nodes: { '10.244.0.145' , '10.244.0.143' , '10.244.0.146' , '10.244.0.144' , '10.244.0.147' } Execution time = 4 .855740308761597 The output of the hello world Ray code shows 5 nodes in the Ray cluster. Ray Nodes: {'10.244.0.145', '10.244.0.143', '10.244.0.146', '10.244.0.144', '10.244.0.147'} # Delete the cluster. $ kubectl delete raycluster raycluster-heterogeneous","title":"Running an example cluster"},{"location":"deploy/docker/","text":"Docker images \u00b6 Find the Docker images for various KubeRay components on Dockerhub . Stable versions \u00b6 For stable releases, use version tags (e.g. kuberay/operator:v0.4.0 ). Master commits \u00b6 The first seven characters of the git SHA specify images built from specific commits (e.g. kuberay/operator:944a042 ). Nightly images \u00b6 The nightly tag specifies images built from the most recent master (e.g. kuberay/operator:nightly ).","title":"Docker Images"},{"location":"deploy/docker/#docker-images","text":"Find the Docker images for various KubeRay components on Dockerhub .","title":"Docker images"},{"location":"deploy/docker/#stable-versions","text":"For stable releases, use version tags (e.g. kuberay/operator:v0.4.0 ).","title":"Stable versions"},{"location":"deploy/docker/#master-commits","text":"The first seven characters of the git SHA specify images built from specific commits (e.g. kuberay/operator:944a042 ).","title":"Master commits"},{"location":"deploy/docker/#nightly-images","text":"The nightly tag specifies images built from the most recent master (e.g. kuberay/operator:nightly ).","title":"Nightly images"},{"location":"deploy/helm-cluster/","text":"RayCluster \u00b6 RayCluster is a custom resource definition (CRD). KubeRay operator will listen to the resource events about RayCluster and create related Kubernetes resources (e.g. Pod & Service). Hence, KubeRay operator installation and CRD registration are required for this guide. Prerequisites \u00b6 See kuberay-operator/README.md for more details. * Helm * Install custom resource definition and KubeRay operator (covered by the following end-to-end example.) End-to-end example \u00b6 # Step 1: Create a KinD cluster kind create cluster # Step 2: Register a Helm chart repo helm repo add kuberay https://ray-project.github.io/kuberay-helm/ # Step 3: Install both CRDs and KubeRay operator v0.4.0. helm install kuberay-operator kuberay/kuberay-operator --version 0 .4.0 # Step 4: Install a RayCluster custom resource helm install raycluster kuberay/ray-cluster --version 0 .4.0 # Step 5: Verify the installation of KubeRay operator and RayCluster kubectl get pods # NAME READY STATUS RESTARTS AGE # kuberay-operator-6fcbb94f64-gkpc9 1/1 Running 0 89s # raycluster-kuberay-head-qp9f4 1/1 Running 0 66s # raycluster-kuberay-worker-workergroup-2jckt 1/1 Running 0 66s # Step 6: Forward the port of Dashboard kubectl port-forward --address 0 .0.0.0 svc/raycluster-kuberay-head-svc 8265 :8265 # Step 7: Check ${YOUR_IP}:8265 for the Dashboard (e.g. 127.0.0.1:8265) # Step 8: Log in to Ray head Pod and execute a job. kubectl exec -it ${ RAYCLUSTER_HEAD_POD } -- bash python -c \"import ray; ray.init(); print(ray.cluster_resources())\" # (in Ray head Pod) # Step 9: Check ${YOUR_IP}:8265/#/job. The status of the job should be \"SUCCEEDED\". # Step 10: Uninstall RayCluster helm uninstall raycluster # Step 11: Verify that RayCluster has been removed successfully # NAME READY STATUS RESTARTS AGE # kuberay-operator-6fcbb94f64-gkpc9 1/1 Running 0 9m57s","title":"Installation(Helm-cluster)"},{"location":"deploy/helm-cluster/#raycluster","text":"RayCluster is a custom resource definition (CRD). KubeRay operator will listen to the resource events about RayCluster and create related Kubernetes resources (e.g. Pod & Service). Hence, KubeRay operator installation and CRD registration are required for this guide.","title":"RayCluster"},{"location":"deploy/helm-cluster/#prerequisites","text":"See kuberay-operator/README.md for more details. * Helm * Install custom resource definition and KubeRay operator (covered by the following end-to-end example.)","title":"Prerequisites"},{"location":"deploy/helm-cluster/#end-to-end-example","text":"# Step 1: Create a KinD cluster kind create cluster # Step 2: Register a Helm chart repo helm repo add kuberay https://ray-project.github.io/kuberay-helm/ # Step 3: Install both CRDs and KubeRay operator v0.4.0. helm install kuberay-operator kuberay/kuberay-operator --version 0 .4.0 # Step 4: Install a RayCluster custom resource helm install raycluster kuberay/ray-cluster --version 0 .4.0 # Step 5: Verify the installation of KubeRay operator and RayCluster kubectl get pods # NAME READY STATUS RESTARTS AGE # kuberay-operator-6fcbb94f64-gkpc9 1/1 Running 0 89s # raycluster-kuberay-head-qp9f4 1/1 Running 0 66s # raycluster-kuberay-worker-workergroup-2jckt 1/1 Running 0 66s # Step 6: Forward the port of Dashboard kubectl port-forward --address 0 .0.0.0 svc/raycluster-kuberay-head-svc 8265 :8265 # Step 7: Check ${YOUR_IP}:8265 for the Dashboard (e.g. 127.0.0.1:8265) # Step 8: Log in to Ray head Pod and execute a job. kubectl exec -it ${ RAYCLUSTER_HEAD_POD } -- bash python -c \"import ray; ray.init(); print(ray.cluster_resources())\" # (in Ray head Pod) # Step 9: Check ${YOUR_IP}:8265/#/job. The status of the job should be \"SUCCEEDED\". # Step 10: Uninstall RayCluster helm uninstall raycluster # Step 11: Verify that RayCluster has been removed successfully # NAME READY STATUS RESTARTS AGE # kuberay-operator-6fcbb94f64-gkpc9 1/1 Running 0 9m57s","title":"End-to-end example"},{"location":"deploy/helm/","text":"KubeRay Operator \u00b6 This document provides instructions to install both CRDs (RayCluster, RayJob, RayService) and KubeRay operator with a Helm chart. Helm \u00b6 Make sure the version of Helm is v3+. Currently, existing CI tests are based on Helm v3.4.1 and v3.9.4. helm version Install CRDs and KubeRay operator \u00b6 Install a stable version via Helm repository (only supports KubeRay v0.4.0+) helm repo add kuberay https://ray-project.github.io/kuberay-helm/ # Install both CRDs and KubeRay operator v0.4.0. helm install kuberay-operator kuberay/kuberay-operator --version 0 .4.0 # Check the KubeRay operator Pod in `default` namespace kubectl get pods # NAME READY STATUS RESTARTS AGE # kuberay-operator-6fcbb94f64-mbfnr 1/1 Running 0 17s Install the nightly version # Step1: Clone KubeRay repository # Step2: Move to `helm-chart/kuberay-operator` # Step3: Install KubeRay operator helm install kuberay-operator . List the chart \u00b6 To list the my-release deployment: helm ls # NAME NAMESPACE REVISION UPDATED STATUS CHART # APP VERSION # kuberay-operator default 1 2022-12-02 02:13:37.514445313 +0000 UTC deployed kuberay-operator-0.4.0 1.0 Uninstall the Chart \u00b6 # Uninstall the `kuberay-operator` release helm uninstall kuberay-operator # The operator Pod should be removed. kubectl get pods # No resources found in default namespace. Working with Argo CD \u00b6 If you are using Argo CD to manage the operator, you will encounter the issue which complains the CRDs too long. Same with this issue . The recommended solution is to split the operator into two Argo apps, such as: The first app just for installing the CRDs with Replace=true directly, snippet: apiVersion : argoproj.io/v1alpha1 kind : Application metadata : name : ray-operator-crds spec : project : default source : repoURL : https://github.com/ray-project/kuberay targetRevision : v0.3.0 path : helm-chart/kuberay-operator/crds destination : server : https://kubernetes.default.svc syncPolicy : syncOptions : - Replace=true ... The second app that installs the Helm chart with skipCrds=true (new feature in Argo CD 2.3.0), snippet: apiVersion : argoproj.io/v1alpha1 kind : Application metadata : name : ray-operator spec : source : repoURL : https://github.com/ray-project/kuberay targetRevision : v0.3.0 path : helm-chart/kuberay-operator helm : skipCrds : true destination : server : https://kubernetes.default.svc namespace : ray-operator syncPolicy : syncOptions : - CreateNamespace=true ...","title":"Installation(Helm)"},{"location":"deploy/helm/#kuberay-operator","text":"This document provides instructions to install both CRDs (RayCluster, RayJob, RayService) and KubeRay operator with a Helm chart.","title":"KubeRay Operator"},{"location":"deploy/helm/#helm","text":"Make sure the version of Helm is v3+. Currently, existing CI tests are based on Helm v3.4.1 and v3.9.4. helm version","title":"Helm"},{"location":"deploy/helm/#install-crds-and-kuberay-operator","text":"Install a stable version via Helm repository (only supports KubeRay v0.4.0+) helm repo add kuberay https://ray-project.github.io/kuberay-helm/ # Install both CRDs and KubeRay operator v0.4.0. helm install kuberay-operator kuberay/kuberay-operator --version 0 .4.0 # Check the KubeRay operator Pod in `default` namespace kubectl get pods # NAME READY STATUS RESTARTS AGE # kuberay-operator-6fcbb94f64-mbfnr 1/1 Running 0 17s Install the nightly version # Step1: Clone KubeRay repository # Step2: Move to `helm-chart/kuberay-operator` # Step3: Install KubeRay operator helm install kuberay-operator .","title":"Install CRDs and KubeRay operator"},{"location":"deploy/helm/#list-the-chart","text":"To list the my-release deployment: helm ls # NAME NAMESPACE REVISION UPDATED STATUS CHART # APP VERSION # kuberay-operator default 1 2022-12-02 02:13:37.514445313 +0000 UTC deployed kuberay-operator-0.4.0 1.0","title":"List the chart"},{"location":"deploy/helm/#uninstall-the-chart","text":"# Uninstall the `kuberay-operator` release helm uninstall kuberay-operator # The operator Pod should be removed. kubectl get pods # No resources found in default namespace.","title":"Uninstall the Chart"},{"location":"deploy/helm/#working-with-argo-cd","text":"If you are using Argo CD to manage the operator, you will encounter the issue which complains the CRDs too long. Same with this issue . The recommended solution is to split the operator into two Argo apps, such as: The first app just for installing the CRDs with Replace=true directly, snippet: apiVersion : argoproj.io/v1alpha1 kind : Application metadata : name : ray-operator-crds spec : project : default source : repoURL : https://github.com/ray-project/kuberay targetRevision : v0.3.0 path : helm-chart/kuberay-operator/crds destination : server : https://kubernetes.default.svc syncPolicy : syncOptions : - Replace=true ... The second app that installs the Helm chart with skipCrds=true (new feature in Argo CD 2.3.0), snippet: apiVersion : argoproj.io/v1alpha1 kind : Application metadata : name : ray-operator spec : source : repoURL : https://github.com/ray-project/kuberay targetRevision : v0.3.0 path : helm-chart/kuberay-operator helm : skipCrds : true destination : server : https://kubernetes.default.svc namespace : ray-operator syncPolicy : syncOptions : - CreateNamespace=true ...","title":"Working with Argo CD"},{"location":"deploy/installation/","text":"Installation \u00b6 Make sure your Kubernetes cluster and Kubectl are both at version at least 1.19. Nightly version \u00b6 export KUBERAY_VERSION = master # Install CRDs kubectl create -k \"github.com/ray-project/kuberay/manifests/cluster-scope-resources?ref= ${ KUBERAY_VERSION } &timeout=90s\" # Install KubeRay operator kubectl apply -k \"github.com/ray-project/kuberay/manifests/base?ref= ${ KUBERAY_VERSION } &timeout=90s\" Stable version \u00b6 Method 1: Install charts from Helm repository \u00b6 helm repo add kuberay https://ray-project.github.io/kuberay-helm/ # Install both CRDs and KubeRay operator helm install kuberay-operator kuberay/kuberay-operator Method 2: Kustomize \u00b6 # Install CRDs kubectl create -k \"github.com/ray-project/kuberay/manifests/cluster-scope-resources?ref=v0.3.0\" # Install KubeRay operator kubectl apply -k \"github.com/ray-project/kuberay/manifests/base?ref=v0.3.0\" Observe that we must use kubectl create to install cluster-scoped resources. The corresponding kubectl apply command will not work. See KubeRay issue #271 . Single Namespace version \u00b6 Users can use the following commands to deploy KubeRay operator in a specific namespace. export KUBERAY_NAMESPACE = <my-awesome-namespace> # Install CRDs (Executed by cluster admin) kustomize build \"github.com/ray-project/kuberay/manifests/overlays/single-namespace-resources\" | envsubst | kubectl create -f - # Install KubeRay operator (Executed by user) kustomize build \"github.com/ray-project/kuberay/manifests/overlays/single-namespace\" | envsubst | kubectl apply -f -","title":"Installation(Yaml)"},{"location":"deploy/installation/#installation","text":"Make sure your Kubernetes cluster and Kubectl are both at version at least 1.19.","title":"Installation"},{"location":"deploy/installation/#nightly-version","text":"export KUBERAY_VERSION = master # Install CRDs kubectl create -k \"github.com/ray-project/kuberay/manifests/cluster-scope-resources?ref= ${ KUBERAY_VERSION } &timeout=90s\" # Install KubeRay operator kubectl apply -k \"github.com/ray-project/kuberay/manifests/base?ref= ${ KUBERAY_VERSION } &timeout=90s\"","title":"Nightly version"},{"location":"deploy/installation/#stable-version","text":"","title":"Stable version"},{"location":"deploy/installation/#method-1-install-charts-from-helm-repository","text":"helm repo add kuberay https://ray-project.github.io/kuberay-helm/ # Install both CRDs and KubeRay operator helm install kuberay-operator kuberay/kuberay-operator","title":"Method 1: Install charts from Helm repository"},{"location":"deploy/installation/#method-2-kustomize","text":"# Install CRDs kubectl create -k \"github.com/ray-project/kuberay/manifests/cluster-scope-resources?ref=v0.3.0\" # Install KubeRay operator kubectl apply -k \"github.com/ray-project/kuberay/manifests/base?ref=v0.3.0\" Observe that we must use kubectl create to install cluster-scoped resources. The corresponding kubectl apply command will not work. See KubeRay issue #271 .","title":"Method 2: Kustomize"},{"location":"deploy/installation/#single-namespace-version","text":"Users can use the following commands to deploy KubeRay operator in a specific namespace. export KUBERAY_NAMESPACE = <my-awesome-namespace> # Install CRDs (Executed by cluster admin) kustomize build \"github.com/ray-project/kuberay/manifests/overlays/single-namespace-resources\" | envsubst | kubectl create -f - # Install KubeRay operator (Executed by user) kustomize build \"github.com/ray-project/kuberay/manifests/overlays/single-namespace\" | envsubst | kubectl apply -f -","title":"Single Namespace version"},{"location":"design/protobuf-grpc-service/","text":"Support proto Core API and RESTful backend services \u00b6 Motivation \u00b6 There're few major blockers for users to use KubeRay Operator directly. Current ray operator is only friendly to users who is familiar with Kubernetes operator pattern. For most data scientists, there's still a learning curve. Using kubectl requires sophisticated permission system. Some kubernetes clusters do not enable user level authentication. In some companies, devops use loose RBAC management and corp SSO system is not integrated with Kubernetes OIDC at all. For the above reasons, it's worth it to build a generic abstraction on top of the RayCluster CRD. With the core API support, we can easily build backend services, cli, etc to bridge users without Kubernetes experience to KubeRay. Goals \u00b6 The API definition should be flexible enough to support different kinds of clients (e.g. backend, cli etc). This backend service underneath should leverage generate clients to interact with existing RayCluster custom resources. New added components should be plugable to existing operator. Proposal \u00b6 Deployment topology and interactive flow \u00b6 The new gRPC service would be a individual deployment of the KubeRay control plane and user can choose to install it optionally. It will create a service and exposes endpoint to users. NAME READY STATUS RESTARTS AGE kuberay-grpc-service-c8db9dc65-d4w5r 1/1 Running 0 2d15h kuberay-operator-785476b948-fmlm7 1/1 Running 0 3d In issue #29 , RayCluster CRD clientset has been generated and gRPC service can leverage it to operate Custom Resources. A simple flow would be like this. (Thanks @akanso for providing the flow) client --> GRPC Server --> [created Custom Resources] <-- Ray Operator (reads CR and accordingly performs CRUD) API abstraction \u00b6 Protocol Buffers are a language-neutral, platform-neutral extensible mechanism for serializing structured data. Protoc also provides different community plugins to meet different needs. In order to better define resources at the API level, a few proto files will be defined. Technically, we can use similar data structure like RayCluster Kubernetes resource but this is probably not a good idea. Some of the Kubernetes API like tolerance and node affinity are too complicated to be converted to an API. We want to leave some flexibility to use database to store history data in the near future (for example, pagination, list options etc). To resolve these issues, we provide a simple API which can cover most common use-cases. For example, the protobuf definition of the RayCluster : service ClusterService { // Creates a new Cluster. rpc CreateCluster ( CreateClusterRequest ) returns ( Cluster ) { option ( google.api.http ) = { post : \"/apis/v1alpha2/namespaces/{namespace}/clusters\" body : \"cluster\" }; } // Finds a specific Cluster by ID. rpc GetCluster ( GetClusterRequest ) returns ( Cluster ) { option ( google.api.http ) = { get : \"/apis/v1alpha2/namespaces/{namespace}/clusters/{name}\" }; } // Finds all Clusters in a given namespace. Supports pagination, and sorting on certain fields. rpc ListCluster ( ListClustersRequest ) returns ( ListClustersResponse ) { option ( google.api.http ) = { get : \"/apis/v1alpha2/namespaces/{namespace}/clusters\" }; } // Finds all Clusters in all namespaces. Supports pagination, and sorting on certain fields. rpc ListAllClusters ( ListAllClustersRequest ) returns ( ListAllClustersResponse ) { option ( google.api.http ) = { get : \"/apis/v1alpha2/clusters\" }; } // Deletes an cluster without deleting the cluster's runs and jobs. To // avoid unexpected behaviors, delete an cluster's runs and jobs before // deleting the cluster. rpc DeleteCluster ( DeleteClusterRequest ) returns ( google.protobuf.Empty ) { option ( google.api.http ) = { delete : \"/apis/v1alpha2/namespaces/{namespace}/clusters/{name}\" }; } } message CreateClusterRequest { // The cluster to be created. Cluster cluster = 1 ; // The namespace of the cluster to be created. string namespace = 2 ; } message GetClusterRequest { // The name of the cluster to be retrieved. string name = 1 ; // The namespace of the cluster to be retrieved. string namespace = 2 ; } message ListClustersRequest { // The namespace of the clusters to be retrieved. string namespace = 1 ; } message ListClustersResponse { // A list of clusters returned. repeated Cluster clusters = 1 ; } message ListAllClustersRequest {} message ListAllClustersResponse { // A list of clusters returned. repeated Cluster clusters = 1 ; } message DeleteClusterRequest { // The name of the cluster to be deleted. string name = 1 ; // The namespace of the cluster to be deleted. string namespace = 2 ; } message Cluster { // Required input field. Unique cluster name provided by user. string name = 1 ; // Required input field. Cluster's namespace provided by user string namespace = 2 ; // Required field. This field indicates the user who owns the cluster. string user = 3 ; // Optional input field. Ray cluster version string version = 4 ; // Optional field. enum Environment { DEV = 0 ; TESTING = 1 ; STAGING = 2 ; PRODUCTION = 3 ; } Environment environment = 5 ; // Required field. This field indicates ray cluster configuration ClusterSpec cluster_spec = 6 ; // Output. The time that the cluster created. google.protobuf.Timestamp created_at = 7 ; // Output. The time that the cluster deleted. google.protobuf.Timestamp deleted_at = 8 ; // Output. The status to show the cluster status.state string cluster_state = 9 ; // Output. The list related to the cluster. repeated ClusterEvent events = 10 ; // Output. The service endpoint of the cluster map < string , string > service_endpoint = 11 ; // Optional input field. Container environment variables from user. map < string , string > envs = 12 ; } message ClusterSpec { // The head group configuration HeadGroupSpec head_group_spec = 1 ; // The worker group configurations repeated WorkerGroupSpec worker_group_spec = 2 ; } message Volume { string mount_path = 1 ; enum VolumeType { PERSISTENT_VOLUME_CLAIM = 0 ; HOST_PATH = 1 ; } VolumeType volume_type = 2 ; string name = 3 ; string source = 4 ; bool read_only = 5 ; // If indicate hostpath, we need to let user indicate which type // they would like to use. enum HostPathType { DIRECTORY = 0 ; FILE = 1 ; } HostPathType host_path_type = 6 ; enum MountPropagationMode { NONE = 0 ; HOSTTOCONTAINER = 1 ; BIDIRECTIONAL = 2 ; } MountPropagationMode mount_propagation_mode = 7 ; } message HeadGroupSpec { // Optional. The computeTemplate of head node group string compute_template = 1 ; // Optional field. This field will be used to retrieve right ray container string image = 2 ; // Optional. The service type (ClusterIP, NodePort, Load balancer) of the head node string service_type = 3 ; // Optional. The ray start params of head node group map < string , string > ray_start_params = 4 ; // Optional. The volumes mount to head pod repeated Volume volumes = 5 ; } message WorkerGroupSpec { // Required. Group name of the current worker group string group_name = 1 ; // Optional. The computeTemplate of head node group string compute_template = 2 ; // Optional field. This field will be used to retrieve right ray container string image = 3 ; // Required. Desired replicas of the worker group int32 replicas = 4 ; // Optional. Min replicas of the worker group int32 min_replicas = 5 ; // Optional. Max replicas of the worker group int32 max_replicas = 6 ; // Optional. The ray start parames of worker node group map < string , string > ray_start_params = 7 ; // Optional. The volumes mount to worker pods repeated Volume volumes = 8 ; } message ClusterEvent { // Output. Unique Event Id. string id = 1 ; // Output. Human readable name for event. string name = 2 ; // Output. The creation time of the event. google.protobuf.Timestamp created_at = 3 ; // Output. The last time the event occur. google.protobuf.Timestamp first_timestamp = 4 ; // Output. The first time the event occur google.protobuf.Timestamp last_timestamp = 5 ; // Output. The reason for the transition into the object's current status. string reason = 6 ; // Output. A human-readable description of the status of this operation. string message = 7 ; // Output. Type of this event (Normal, Warning), new types could be added in the future string type = 8 ; // Output. The number of times this event has occurred. int32 count = 9 ; } Support multiple clients \u00b6 Since we may have different clients to interactive with our services, we will generate gateway RESTful APIs and OpenAPI Spec at the same time. .proto define core api, grpc and gateway services. go_client and swagger can be generated easily for further usage. gRPC services \u00b6 The GRPC protocol provides an extremely efficient way of cross-service communication for distributed applications. The public toolkit includes instruments to generate client and server code-bases for many languages allowing the developer to use the most optimal language for the task. The service will implement gPRC server as following graph shows. A ResourceManager will be used to abstract the implementation of CRUD operators. ClientManager manages kubernetes clients which can operate Kubernetes native resource and custom resources like RayCluster. RayClusterClient comes from code generator of CRD. issue#29 Implementation History \u00b6 2021-11-25: inital proposal accepted. 2022-12-01: new protobuf definition released. Note: we should update doc when there's a large update.","title":"Core API and Backend Service"},{"location":"design/protobuf-grpc-service/#support-proto-core-api-and-restful-backend-services","text":"","title":"Support proto Core API and RESTful backend services"},{"location":"design/protobuf-grpc-service/#motivation","text":"There're few major blockers for users to use KubeRay Operator directly. Current ray operator is only friendly to users who is familiar with Kubernetes operator pattern. For most data scientists, there's still a learning curve. Using kubectl requires sophisticated permission system. Some kubernetes clusters do not enable user level authentication. In some companies, devops use loose RBAC management and corp SSO system is not integrated with Kubernetes OIDC at all. For the above reasons, it's worth it to build a generic abstraction on top of the RayCluster CRD. With the core API support, we can easily build backend services, cli, etc to bridge users without Kubernetes experience to KubeRay.","title":"Motivation"},{"location":"design/protobuf-grpc-service/#goals","text":"The API definition should be flexible enough to support different kinds of clients (e.g. backend, cli etc). This backend service underneath should leverage generate clients to interact with existing RayCluster custom resources. New added components should be plugable to existing operator.","title":"Goals"},{"location":"design/protobuf-grpc-service/#proposal","text":"","title":"Proposal"},{"location":"design/protobuf-grpc-service/#deployment-topology-and-interactive-flow","text":"The new gRPC service would be a individual deployment of the KubeRay control plane and user can choose to install it optionally. It will create a service and exposes endpoint to users. NAME READY STATUS RESTARTS AGE kuberay-grpc-service-c8db9dc65-d4w5r 1/1 Running 0 2d15h kuberay-operator-785476b948-fmlm7 1/1 Running 0 3d In issue #29 , RayCluster CRD clientset has been generated and gRPC service can leverage it to operate Custom Resources. A simple flow would be like this. (Thanks @akanso for providing the flow) client --> GRPC Server --> [created Custom Resources] <-- Ray Operator (reads CR and accordingly performs CRUD)","title":"Deployment topology and interactive flow"},{"location":"design/protobuf-grpc-service/#api-abstraction","text":"Protocol Buffers are a language-neutral, platform-neutral extensible mechanism for serializing structured data. Protoc also provides different community plugins to meet different needs. In order to better define resources at the API level, a few proto files will be defined. Technically, we can use similar data structure like RayCluster Kubernetes resource but this is probably not a good idea. Some of the Kubernetes API like tolerance and node affinity are too complicated to be converted to an API. We want to leave some flexibility to use database to store history data in the near future (for example, pagination, list options etc). To resolve these issues, we provide a simple API which can cover most common use-cases. For example, the protobuf definition of the RayCluster : service ClusterService { // Creates a new Cluster. rpc CreateCluster ( CreateClusterRequest ) returns ( Cluster ) { option ( google.api.http ) = { post : \"/apis/v1alpha2/namespaces/{namespace}/clusters\" body : \"cluster\" }; } // Finds a specific Cluster by ID. rpc GetCluster ( GetClusterRequest ) returns ( Cluster ) { option ( google.api.http ) = { get : \"/apis/v1alpha2/namespaces/{namespace}/clusters/{name}\" }; } // Finds all Clusters in a given namespace. Supports pagination, and sorting on certain fields. rpc ListCluster ( ListClustersRequest ) returns ( ListClustersResponse ) { option ( google.api.http ) = { get : \"/apis/v1alpha2/namespaces/{namespace}/clusters\" }; } // Finds all Clusters in all namespaces. Supports pagination, and sorting on certain fields. rpc ListAllClusters ( ListAllClustersRequest ) returns ( ListAllClustersResponse ) { option ( google.api.http ) = { get : \"/apis/v1alpha2/clusters\" }; } // Deletes an cluster without deleting the cluster's runs and jobs. To // avoid unexpected behaviors, delete an cluster's runs and jobs before // deleting the cluster. rpc DeleteCluster ( DeleteClusterRequest ) returns ( google.protobuf.Empty ) { option ( google.api.http ) = { delete : \"/apis/v1alpha2/namespaces/{namespace}/clusters/{name}\" }; } } message CreateClusterRequest { // The cluster to be created. Cluster cluster = 1 ; // The namespace of the cluster to be created. string namespace = 2 ; } message GetClusterRequest { // The name of the cluster to be retrieved. string name = 1 ; // The namespace of the cluster to be retrieved. string namespace = 2 ; } message ListClustersRequest { // The namespace of the clusters to be retrieved. string namespace = 1 ; } message ListClustersResponse { // A list of clusters returned. repeated Cluster clusters = 1 ; } message ListAllClustersRequest {} message ListAllClustersResponse { // A list of clusters returned. repeated Cluster clusters = 1 ; } message DeleteClusterRequest { // The name of the cluster to be deleted. string name = 1 ; // The namespace of the cluster to be deleted. string namespace = 2 ; } message Cluster { // Required input field. Unique cluster name provided by user. string name = 1 ; // Required input field. Cluster's namespace provided by user string namespace = 2 ; // Required field. This field indicates the user who owns the cluster. string user = 3 ; // Optional input field. Ray cluster version string version = 4 ; // Optional field. enum Environment { DEV = 0 ; TESTING = 1 ; STAGING = 2 ; PRODUCTION = 3 ; } Environment environment = 5 ; // Required field. This field indicates ray cluster configuration ClusterSpec cluster_spec = 6 ; // Output. The time that the cluster created. google.protobuf.Timestamp created_at = 7 ; // Output. The time that the cluster deleted. google.protobuf.Timestamp deleted_at = 8 ; // Output. The status to show the cluster status.state string cluster_state = 9 ; // Output. The list related to the cluster. repeated ClusterEvent events = 10 ; // Output. The service endpoint of the cluster map < string , string > service_endpoint = 11 ; // Optional input field. Container environment variables from user. map < string , string > envs = 12 ; } message ClusterSpec { // The head group configuration HeadGroupSpec head_group_spec = 1 ; // The worker group configurations repeated WorkerGroupSpec worker_group_spec = 2 ; } message Volume { string mount_path = 1 ; enum VolumeType { PERSISTENT_VOLUME_CLAIM = 0 ; HOST_PATH = 1 ; } VolumeType volume_type = 2 ; string name = 3 ; string source = 4 ; bool read_only = 5 ; // If indicate hostpath, we need to let user indicate which type // they would like to use. enum HostPathType { DIRECTORY = 0 ; FILE = 1 ; } HostPathType host_path_type = 6 ; enum MountPropagationMode { NONE = 0 ; HOSTTOCONTAINER = 1 ; BIDIRECTIONAL = 2 ; } MountPropagationMode mount_propagation_mode = 7 ; } message HeadGroupSpec { // Optional. The computeTemplate of head node group string compute_template = 1 ; // Optional field. This field will be used to retrieve right ray container string image = 2 ; // Optional. The service type (ClusterIP, NodePort, Load balancer) of the head node string service_type = 3 ; // Optional. The ray start params of head node group map < string , string > ray_start_params = 4 ; // Optional. The volumes mount to head pod repeated Volume volumes = 5 ; } message WorkerGroupSpec { // Required. Group name of the current worker group string group_name = 1 ; // Optional. The computeTemplate of head node group string compute_template = 2 ; // Optional field. This field will be used to retrieve right ray container string image = 3 ; // Required. Desired replicas of the worker group int32 replicas = 4 ; // Optional. Min replicas of the worker group int32 min_replicas = 5 ; // Optional. Max replicas of the worker group int32 max_replicas = 6 ; // Optional. The ray start parames of worker node group map < string , string > ray_start_params = 7 ; // Optional. The volumes mount to worker pods repeated Volume volumes = 8 ; } message ClusterEvent { // Output. Unique Event Id. string id = 1 ; // Output. Human readable name for event. string name = 2 ; // Output. The creation time of the event. google.protobuf.Timestamp created_at = 3 ; // Output. The last time the event occur. google.protobuf.Timestamp first_timestamp = 4 ; // Output. The first time the event occur google.protobuf.Timestamp last_timestamp = 5 ; // Output. The reason for the transition into the object's current status. string reason = 6 ; // Output. A human-readable description of the status of this operation. string message = 7 ; // Output. Type of this event (Normal, Warning), new types could be added in the future string type = 8 ; // Output. The number of times this event has occurred. int32 count = 9 ; }","title":"API abstraction"},{"location":"design/protobuf-grpc-service/#support-multiple-clients","text":"Since we may have different clients to interactive with our services, we will generate gateway RESTful APIs and OpenAPI Spec at the same time. .proto define core api, grpc and gateway services. go_client and swagger can be generated easily for further usage.","title":"Support multiple clients"},{"location":"design/protobuf-grpc-service/#grpc-services","text":"The GRPC protocol provides an extremely efficient way of cross-service communication for distributed applications. The public toolkit includes instruments to generate client and server code-bases for many languages allowing the developer to use the most optimal language for the task. The service will implement gPRC server as following graph shows. A ResourceManager will be used to abstract the implementation of CRUD operators. ClientManager manages kubernetes clients which can operate Kubernetes native resource and custom resources like RayCluster. RayClusterClient comes from code generator of CRD. issue#29","title":"gRPC services"},{"location":"design/protobuf-grpc-service/#implementation-history","text":"2021-11-25: inital proposal accepted. 2022-12-01: new protobuf definition released. Note: we should update doc when there's a large update.","title":"Implementation History"},{"location":"development/development/","text":"KubeRay Development Guidance \u00b6 Develop KubeRay Operator \u00b6 See ray-operator/DEVELOPMENT.md for more details. Develop KubeRay APIServer \u00b6 See apiserver/DEVELOPMENT.md for more details. Develop KubeRay CLI \u00b6 See cli/README.md for more details. Develop proto and OpenAPI \u00b6 See proto/README.md for more details. Deploy Docs locally \u00b6 Run the following command in the root directory of your KubeRay repo to deploy Docs locally: docker run --rm -it -p 8000 :8000 -v ${ PWD } :/docs squidfunk/mkdocs-material Then access http://0.0.0.0:8000/kuberay/ in your web browser.","title":"Development"},{"location":"development/development/#kuberay-development-guidance","text":"","title":"KubeRay Development Guidance"},{"location":"development/development/#develop-kuberay-operator","text":"See ray-operator/DEVELOPMENT.md for more details.","title":"Develop KubeRay Operator"},{"location":"development/development/#develop-kuberay-apiserver","text":"See apiserver/DEVELOPMENT.md for more details.","title":"Develop KubeRay APIServer"},{"location":"development/development/#develop-kuberay-cli","text":"See cli/README.md for more details.","title":"Develop KubeRay CLI"},{"location":"development/development/#develop-proto-and-openapi","text":"See proto/README.md for more details.","title":"Develop proto and OpenAPI"},{"location":"development/development/#deploy-docs-locally","text":"Run the following command in the root directory of your KubeRay repo to deploy Docs locally: docker run --rm -it -p 8000 :8000 -v ${ PWD } :/docs squidfunk/mkdocs-material Then access http://0.0.0.0:8000/kuberay/ in your web browser.","title":"Deploy Docs locally"},{"location":"development/release/","text":"KubeRay Release Process \u00b6 Prerequisite \u00b6 Github Write permissions to cut a release tag/branch. Dockerhub Write permissions to push images with pinned tag. Release Process \u00b6 Make sure the last commit you want to release past Go-build-and-test workflow. Check out that commit (in this example, we'll use 6214e560 ). Depends on what version you want to release, Major or Minor version - Use the GitHub UI to cut a release branch and name the release branch v{MAJOR}.${MINOR}-branch Patch version - You don't need to cut release branch on patch version. Tag the image version from kuberay/operator:6214e560 to kuberay/operator:v0.2.0 and push to dockerhub. docker tag kuberay/operator:6214e560 kuberay/operator:v0.2.0 docker push kuberay/operator:v0.2.0 docker tag kuberay/apiserver:6214e560 kuberay/apiserver:v0.2.0 docker push kuberay/apiserver:v0.2.0 Build CLI with multi arch support and they will be uploaded as release artifacts in later step. Create a new PR against the release branch to change container image in manifest to point to that commit hash. images: - name: kuberay/operator newName: kuberay/operator newTag: v0.2.0 ... note: post submit job will always build a new image using the PULL_BASE_HASH as image tag. Create a tag and push tag to upstream. git tag v0.2.0 git push upstream v0.2.0 Run following code and fetch online git commits from last release (v0.1.0) to current release (v0.2.0). git log v0.1.0..v0.2.0 --oneline Generate release notes and update Github release. See v0.1.0 example here . Please also upload CLI binaries. Send a PR to update CHANGELOG.md","title":"Release"},{"location":"development/release/#kuberay-release-process","text":"","title":"KubeRay Release Process"},{"location":"development/release/#prerequisite","text":"Github Write permissions to cut a release tag/branch. Dockerhub Write permissions to push images with pinned tag.","title":"Prerequisite"},{"location":"development/release/#release-process","text":"Make sure the last commit you want to release past Go-build-and-test workflow. Check out that commit (in this example, we'll use 6214e560 ). Depends on what version you want to release, Major or Minor version - Use the GitHub UI to cut a release branch and name the release branch v{MAJOR}.${MINOR}-branch Patch version - You don't need to cut release branch on patch version. Tag the image version from kuberay/operator:6214e560 to kuberay/operator:v0.2.0 and push to dockerhub. docker tag kuberay/operator:6214e560 kuberay/operator:v0.2.0 docker push kuberay/operator:v0.2.0 docker tag kuberay/apiserver:6214e560 kuberay/apiserver:v0.2.0 docker push kuberay/apiserver:v0.2.0 Build CLI with multi arch support and they will be uploaded as release artifacts in later step. Create a new PR against the release branch to change container image in manifest to point to that commit hash. images: - name: kuberay/operator newName: kuberay/operator newTag: v0.2.0 ... note: post submit job will always build a new image using the PULL_BASE_HASH as image tag. Create a tag and push tag to upstream. git tag v0.2.0 git push upstream v0.2.0 Run following code and fetch online git commits from last release (v0.1.0) to current release (v0.2.0). git log v0.1.0..v0.2.0 --oneline Generate release notes and update Github release. See v0.1.0 example here . Please also upload CLI binaries. Send a PR to update CHANGELOG.md","title":"Release Process"},{"location":"guidance/autoscaler/","text":"Autoscaler (beta) \u00b6 Ray Autoscaler integration is beta since KubeRay 0.3.0 and Ray 2.0.0. While autoscaling functionality is stable, the details of autoscaler behavior and configuration may change in future releases. See the official Ray documentation for even more information about Ray autoscaling on Kubernetes. Prerequisite \u00b6 Start by deploying the latest stable version of the KubeRay operator: kubectl create -k \"github.com/ray-project/kuberay/ray-operator/config/default?ref=v0.3.0&timeout=90s\" Deploy a cluster with autoscaling enabled \u00b6 Next, to deploy a sample autoscaling Ray cluster, run kubectl apply -f https://raw.githubusercontent.com/ray-project/kuberay/release-0.3/ray-operator/config/samples/ray-cluster.autoscaler.yaml See the above config file for details on autoscaling configuration. Note Ray container resource requests and limits in the example configuration above are too small to be used in production. For typical use-cases, you should use large Ray pods. If possible, each Ray pod should be sized to take up its entire K8s node. We don't recommend allocating less than 8 gigabytes of memory for Ray containers running in production. For an autoscaling configuration more suitable for production, see ray-cluster.autoscaler.large.yaml . The output of kubectl get pods should indicate the presence of a Ray head pod with two containers, the Ray container and the autoscaler container. You should also see a Ray worker pod with a single Ray container. $ kubectl get pods NAME READY STATUS RESTARTS AGE raycluster-autoscaler-head-mgwwk 2/2 Running 0 4m41s raycluster-autoscaler-worker-small-group-fg4fv 1/1 Running 0 4m41s Check the autoscaler container's logs to confirm that the autoscaler is healthy. Here's an example of logs from a healthy autoscaler. kubectl logs -f raycluster-autoscaler-head-mgwwk autoscaler 2022-03-10 07:51:22,616 INFO monitor.py:226 -- Starting autoscaler metrics server on port 44217 2022-03-10 07:51:22,621 INFO monitor.py:243 -- Monitor: Started 2022-03-10 07:51:22,824 INFO node_provider.py:143 -- Creating KuberayNodeProvider. 2022-03-10 07:51:22,825 INFO autoscaler.py:282 -- StandardAutoscaler: {'provider': {'type': 'kuberay', 'namespace': 'default', 'disable_node_updaters': True, 'disable_launch_config_check': True}, 'cluster_name': 'raycluster-autoscaler', 'head_node_type': 'head-group', 'available_node_types': {'head-group': {'min_workers': 0, 'max_workers': 0, 'node_config': {}, 'resources': {'CPU': 1}}, 'small-group': {'min_workers': 1, 'max_workers': 300, 'node_config': {}, 'resources': {'CPU': 1}}}, 'max_workers': 300, 'idle_timeout_minutes': 5, 'upscaling_speed': 1, 'file_mounts': {}, 'cluster_synced_files': [], 'file_mounts_sync_continuously': False, 'initialization_commands': [], 'setup_commands': [], 'head_setup_commands': [], 'worker_setup_commands': [], 'head_start_ray_commands': [], 'worker_start_ray_commands': [], 'auth': {}, 'head_node': {}, 'worker_nodes': {}} 2022-03-10 07:51:23,027 INFO autoscaler.py:327 -- ======== Autoscaler status: 2022-03-10 07:51:23.027271 ======== Node status --------------------------------------------------------------- Healthy: 1 head-group Pending: (no pending nodes) Recent failures: (no failures) Resources --------------------------------------------------------------- Usage: 0.0/1.0 CPU 0.00/0.931 GiB memory 0.00/0.200 GiB object_store_memory Demands: (no resource demands) Notes \u00b6 To enable autoscaling, set your RayCluster CR's spec.enableInTreeAutoscaling field to true. The operator will then automatically inject a preconfigured autoscaler container to the head pod. The service account, role, and role binding needed by the autoscaler will be created by the operator out-of-box. The operator will also configure an empty-dir logging volume for the Ray head pod. The volume will be mounted into the Ray and autoscaler containers; this is necessary to support the event logging introduced in Ray PR #13434 . spec: enableInTreeAutoscaling: true If your RayCluster CR's spec.rayVersion field is at least 2.0.0 , the autoscaler container will use the same image as the Ray container. For Ray versions older than 2.0.0, the image rayproject/ray:2.0.0 will be used to run the autoscaler. Autoscaling functionality is supported only with Ray versions at least as new as 1.11.0. Autoscaler support is beta as of Ray 2.0.0 and KubeRay 0.3.0; while autoscaling functionality is stable, the details of autoscaler behavior and configuration may change in future releases. Test autoscaling \u00b6 Let's now try out the autoscaler. We can run the following command to get a Python interpreter in the head pod: kubectl exec `kubectl get pods -o custom-columns=POD:metadata.name | grep raycluster-autoscaler-head` -it -c ray-head -- python In the Python interpreter, run the following snippet to scale up the cluster: import ray ray.init() ray.autoscaler.sdk.request_resources(num_cpus=4) You should then see two extra Ray nodes (pods) scale up to satisfy the 4 CPU demand. $ kubectl get pods NAME READY STATUS RESTARTS AGE raycluster-autoscaler-head-mgwwk 2/2 Running 0 4m41s raycluster-autoscaler-worker-small-group-4d255 1/1 Running 0 40s raycluster-autoscaler-worker-small-group-fg4fv 1/1 Running 0 4m41s raycluster-autoscaler-worker-small-group-qzhvg 1/1 Running 0 40s","title":"Autoscaling"},{"location":"guidance/autoscaler/#autoscaler-beta","text":"Ray Autoscaler integration is beta since KubeRay 0.3.0 and Ray 2.0.0. While autoscaling functionality is stable, the details of autoscaler behavior and configuration may change in future releases. See the official Ray documentation for even more information about Ray autoscaling on Kubernetes.","title":"Autoscaler (beta)"},{"location":"guidance/autoscaler/#prerequisite","text":"Start by deploying the latest stable version of the KubeRay operator: kubectl create -k \"github.com/ray-project/kuberay/ray-operator/config/default?ref=v0.3.0&timeout=90s\"","title":"Prerequisite"},{"location":"guidance/autoscaler/#deploy-a-cluster-with-autoscaling-enabled","text":"Next, to deploy a sample autoscaling Ray cluster, run kubectl apply -f https://raw.githubusercontent.com/ray-project/kuberay/release-0.3/ray-operator/config/samples/ray-cluster.autoscaler.yaml See the above config file for details on autoscaling configuration. Note Ray container resource requests and limits in the example configuration above are too small to be used in production. For typical use-cases, you should use large Ray pods. If possible, each Ray pod should be sized to take up its entire K8s node. We don't recommend allocating less than 8 gigabytes of memory for Ray containers running in production. For an autoscaling configuration more suitable for production, see ray-cluster.autoscaler.large.yaml . The output of kubectl get pods should indicate the presence of a Ray head pod with two containers, the Ray container and the autoscaler container. You should also see a Ray worker pod with a single Ray container. $ kubectl get pods NAME READY STATUS RESTARTS AGE raycluster-autoscaler-head-mgwwk 2/2 Running 0 4m41s raycluster-autoscaler-worker-small-group-fg4fv 1/1 Running 0 4m41s Check the autoscaler container's logs to confirm that the autoscaler is healthy. Here's an example of logs from a healthy autoscaler. kubectl logs -f raycluster-autoscaler-head-mgwwk autoscaler 2022-03-10 07:51:22,616 INFO monitor.py:226 -- Starting autoscaler metrics server on port 44217 2022-03-10 07:51:22,621 INFO monitor.py:243 -- Monitor: Started 2022-03-10 07:51:22,824 INFO node_provider.py:143 -- Creating KuberayNodeProvider. 2022-03-10 07:51:22,825 INFO autoscaler.py:282 -- StandardAutoscaler: {'provider': {'type': 'kuberay', 'namespace': 'default', 'disable_node_updaters': True, 'disable_launch_config_check': True}, 'cluster_name': 'raycluster-autoscaler', 'head_node_type': 'head-group', 'available_node_types': {'head-group': {'min_workers': 0, 'max_workers': 0, 'node_config': {}, 'resources': {'CPU': 1}}, 'small-group': {'min_workers': 1, 'max_workers': 300, 'node_config': {}, 'resources': {'CPU': 1}}}, 'max_workers': 300, 'idle_timeout_minutes': 5, 'upscaling_speed': 1, 'file_mounts': {}, 'cluster_synced_files': [], 'file_mounts_sync_continuously': False, 'initialization_commands': [], 'setup_commands': [], 'head_setup_commands': [], 'worker_setup_commands': [], 'head_start_ray_commands': [], 'worker_start_ray_commands': [], 'auth': {}, 'head_node': {}, 'worker_nodes': {}} 2022-03-10 07:51:23,027 INFO autoscaler.py:327 -- ======== Autoscaler status: 2022-03-10 07:51:23.027271 ======== Node status --------------------------------------------------------------- Healthy: 1 head-group Pending: (no pending nodes) Recent failures: (no failures) Resources --------------------------------------------------------------- Usage: 0.0/1.0 CPU 0.00/0.931 GiB memory 0.00/0.200 GiB object_store_memory Demands: (no resource demands)","title":"Deploy a cluster with autoscaling enabled"},{"location":"guidance/autoscaler/#notes","text":"To enable autoscaling, set your RayCluster CR's spec.enableInTreeAutoscaling field to true. The operator will then automatically inject a preconfigured autoscaler container to the head pod. The service account, role, and role binding needed by the autoscaler will be created by the operator out-of-box. The operator will also configure an empty-dir logging volume for the Ray head pod. The volume will be mounted into the Ray and autoscaler containers; this is necessary to support the event logging introduced in Ray PR #13434 . spec: enableInTreeAutoscaling: true If your RayCluster CR's spec.rayVersion field is at least 2.0.0 , the autoscaler container will use the same image as the Ray container. For Ray versions older than 2.0.0, the image rayproject/ray:2.0.0 will be used to run the autoscaler. Autoscaling functionality is supported only with Ray versions at least as new as 1.11.0. Autoscaler support is beta as of Ray 2.0.0 and KubeRay 0.3.0; while autoscaling functionality is stable, the details of autoscaler behavior and configuration may change in future releases.","title":"Notes"},{"location":"guidance/autoscaler/#test-autoscaling","text":"Let's now try out the autoscaler. We can run the following command to get a Python interpreter in the head pod: kubectl exec `kubectl get pods -o custom-columns=POD:metadata.name | grep raycluster-autoscaler-head` -it -c ray-head -- python In the Python interpreter, run the following snippet to scale up the cluster: import ray ray.init() ray.autoscaler.sdk.request_resources(num_cpus=4) You should then see two extra Ray nodes (pods) scale up to satisfy the 4 CPU demand. $ kubectl get pods NAME READY STATUS RESTARTS AGE raycluster-autoscaler-head-mgwwk 2/2 Running 0 4m41s raycluster-autoscaler-worker-small-group-4d255 1/1 Running 0 40s raycluster-autoscaler-worker-small-group-fg4fv 1/1 Running 0 4m41s raycluster-autoscaler-worker-small-group-qzhvg 1/1 Running 0 40s","title":"Test autoscaling"},{"location":"guidance/gcs-ft/","text":"Ray GCS Fault Tolerance (GCS FT) (Alpha Release) \u00b6 Note: This feature is alpha. Ray GCS FT enables GCS server to use external storage backend. As a result, Ray clusters can tolerant GCS failures and recover from failures without affecting important services such as detached Actors & RayServe deployments. Prerequisite \u00b6 Ray 2.0 is required. You need to support external Redis server for Ray. (Redis HA cluster is highly recommended.) Enable Ray GCS FT \u00b6 To enable Ray GCS FT in your newly KubeRay-managed Ray cluster, you need to enable it by adding an annotation to the RayCluster YAML file. ... kind : RayCluster metadata : annotations : ray.io/ft-enabled : \"true\" # <- add this annotation enable GCS FT ray.io/external-storage-namespace : \"my-raycluster-storage-namespace\" # <- optional, to specify the external storage namespace ... An example can be found at ray-cluster.external-redis.yaml When annotation ray.io/ft-enabled is added with a true value, KubeRay will enable Ray GCS FT feature. This feature contains several components: Newly created Ray cluster has Readiness Probe and Liveness Probe added to all the head/worker nodes. KubeRay Operator controller watches for Event object changes which can notify in case of readiness probe failures and mark them as Unhealthy . KubeRay Operator controller kills and recreate any Unhealthy Ray head/worker node. Implementation Details \u00b6 Readiness Probe vs Liveness Probe \u00b6 These are the two types of probes we used in Ray GCS FT. The readiness probe is used to notify KubeRay in case of failures in the corresponding Ray cluster. KubeRay can try its best to recover the Ray cluster. If KubeRay cannot recover the failed head/worker node, the liveness probe gets in, delete the old pod and create a new pod. By default, the liveness probe gets involved later than the readiness probe. The liveness probe is our last resort to recover the Ray cluster. However, in our current implementation, for the readiness probe failures, we also kill & recreate the corresponding pod that runs head/worker node. Currently, the readiness probe and the liveness probe are using the same command to do the work. In the future, we may run different commands for the readiness probe and the liveness probe. On Ray head node, we access a local Ray dashboard http endpoint and a Raylet http endpoint to make sure this head node is in healthy state. Since Ray dashboard does not reside Ray worker node, we only check the local Raylet http endpoint to make sure the worker node is healthy. Ray GCS FT Annotation \u00b6 Our Ray GCS FT feature checks if an annotation called ray.io/ft-enabled is set to true in RayCluster YAML file. If so, KubeRay will also add such annotation to the pod whenever the head/worker node is created. Use External Redis Cluster \u00b6 To use external Redis cluster as the backend storage(required by Ray GCS FT), you need to add RAY_REDIS_ADDRESS environment variable to the head node template. Also, you can specify a storage namespace for your Ray cluster by using an annotation ray.io/external-storage-namespace An example can be found at ray-cluster.external-redis.yaml To use SSL/TLS in the connection, you add rediss:// as the prefix of the redis address instead of the redis:// prefix. This feature is only available in Ray 2.2 and above. You can also specify additional environment variables in the head pod to customize the SSL configuration: RAY_REDIS_CA_CERT The location of the CA certificate (optional) RAY_REDIS_CA_PATH Path of trusted certificates (optional) RAY_REDIS_CLIENT_CERT File name of client certificate file (optional) RAY_REDIS_CLIENT_KEY File name of client private key (optional) RAY_REDIS_SERVER_NAME Server name to request (SNI) (optional) KubeRay Operator Controller \u00b6 KubeRay Operator controller watches for new Event reconcile call. If this Event object is to notify the failed readiness probe, controller checks if this pod has ray.io/ft-enabled set to true . If this pod has this annotation set to true, that means this pod belongs to a Ray cluster that has Ray GCS FT enabled. After this, the controller will try to recover the failed pod. If controller cannot recover it, an annotation named ray.io/health-state with a value Unhealthy is added to this pod. In every KubeRay Operator controller reconcile loop, it monitors any pod in Ray cluster that has Unhealthy value in annotation ray.io/health-state . If any pod is found, this pod is deleted and gets recreated. External Storage Namespace \u00b6 External storage namespaces can be used to share a single storage backend among multiple Ray clusters. By default, ray.io/external-storage-namespace uses the RayCluster UID as its value when GCS FT is enabled. Or if the user wants to use customized external storage namespace, the user can add ray.io/external-storage-namespace annotation to RayCluster yaml file. Whenever ray.io/external-storage-namespace annotation is set, the head/worker node will have RAY_external_storage_namespace environment variable set which Ray can pick up later. Known issues and limitations \u00b6 For now, Ray head/worker node that fails the readiness probe recovers itself by restarting itself. More fine-grained control and recovery mechanisms are expected in the future. Test Ray GCS FT \u00b6 Currently, two tests are responsible for ensuring Ray GCS FT is working correctly. Detached actor test RayServe test In detached actor test, a detached actor is created at first. Then, the head node is killed. KubeRay brings back another head node replacement pod. However, the detached actor is still expected to be available. (Note: the client that creates the detached actor does not exist and will retry in case of Ray cluster returns failure) In RayServe test, a simple RayServe app is deployed on the Ray cluster. In case of GCS server crash, the RayServe app continues to be accessible after the head node recovery.","title":"Ray GCS FT"},{"location":"guidance/gcs-ft/#ray-gcs-fault-tolerance-gcs-ft-alpha-release","text":"Note: This feature is alpha. Ray GCS FT enables GCS server to use external storage backend. As a result, Ray clusters can tolerant GCS failures and recover from failures without affecting important services such as detached Actors & RayServe deployments.","title":"Ray GCS Fault Tolerance (GCS FT) (Alpha Release)"},{"location":"guidance/gcs-ft/#prerequisite","text":"Ray 2.0 is required. You need to support external Redis server for Ray. (Redis HA cluster is highly recommended.)","title":"Prerequisite"},{"location":"guidance/gcs-ft/#enable-ray-gcs-ft","text":"To enable Ray GCS FT in your newly KubeRay-managed Ray cluster, you need to enable it by adding an annotation to the RayCluster YAML file. ... kind : RayCluster metadata : annotations : ray.io/ft-enabled : \"true\" # <- add this annotation enable GCS FT ray.io/external-storage-namespace : \"my-raycluster-storage-namespace\" # <- optional, to specify the external storage namespace ... An example can be found at ray-cluster.external-redis.yaml When annotation ray.io/ft-enabled is added with a true value, KubeRay will enable Ray GCS FT feature. This feature contains several components: Newly created Ray cluster has Readiness Probe and Liveness Probe added to all the head/worker nodes. KubeRay Operator controller watches for Event object changes which can notify in case of readiness probe failures and mark them as Unhealthy . KubeRay Operator controller kills and recreate any Unhealthy Ray head/worker node.","title":"Enable Ray GCS FT"},{"location":"guidance/gcs-ft/#implementation-details","text":"","title":"Implementation Details"},{"location":"guidance/gcs-ft/#readiness-probe-vs-liveness-probe","text":"These are the two types of probes we used in Ray GCS FT. The readiness probe is used to notify KubeRay in case of failures in the corresponding Ray cluster. KubeRay can try its best to recover the Ray cluster. If KubeRay cannot recover the failed head/worker node, the liveness probe gets in, delete the old pod and create a new pod. By default, the liveness probe gets involved later than the readiness probe. The liveness probe is our last resort to recover the Ray cluster. However, in our current implementation, for the readiness probe failures, we also kill & recreate the corresponding pod that runs head/worker node. Currently, the readiness probe and the liveness probe are using the same command to do the work. In the future, we may run different commands for the readiness probe and the liveness probe. On Ray head node, we access a local Ray dashboard http endpoint and a Raylet http endpoint to make sure this head node is in healthy state. Since Ray dashboard does not reside Ray worker node, we only check the local Raylet http endpoint to make sure the worker node is healthy.","title":"Readiness Probe vs Liveness Probe"},{"location":"guidance/gcs-ft/#ray-gcs-ft-annotation","text":"Our Ray GCS FT feature checks if an annotation called ray.io/ft-enabled is set to true in RayCluster YAML file. If so, KubeRay will also add such annotation to the pod whenever the head/worker node is created.","title":"Ray GCS FT Annotation"},{"location":"guidance/gcs-ft/#use-external-redis-cluster","text":"To use external Redis cluster as the backend storage(required by Ray GCS FT), you need to add RAY_REDIS_ADDRESS environment variable to the head node template. Also, you can specify a storage namespace for your Ray cluster by using an annotation ray.io/external-storage-namespace An example can be found at ray-cluster.external-redis.yaml To use SSL/TLS in the connection, you add rediss:// as the prefix of the redis address instead of the redis:// prefix. This feature is only available in Ray 2.2 and above. You can also specify additional environment variables in the head pod to customize the SSL configuration: RAY_REDIS_CA_CERT The location of the CA certificate (optional) RAY_REDIS_CA_PATH Path of trusted certificates (optional) RAY_REDIS_CLIENT_CERT File name of client certificate file (optional) RAY_REDIS_CLIENT_KEY File name of client private key (optional) RAY_REDIS_SERVER_NAME Server name to request (SNI) (optional)","title":"Use External Redis Cluster"},{"location":"guidance/gcs-ft/#kuberay-operator-controller","text":"KubeRay Operator controller watches for new Event reconcile call. If this Event object is to notify the failed readiness probe, controller checks if this pod has ray.io/ft-enabled set to true . If this pod has this annotation set to true, that means this pod belongs to a Ray cluster that has Ray GCS FT enabled. After this, the controller will try to recover the failed pod. If controller cannot recover it, an annotation named ray.io/health-state with a value Unhealthy is added to this pod. In every KubeRay Operator controller reconcile loop, it monitors any pod in Ray cluster that has Unhealthy value in annotation ray.io/health-state . If any pod is found, this pod is deleted and gets recreated.","title":"KubeRay Operator Controller"},{"location":"guidance/gcs-ft/#external-storage-namespace","text":"External storage namespaces can be used to share a single storage backend among multiple Ray clusters. By default, ray.io/external-storage-namespace uses the RayCluster UID as its value when GCS FT is enabled. Or if the user wants to use customized external storage namespace, the user can add ray.io/external-storage-namespace annotation to RayCluster yaml file. Whenever ray.io/external-storage-namespace annotation is set, the head/worker node will have RAY_external_storage_namespace environment variable set which Ray can pick up later.","title":"External Storage Namespace"},{"location":"guidance/gcs-ft/#known-issues-and-limitations","text":"For now, Ray head/worker node that fails the readiness probe recovers itself by restarting itself. More fine-grained control and recovery mechanisms are expected in the future.","title":"Known issues and limitations"},{"location":"guidance/gcs-ft/#test-ray-gcs-ft","text":"Currently, two tests are responsible for ensuring Ray GCS FT is working correctly. Detached actor test RayServe test In detached actor test, a detached actor is created at first. Then, the head node is killed. KubeRay brings back another head node replacement pod. However, the detached actor is still expected to be available. (Note: the client that creates the detached actor does not exist and will retry in case of Ray cluster returns failure) In RayServe test, a simple RayServe app is deployed on the Ray cluster. In case of GCS server crash, the RayServe app continues to be accessible after the head node recovery.","title":"Test Ray GCS FT"},{"location":"guidance/ingress/","text":"Ingress Usage \u00b6 KubeRay built-in ingress support: KubeRay will help users create a Kubernetes ingress when spec.headGroupSpec.enableIngress: true . Currently, the built-in support only supports simple NGINX setups. Note that users still need to install ingress controller by themselves. We do not recommend using built-in ingress support in a production environment with complex routing requirements. Example: NGINX Ingress on KinD (built-in ingress support) Manually setting up an ingress for KubeRay: For production use-cases, we recommend taking this route. Example: AWS Application Load Balancer (ALB) Ingress support on AWS EKS Example: Manually setting up NGINX Ingress on KinD Prerequisite \u00b6 It's user's responsibility to install ingress controller by themselves. In order to pass through the customized ingress configuration, you can annotate RayCluster object and the controller will pass the annotations to the ingress object. Example: NGINX Ingress on KinD (built-in ingress support) \u00b6 # Step 1: Create a KinD cluster with `extraPortMappings` and `node-labels` cat <<EOF | kind create cluster --config=- kind: Cluster apiVersion: kind.x-k8s.io/v1alpha4 nodes: - role: control-plane kubeadmConfigPatches: - | kind: InitConfiguration nodeRegistration: kubeletExtraArgs: node-labels: \"ingress-ready=true\" extraPortMappings: - containerPort: 80 hostPort: 80 protocol: TCP - containerPort: 443 hostPort: 443 protocol: TCP EOF # Step 2: Install NGINX ingress controller kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/kind/deploy.yaml kubectl wait --namespace ingress-nginx \\ --for = condition = ready pod \\ --selector = app.kubernetes.io/component = controller \\ --timeout = 90s # Step 3: Install KubeRay operator pushd helm-chart/kuberay-operator helm install kuberay-operator . # Step 4: Install RayCluster with NGINX ingress. See https://github.com/ray-project/kuberay/pull/646 # for the explanations of `ray-cluster.ingress.yaml`. Some fields are worth to discuss further: # # (1) metadata.annotations.kubernetes.io/ingress.class: nginx => required # (2) spec.headGroupSpec.enableIngress: true => required # (3) metadata.annotations.nginx.ingress.kubernetes.io/rewrite-target: /$1 => required for NGINX. popd kubectl apply -f ray-operator/config/samples/ray-cluster.ingress.yaml # Step 5: Check ingress created by Step 4. kubectl describe ingress raycluster-ingress-head-ingress # [Example] # ... # Rules: # Host Path Backends # ---- ---- -------- # * # /raycluster-ingress/(.*) raycluster-ingress-head-svc:8265 (10.244.0.11:8265) # Annotations: nginx.ingress.kubernetes.io/rewrite-target: /$1 # Step 6: Check `<ip>/raycluster-ingress/` on your browser. You will see the Ray Dashboard. # [Note] The forward slash at the end of the address is necessary. `<ip>/raycluster-ingress` # will report \"404 Not Found\". Example: AWS Application Load Balancer (ALB) Ingress support on AWS EKS \u00b6 Prerequisite \u00b6 Follow the document Getting started with Amazon EKS \u2013 AWS Management Console and AWS CLI to create an EKS cluster. Follow the installation instructions to set up the AWS Load Balancer controller . Note that the repository maintains a webpage for each release. Please make sure you use the latest installation instructions. (Optional) Try echo server example in the aws-load-balancer-controller repository. (Optional) Read how-it-works.md to understand the mechanism of aws-load-balancer-controller . Instructions \u00b6 # Step 1: Install KubeRay operator and CRD pushd helm-chart/kuberay-operator/ helm install kuberay-operator . popd # Step 2: Install a RayCluster pushd helm-chart/ray-cluster helm install ray-cluster . popd # Step 3: Edit the `ray-operator/config/samples/ray-cluster-alb-ingress.yaml` # # (1) Annotation `alb.ingress.kubernetes.io/subnets` # 1. Please include at least two subnets. # 2. One Availability Zone (ex: us-west-2a) can only have at most 1 subnet. # 3. In this example, you need to select public subnets (subnets that \"Auto-assign public IPv4 address\" is Yes on AWS dashboard) # # (2) Set the name of head pod service to `spec...backend.service.name` eksctl get cluster ${ YOUR_EKS_CLUSTER } # Check subnets on the EKS cluster # Step 4: Create an ALB ingress. When an ingress with proper annotations creates, # AWS Load Balancer controller will reconcile a ALB (not in AWS EKS cluster). kubectl apply -f ray-operator/config/samples/alb-ingress.yaml # Step 5: Check ingress created by Step 4. kubectl describe ingress ray-cluster-ingress # [Example] # Name: ray-cluster-ingress # Labels: <none> # Namespace: default # Address: k8s-default-rayclust-....${REGION_CODE}.elb.amazonaws.com # Default backend: default-http-backend:80 (<error: endpoints \"default-http-backend\" not found>) # Rules: # Host Path Backends # ---- ---- -------- # * # / ray-cluster-kuberay-head-svc:8265 (192.168.185.157:8265) # Annotations: alb.ingress.kubernetes.io/scheme: internet-facing # alb.ingress.kubernetes.io/subnets: ${SUBNET_1},${SUBNET_2} # alb.ingress.kubernetes.io/tags: Environment=dev,Team=test # alb.ingress.kubernetes.io/target-type: ip # Events: # Type Reason Age From Message # ---- ------ ---- ---- ------- # Normal SuccessfullyReconciled 39m ingress Successfully reconciled # Step 6: Check ALB on AWS (EC2 -> Load Balancing -> Load Balancers) # The name of the ALB should be like \"k8s-default-rayclust-......\". # Step 7: Check Ray Dashboard by ALB DNS Name. The name of the DNS Name should be like # \"k8s-default-rayclust-.....us-west-2.elb.amazonaws.com\" # Step 8: Delete the ingress, and AWS Load Balancer controller will remove ALB. # Check ALB on AWS to make sure it is removed. kubectl delete ingress ray-cluster-ingress Example: Manually setting up NGINX Ingress on KinD \u00b6 # Step 1: Create a KinD cluster with `extraPortMappings` and `node-labels` # Reference for the setting up of kind cluster: https://kind.sigs.k8s.io/docs/user/ingress/ cat <<EOF | kind create cluster --config=- kind: Cluster apiVersion: kind.x-k8s.io/v1alpha4 nodes: - role: control-plane kubeadmConfigPatches: - | kind: InitConfiguration nodeRegistration: kubeletExtraArgs: node-labels: \"ingress-ready=true\" extraPortMappings: - containerPort: 80 hostPort: 80 protocol: TCP - containerPort: 443 hostPort: 443 protocol: TCP EOF # Step 2: Install NGINX ingress controller kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/kind/deploy.yaml kubectl wait --namespace ingress-nginx \\ --for = condition = ready pod \\ --selector = app.kubernetes.io/component = controller \\ --timeout = 90s # Step 3: Install KubeRay operator pushd helm-chart/kuberay-operator helm install kuberay-operator . popd # Step 4: Install RayCluster and create an ingress separately. # If you want to change ingress settings, you can edit the ingress portion in # `ray-operator/config/samples/ray-cluster.separate-ingress.yaml`. # More information about change of setting was documented in https://github.com/ray-project/kuberay/pull/699 # and `ray-operator/config/samples/ray-cluster.separate-ingress.yaml` kubectl apply -f ray-operator/config/samples/ray-cluster.separate-ingress.yaml # Step 5: Check the ingress created in Step 4. kubectl describe ingress raycluster-ingress-head-ingress # [Example] # ... # Rules: # Host Path Backends # ---- ---- -------- # * # /raycluster-ingress/(.*) raycluster-ingress-head-svc:8265 (10.244.0.11:8265) # Annotations: nginx.ingress.kubernetes.io/rewrite-target: /$1 # Step 6: Check `<ip>/raycluster-ingress/` on your browser. You will see the Ray Dashboard. # [Note] The forward slash at the end of the address is necessary. `<ip>/raycluster-ingress` # will report \"404 Not Found\".","title":"Ingress"},{"location":"guidance/ingress/#ingress-usage","text":"KubeRay built-in ingress support: KubeRay will help users create a Kubernetes ingress when spec.headGroupSpec.enableIngress: true . Currently, the built-in support only supports simple NGINX setups. Note that users still need to install ingress controller by themselves. We do not recommend using built-in ingress support in a production environment with complex routing requirements. Example: NGINX Ingress on KinD (built-in ingress support) Manually setting up an ingress for KubeRay: For production use-cases, we recommend taking this route. Example: AWS Application Load Balancer (ALB) Ingress support on AWS EKS Example: Manually setting up NGINX Ingress on KinD","title":"Ingress Usage"},{"location":"guidance/ingress/#prerequisite","text":"It's user's responsibility to install ingress controller by themselves. In order to pass through the customized ingress configuration, you can annotate RayCluster object and the controller will pass the annotations to the ingress object.","title":"Prerequisite"},{"location":"guidance/ingress/#example-nginx-ingress-on-kind-built-in-ingress-support","text":"# Step 1: Create a KinD cluster with `extraPortMappings` and `node-labels` cat <<EOF | kind create cluster --config=- kind: Cluster apiVersion: kind.x-k8s.io/v1alpha4 nodes: - role: control-plane kubeadmConfigPatches: - | kind: InitConfiguration nodeRegistration: kubeletExtraArgs: node-labels: \"ingress-ready=true\" extraPortMappings: - containerPort: 80 hostPort: 80 protocol: TCP - containerPort: 443 hostPort: 443 protocol: TCP EOF # Step 2: Install NGINX ingress controller kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/kind/deploy.yaml kubectl wait --namespace ingress-nginx \\ --for = condition = ready pod \\ --selector = app.kubernetes.io/component = controller \\ --timeout = 90s # Step 3: Install KubeRay operator pushd helm-chart/kuberay-operator helm install kuberay-operator . # Step 4: Install RayCluster with NGINX ingress. See https://github.com/ray-project/kuberay/pull/646 # for the explanations of `ray-cluster.ingress.yaml`. Some fields are worth to discuss further: # # (1) metadata.annotations.kubernetes.io/ingress.class: nginx => required # (2) spec.headGroupSpec.enableIngress: true => required # (3) metadata.annotations.nginx.ingress.kubernetes.io/rewrite-target: /$1 => required for NGINX. popd kubectl apply -f ray-operator/config/samples/ray-cluster.ingress.yaml # Step 5: Check ingress created by Step 4. kubectl describe ingress raycluster-ingress-head-ingress # [Example] # ... # Rules: # Host Path Backends # ---- ---- -------- # * # /raycluster-ingress/(.*) raycluster-ingress-head-svc:8265 (10.244.0.11:8265) # Annotations: nginx.ingress.kubernetes.io/rewrite-target: /$1 # Step 6: Check `<ip>/raycluster-ingress/` on your browser. You will see the Ray Dashboard. # [Note] The forward slash at the end of the address is necessary. `<ip>/raycluster-ingress` # will report \"404 Not Found\".","title":"Example: NGINX Ingress on KinD (built-in ingress support)"},{"location":"guidance/ingress/#example-aws-application-load-balancer-alb-ingress-support-on-aws-eks","text":"","title":"Example: AWS Application Load Balancer (ALB) Ingress support on AWS EKS"},{"location":"guidance/ingress/#prerequisite_1","text":"Follow the document Getting started with Amazon EKS \u2013 AWS Management Console and AWS CLI to create an EKS cluster. Follow the installation instructions to set up the AWS Load Balancer controller . Note that the repository maintains a webpage for each release. Please make sure you use the latest installation instructions. (Optional) Try echo server example in the aws-load-balancer-controller repository. (Optional) Read how-it-works.md to understand the mechanism of aws-load-balancer-controller .","title":"Prerequisite"},{"location":"guidance/ingress/#instructions","text":"# Step 1: Install KubeRay operator and CRD pushd helm-chart/kuberay-operator/ helm install kuberay-operator . popd # Step 2: Install a RayCluster pushd helm-chart/ray-cluster helm install ray-cluster . popd # Step 3: Edit the `ray-operator/config/samples/ray-cluster-alb-ingress.yaml` # # (1) Annotation `alb.ingress.kubernetes.io/subnets` # 1. Please include at least two subnets. # 2. One Availability Zone (ex: us-west-2a) can only have at most 1 subnet. # 3. In this example, you need to select public subnets (subnets that \"Auto-assign public IPv4 address\" is Yes on AWS dashboard) # # (2) Set the name of head pod service to `spec...backend.service.name` eksctl get cluster ${ YOUR_EKS_CLUSTER } # Check subnets on the EKS cluster # Step 4: Create an ALB ingress. When an ingress with proper annotations creates, # AWS Load Balancer controller will reconcile a ALB (not in AWS EKS cluster). kubectl apply -f ray-operator/config/samples/alb-ingress.yaml # Step 5: Check ingress created by Step 4. kubectl describe ingress ray-cluster-ingress # [Example] # Name: ray-cluster-ingress # Labels: <none> # Namespace: default # Address: k8s-default-rayclust-....${REGION_CODE}.elb.amazonaws.com # Default backend: default-http-backend:80 (<error: endpoints \"default-http-backend\" not found>) # Rules: # Host Path Backends # ---- ---- -------- # * # / ray-cluster-kuberay-head-svc:8265 (192.168.185.157:8265) # Annotations: alb.ingress.kubernetes.io/scheme: internet-facing # alb.ingress.kubernetes.io/subnets: ${SUBNET_1},${SUBNET_2} # alb.ingress.kubernetes.io/tags: Environment=dev,Team=test # alb.ingress.kubernetes.io/target-type: ip # Events: # Type Reason Age From Message # ---- ------ ---- ---- ------- # Normal SuccessfullyReconciled 39m ingress Successfully reconciled # Step 6: Check ALB on AWS (EC2 -> Load Balancing -> Load Balancers) # The name of the ALB should be like \"k8s-default-rayclust-......\". # Step 7: Check Ray Dashboard by ALB DNS Name. The name of the DNS Name should be like # \"k8s-default-rayclust-.....us-west-2.elb.amazonaws.com\" # Step 8: Delete the ingress, and AWS Load Balancer controller will remove ALB. # Check ALB on AWS to make sure it is removed. kubectl delete ingress ray-cluster-ingress","title":"Instructions"},{"location":"guidance/ingress/#example-manually-setting-up-nginx-ingress-on-kind","text":"# Step 1: Create a KinD cluster with `extraPortMappings` and `node-labels` # Reference for the setting up of kind cluster: https://kind.sigs.k8s.io/docs/user/ingress/ cat <<EOF | kind create cluster --config=- kind: Cluster apiVersion: kind.x-k8s.io/v1alpha4 nodes: - role: control-plane kubeadmConfigPatches: - | kind: InitConfiguration nodeRegistration: kubeletExtraArgs: node-labels: \"ingress-ready=true\" extraPortMappings: - containerPort: 80 hostPort: 80 protocol: TCP - containerPort: 443 hostPort: 443 protocol: TCP EOF # Step 2: Install NGINX ingress controller kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/kind/deploy.yaml kubectl wait --namespace ingress-nginx \\ --for = condition = ready pod \\ --selector = app.kubernetes.io/component = controller \\ --timeout = 90s # Step 3: Install KubeRay operator pushd helm-chart/kuberay-operator helm install kuberay-operator . popd # Step 4: Install RayCluster and create an ingress separately. # If you want to change ingress settings, you can edit the ingress portion in # `ray-operator/config/samples/ray-cluster.separate-ingress.yaml`. # More information about change of setting was documented in https://github.com/ray-project/kuberay/pull/699 # and `ray-operator/config/samples/ray-cluster.separate-ingress.yaml` kubectl apply -f ray-operator/config/samples/ray-cluster.separate-ingress.yaml # Step 5: Check the ingress created in Step 4. kubectl describe ingress raycluster-ingress-head-ingress # [Example] # ... # Rules: # Host Path Backends # ---- ---- -------- # * # /raycluster-ingress/(.*) raycluster-ingress-head-svc:8265 (10.244.0.11:8265) # Annotations: nginx.ingress.kubernetes.io/rewrite-target: /$1 # Step 6: Check `<ip>/raycluster-ingress/` on your browser. You will see the Ray Dashboard. # [Note] The forward slash at the end of the address is necessary. `<ip>/raycluster-ingress` # will report \"404 Not Found\".","title":"Example: Manually setting up NGINX Ingress on KinD"},{"location":"guidance/kuberay-with-MCAD/","text":"KubeRay integration with MCAD (Multi-Cluster-App-Dispatcher) \u00b6 The multi-cluster-app-dispatcher is a Kubernetes controller providing mechanisms for applications to manage batch jobs in a single or multi-cluster environment. For more details please refer here . Use case \u00b6 MCAD allows you to deploy Ray cluster with a guarantee that sufficient resources are available in the cluster prior to actual pod creation in the Kubernetes cluster. It supports features such as: Integrates with upstream Kubernetes scheduling stack for features such co-scheduling, Packing on GPU dimension etc. Ability to wrap any Kubernetes objects. Increases control plane stability by JIT (Just-in Time) object creation. Queuing with policies. Quota management that goes across namespaces. Support for multiple Kubernetes clusters; dispatching jobs to any one of a number of Kubernetes clusters. In order to queue Ray cluster(s) and gang dispatch them when aggregated resources are available please refer to the setup KubeRay-MCAD integration with configuration files here . Submitting KubeRay cluster to MCAD \u00b6 Let's submit two Ray clusters on the same Kubernetes cluster. Assuming you have installed all the pre-requisites mentioned in the KubeRay-MCAD integration , we submit the first Ray cluster using command kubectl create -f aw-raycluster.yaml using config file here . Conditions: Last Transition Micro Time: 2022-09-27T21:07:34.252275Z Last Update Micro Time: 2022-09-27T21:07:34.252273Z Status: True Type: Init Last Transition Micro Time: 2022-09-27T21:07:34.252535Z Last Update Micro Time: 2022-09-27T21:07:34.252534Z Reason: AwaitingHeadOfLine Status: True Type: Queueing Last Transition Micro Time: 2022-09-27T21:07:34.261174Z Last Update Micro Time: 2022-09-27T21:07:34.261174Z Reason: FrontOfQueue. Status: True Type: HeadOfLine Last Transition Micro Time: 2022-09-27T21:07:34.316208Z Last Update Micro Time: 2022-09-27T21:07:34.316208Z Reason: AppWrapperRunnable Status: True Type: Dispatched Controllerfirsttimestamp: 2022-09-27T21:07:34.251877Z Filterignore: true Queuejobstate: Dispatched Sender: before manageQueueJob - afterEtcdDispatching State: Running Events: <none> (base) asmalvan@mcad-dev:~/mcad-kuberay$ kubectl get pods NAME READY STATUS RESTARTS AGE raycluster-autoscaler-1-head-9s4x5 2/2 Running 0 47s raycluster-autoscaler-1-worker-small-group-4s6jv 1/1 Running 0 47s As seen the cluster is dispatched and pods are running. Let's submit another Ray cluster and see it queued without creating pending pods using the command kubectl create -f aw-raycluster.yaml . To do this, change cluster name from name: raycluster-autoscaler to name: raycluster-autoscaler-1 and re-submit Conditions: Last Transition Micro Time: 2022-09-27T21:11:06.162080Z Last Update Micro Time: 2022-09-27T21:11:06.162080Z Status: True Type: Init Last Transition Micro Time: 2022-09-27T21:11:06.162401Z Last Update Micro Time: 2022-09-27T21:11:06.162401Z Reason: AwaitingHeadOfLine Status: True Type: Queueing Last Transition Micro Time: 2022-09-27T21:11:06.171619Z Last Update Micro Time: 2022-09-27T21:11:06.171618Z Reason: FrontOfQueue. Status: True Type: HeadOfLine Last Transition Micro Time: 2022-09-27T21:11:06.179694Z Last Update Micro Time: 2022-09-27T21:11:06.179689Z Message: Insufficient resources to dispatch AppWrapper. Reason: AppWrapperNotRunnable. Status: True Type: Backoff Controllerfirsttimestamp: 2022-09-27T21:11:06.161797Z Filterignore: true Queuejobstate: HeadOfLine Sender: before ScheduleNext - setHOL State: Pending Events: <none> As seen the second Ray cluster is queued with no pending pods created. Dispatching policy out of the box is FIFO which can be augmented as per user needs. The second cluster will be dispatched when additional aggregated resources are available in the cluster or the first AppWrapper Ray cluster is deleted.","title":"KubeRay with MCAD"},{"location":"guidance/kuberay-with-MCAD/#kuberay-integration-with-mcad-multi-cluster-app-dispatcher","text":"The multi-cluster-app-dispatcher is a Kubernetes controller providing mechanisms for applications to manage batch jobs in a single or multi-cluster environment. For more details please refer here .","title":"KubeRay integration with MCAD (Multi-Cluster-App-Dispatcher)"},{"location":"guidance/kuberay-with-MCAD/#use-case","text":"MCAD allows you to deploy Ray cluster with a guarantee that sufficient resources are available in the cluster prior to actual pod creation in the Kubernetes cluster. It supports features such as: Integrates with upstream Kubernetes scheduling stack for features such co-scheduling, Packing on GPU dimension etc. Ability to wrap any Kubernetes objects. Increases control plane stability by JIT (Just-in Time) object creation. Queuing with policies. Quota management that goes across namespaces. Support for multiple Kubernetes clusters; dispatching jobs to any one of a number of Kubernetes clusters. In order to queue Ray cluster(s) and gang dispatch them when aggregated resources are available please refer to the setup KubeRay-MCAD integration with configuration files here .","title":"Use case"},{"location":"guidance/kuberay-with-MCAD/#submitting-kuberay-cluster-to-mcad","text":"Let's submit two Ray clusters on the same Kubernetes cluster. Assuming you have installed all the pre-requisites mentioned in the KubeRay-MCAD integration , we submit the first Ray cluster using command kubectl create -f aw-raycluster.yaml using config file here . Conditions: Last Transition Micro Time: 2022-09-27T21:07:34.252275Z Last Update Micro Time: 2022-09-27T21:07:34.252273Z Status: True Type: Init Last Transition Micro Time: 2022-09-27T21:07:34.252535Z Last Update Micro Time: 2022-09-27T21:07:34.252534Z Reason: AwaitingHeadOfLine Status: True Type: Queueing Last Transition Micro Time: 2022-09-27T21:07:34.261174Z Last Update Micro Time: 2022-09-27T21:07:34.261174Z Reason: FrontOfQueue. Status: True Type: HeadOfLine Last Transition Micro Time: 2022-09-27T21:07:34.316208Z Last Update Micro Time: 2022-09-27T21:07:34.316208Z Reason: AppWrapperRunnable Status: True Type: Dispatched Controllerfirsttimestamp: 2022-09-27T21:07:34.251877Z Filterignore: true Queuejobstate: Dispatched Sender: before manageQueueJob - afterEtcdDispatching State: Running Events: <none> (base) asmalvan@mcad-dev:~/mcad-kuberay$ kubectl get pods NAME READY STATUS RESTARTS AGE raycluster-autoscaler-1-head-9s4x5 2/2 Running 0 47s raycluster-autoscaler-1-worker-small-group-4s6jv 1/1 Running 0 47s As seen the cluster is dispatched and pods are running. Let's submit another Ray cluster and see it queued without creating pending pods using the command kubectl create -f aw-raycluster.yaml . To do this, change cluster name from name: raycluster-autoscaler to name: raycluster-autoscaler-1 and re-submit Conditions: Last Transition Micro Time: 2022-09-27T21:11:06.162080Z Last Update Micro Time: 2022-09-27T21:11:06.162080Z Status: True Type: Init Last Transition Micro Time: 2022-09-27T21:11:06.162401Z Last Update Micro Time: 2022-09-27T21:11:06.162401Z Reason: AwaitingHeadOfLine Status: True Type: Queueing Last Transition Micro Time: 2022-09-27T21:11:06.171619Z Last Update Micro Time: 2022-09-27T21:11:06.171618Z Reason: FrontOfQueue. Status: True Type: HeadOfLine Last Transition Micro Time: 2022-09-27T21:11:06.179694Z Last Update Micro Time: 2022-09-27T21:11:06.179689Z Message: Insufficient resources to dispatch AppWrapper. Reason: AppWrapperNotRunnable. Status: True Type: Backoff Controllerfirsttimestamp: 2022-09-27T21:11:06.161797Z Filterignore: true Queuejobstate: HeadOfLine Sender: before ScheduleNext - setHOL State: Pending Events: <none> As seen the second Ray cluster is queued with no pending pods created. Dispatching policy out of the box is FIFO which can be augmented as per user needs. The second cluster will be dispatched when additional aggregated resources are available in the cluster or the first AppWrapper Ray cluster is deleted.","title":"Submitting KubeRay cluster to MCAD"},{"location":"guidance/observability/","text":"Observability \u00b6 RayCluster Status \u00b6 State \u00b6 In the RayCluster resource definition, we use State to represent the current status of the Ray cluster. For now, there are three types of the status exposed by the RayCluster's status.state: ready , unhealthy and failed . | State | Description | | --------- | ----------------------------------------------------------------------------------------------- | | ready | The Ray cluster is ready for use. | | unhealthy | The rayStartParams are misconfigured and the Ray cluster may not function properly. | | failed | A severe issue has prevented the head node or worker nodes from starting. | If you use the apiserver to retrieve the resource, you may find the state in the clusterState field. curl -- reques t GET '<baseUrl>/apis/v 1 alpha 2 / na mespaces/< na mespace>/clus ters /<rayclus ter - na me>' { \"name\" : \"<raycluster-name>\" , \"namespace\" : \"<namespace>\" , //... \"createdAt\" : \"2022-08-10T10:31:25Z\" , \"clusterState\" : \"ready\" , //... } Endpoint \u00b6 If you use the nodeport as service to expose the raycluster endpoint, like dashboard or redis, there are endpoints field in the status to record the service endpoints. you can directly use the ports in the endpoints to connect to the related service. Also, if you use apiserver to retrieve the resource, you can find the endpoints in the serviceEndpoint field. curl -- reques t GET '<baseUrl>/apis/v 1 alpha 2 / na mespaces/< na mespace>/clus ters /<rayclus ter - na me>' { \"name\" : \"<raycluster-name>\" , \"namespace\" : \"<namespace>\" , //... \"serviceEndpoint\" : { \"dashboard\" : \"30001\" , \"head\" : \"30002\" , \"metrics\" : \"30003\" , \"redis\" : \"30004\" }, //... } Ray Cluster: Monitoring with Prometheus & Grafana \u00b6 In this section we will describe how to monitor Ray Clusters in Kubernetes using Prometheus & Grafana. We also leverage the Prometheus Operator to start the whole monitoring system. Requirements: - Prometheus deployed in Kubernetes - Required CRD: servicemonitors.monitoring.coreos.com - Requered CRD: podmonitors.monitoring.coreos.com - Grafana up and running Enable Ray Cluster Metrics \u00b6 Before we define any Prometheus objects, let us first enable and export metrics to a specific port. To enable ray metrics on Head node or a worker node, we need to pass the following option --metrics-expose-port=9001 . We can set the specific option by adding metrics-export-port: \"9001\" to the head node & worker nodes in the rayclusters.ray.io manifest. We also need to export port 9001 in the head node & worker nodes apiVersion : ray.io/v1alpha1 kind : RayCluster metadata : ... name : ray-cluster spec : enableInTreeAutoscaling : true headGroupSpec : rayStartParams : ... metrics-export-port : \"9001\" <--- Enable for the head node ... template : metadata : ... spec : ... containers : - ports : - containerPort : 10001 name : client protocol : TCP - containerPort : 8265 name : dashboard protocol : TCP - containerPort : 8000 name : ray-serve protocol : TCP - containerPort : 6379 name : redis protocol : TCP - containerPort : 9001 name : metrics protocol : TCP workerGroupSpecs : - groupName : workergroup ... rayStartParams : ... metrics-export-port : \"9001\" <--- Enable for worker nodes ... template : metadata : ... spec : ... containers : - ports : - containerPort : 9001 name : metrics protocol : TCP ... ... If you use $kuberay/helm-chart/ray-cluster , then you can add it in the values.yaml head : groupName : headgroup ... initArgs : metrics-export-port : \"9001\" <--- Enable for the head node ... ports : - containerPort : 10001 protocol : TCP name : \"client\" - containerPort : 8265 protocol : TCP name : \"dashboard\" - containerPort : 8000 protocol : TCP name : \"ray-serve\" - containerPort : 6379 protocol : TCP name : \"redis\" - containerPort : 9001 <--- Enable this port protocol : TCP name : \"metrics\" ... worker : groupName : workergroup ... initArgs : ... metrics-export-port : \"9001\" <--- Enable for the head node ports : - containerPort : 9001 <--- Enable this port protocol : TCP name : \"metrics\" ... ... Deploying the cluster with the above options should export metrics on port 9001 . To check, we can port-forward port 9001 to our localhost and query via curl. k port-forward <ray-head-node-id> 9001 :9001 From a second terminal issue $> curl localhost:9001 # TYPE ray_pull_manager_object_request_time_ms histogram ... ray_pull_manager_object_request_time_ms_sum { Component = \"raylet\" ,... ... Before we move on, first ensure that the required metrics port is also defined in the Ray's cluster Kubernetes service. This is done automatically via the Ray Operator if you define the metrics port containerPort: 9001 along with the name and protocol. $> kubectl get svc <ray-cluster-name>-head-svc -o yaml NAME TYPE ... PORT ( S ) ... ... ClusterIP ... 6379 /TCP,9001/TCP,10001/TCP,8265/TCP,8000/TCP ... We are now ready to create the required Prometheus CRDs to collect metrics Collect Head Node metrics with ServiceMonitors \u00b6 Prometheus provides a CRD that targets Kubernetes services to collect metrics. The idea is that we will define a CRD that will have selectors that match the Ray Cluster Kubernetes service labels and ports, the metrics port. apiVersion : monitoring.coreos.com/v1 kind : ServiceMonitor metadata : name : <ray-cluster-name>-head-monitor <-- Replace <ray-cluster-name> with the actual Ray Cluster name namespace : <ray-cluster-namespace> <-- Add the namespace of your ray cluster spec : endpoints : - interval : 1m path : /metrics scrapeTimeout : 10s port : metrics jobLabel : <ray-cluster-name>-ray-head <-- Replace <ray-cluster-name> with the actual Ray Cluster name namespaceSelector : matchNames : - <ray-cluster-namespace> <-- Add the namespace of your ray cluster selector : matchLabels : ray.io/cluster : <ray-cluster-name> <-- Replace <ray-cluster-name> with the actual Ray Cluster name ray.io/identifier : <ray-cluster-name>-head <-- Replace <ray-cluster-name> with the actual Ray Cluster name ray.io/node-type : head targetLabels : - ray.io/cluster A notes for the targetLabels . We added spec.targetLabels[0].ray.io/cluster because we want to include the name of the ray cluster in the metrics that will be generated by this service monitor. The ray.io/cluster label is part of the Ray head node service and it will be transformed to a ray_io_cluster metric label. That is, any metric that will be imported, will also container the following label ray_io_cluster=<ray-cluster-name> . This may seem like optional but it becomes mandatory if you deploy multiple ray clusters. Create the above service monitor by issuing k apply -f serviceMonitor.yaml After a while, Prometheus should start scraping metrics from the head node. You can confirm that by visiting the Prometheus web ui and start typing ray_ . Prometheus should create a dropdown list with suggested Ray metrics. curl 'https://<prometheus-endpoint>/api/v1/query?query=ray_object_store_available_memory' -H 'Accept: */*' Collect Worker Node metrics with PodMonitors \u00b6 Ray operator does not create a Kubernetes service for the ray workers, therefore we can not use a Prometheus ServiceMonitors to scrape the metrics from our workers. Note : We could create a Kubernetes service with selectors a common label subset from our worker pods, however this is not ideal because our workers are independent from each other, that is, they are not a collection of replicas spawned by replicaset controller. Due to that, we should avoid using a Kubernetes service for grouping them together. To collect worker metrics, we can use Prometheus PodMonitros CRD . apiVersion : monitoring.coreos.com/v1 kind : PodMonitor metadata : labels : ray.io/cluster : <ray-cluster-name> <-- Replace <ray-cluster-name> with the actual Ray Cluster name name : <ray-cluster-name>-workers-monitor <-- Replace <ray-cluster-name> with the actual Ray Cluster name namespace : <ray-cluster-namespace> <-- Add the namespace of your ray cluster spec : jobLabel : <ray-cluster-name>-ray-workers <-- Replace <ray-cluster-name> with the actual Ray Cluster name namespaceSelector : matchNames : - <ray-cluster-namespace> <-- Add the namespace of your ray cluster podMetricsEndpoints : - interval : 30s port : metrics scrapeTimeout : 10s podTargetLabels : - ray.io/cluster selector : matchLabels : ray.io/is-ray-node : \"yes\" ray.io/node-type : worker Since we are not selecting a Kubernetes service but pods, our matchLabels now define a set of labels that is common on all Ray workers. We also define metadata.labels by manually adding ray.io/cluster: <ray-cluster-name> and then instructing the PodMonitors resource to add that label in the scraped metrics via spec.podTargetLabels[0].ray.io/cluster . Apply the above PodMonitor manifest k apply -f podMonitor.yaml Last, wait a bit and then ensure that you can see Ray worker metrics in Prometheus curl 'https://<prometheus-endpoint>/api/v1/query?query=ray_object_store_available_memory' -H 'Accept: */*' The above http query should yield metrics from the head node and your worker nodes We have everything we need now and we can use Grafana to create some panels and visualize the scrapped metrics Grafana: Visualize ingested Ray metrics \u00b6 You can use the json in config/grafana to import in Grafana the Ray dashboards. Custom Metrics & Alerting \u00b6 We can also define custom metrics, and create alerts by using prometheusrules.monitoring.coreos.com CRD. Because custom metrics, and alerting is different for each team and setup, we have included an example under $kuberay/config/prometheus/rules that you can use to build custom metrics and alerts","title":"Observability"},{"location":"guidance/observability/#observability","text":"","title":"Observability"},{"location":"guidance/observability/#raycluster-status","text":"","title":"RayCluster Status"},{"location":"guidance/observability/#state","text":"In the RayCluster resource definition, we use State to represent the current status of the Ray cluster. For now, there are three types of the status exposed by the RayCluster's status.state: ready , unhealthy and failed . | State | Description | | --------- | ----------------------------------------------------------------------------------------------- | | ready | The Ray cluster is ready for use. | | unhealthy | The rayStartParams are misconfigured and the Ray cluster may not function properly. | | failed | A severe issue has prevented the head node or worker nodes from starting. | If you use the apiserver to retrieve the resource, you may find the state in the clusterState field. curl -- reques t GET '<baseUrl>/apis/v 1 alpha 2 / na mespaces/< na mespace>/clus ters /<rayclus ter - na me>' { \"name\" : \"<raycluster-name>\" , \"namespace\" : \"<namespace>\" , //... \"createdAt\" : \"2022-08-10T10:31:25Z\" , \"clusterState\" : \"ready\" , //... }","title":"State"},{"location":"guidance/observability/#endpoint","text":"If you use the nodeport as service to expose the raycluster endpoint, like dashboard or redis, there are endpoints field in the status to record the service endpoints. you can directly use the ports in the endpoints to connect to the related service. Also, if you use apiserver to retrieve the resource, you can find the endpoints in the serviceEndpoint field. curl -- reques t GET '<baseUrl>/apis/v 1 alpha 2 / na mespaces/< na mespace>/clus ters /<rayclus ter - na me>' { \"name\" : \"<raycluster-name>\" , \"namespace\" : \"<namespace>\" , //... \"serviceEndpoint\" : { \"dashboard\" : \"30001\" , \"head\" : \"30002\" , \"metrics\" : \"30003\" , \"redis\" : \"30004\" }, //... }","title":"Endpoint"},{"location":"guidance/observability/#ray-cluster-monitoring-with-prometheus-grafana","text":"In this section we will describe how to monitor Ray Clusters in Kubernetes using Prometheus & Grafana. We also leverage the Prometheus Operator to start the whole monitoring system. Requirements: - Prometheus deployed in Kubernetes - Required CRD: servicemonitors.monitoring.coreos.com - Requered CRD: podmonitors.monitoring.coreos.com - Grafana up and running","title":"Ray Cluster: Monitoring with Prometheus &amp; Grafana"},{"location":"guidance/observability/#enable-ray-cluster-metrics","text":"Before we define any Prometheus objects, let us first enable and export metrics to a specific port. To enable ray metrics on Head node or a worker node, we need to pass the following option --metrics-expose-port=9001 . We can set the specific option by adding metrics-export-port: \"9001\" to the head node & worker nodes in the rayclusters.ray.io manifest. We also need to export port 9001 in the head node & worker nodes apiVersion : ray.io/v1alpha1 kind : RayCluster metadata : ... name : ray-cluster spec : enableInTreeAutoscaling : true headGroupSpec : rayStartParams : ... metrics-export-port : \"9001\" <--- Enable for the head node ... template : metadata : ... spec : ... containers : - ports : - containerPort : 10001 name : client protocol : TCP - containerPort : 8265 name : dashboard protocol : TCP - containerPort : 8000 name : ray-serve protocol : TCP - containerPort : 6379 name : redis protocol : TCP - containerPort : 9001 name : metrics protocol : TCP workerGroupSpecs : - groupName : workergroup ... rayStartParams : ... metrics-export-port : \"9001\" <--- Enable for worker nodes ... template : metadata : ... spec : ... containers : - ports : - containerPort : 9001 name : metrics protocol : TCP ... ... If you use $kuberay/helm-chart/ray-cluster , then you can add it in the values.yaml head : groupName : headgroup ... initArgs : metrics-export-port : \"9001\" <--- Enable for the head node ... ports : - containerPort : 10001 protocol : TCP name : \"client\" - containerPort : 8265 protocol : TCP name : \"dashboard\" - containerPort : 8000 protocol : TCP name : \"ray-serve\" - containerPort : 6379 protocol : TCP name : \"redis\" - containerPort : 9001 <--- Enable this port protocol : TCP name : \"metrics\" ... worker : groupName : workergroup ... initArgs : ... metrics-export-port : \"9001\" <--- Enable for the head node ports : - containerPort : 9001 <--- Enable this port protocol : TCP name : \"metrics\" ... ... Deploying the cluster with the above options should export metrics on port 9001 . To check, we can port-forward port 9001 to our localhost and query via curl. k port-forward <ray-head-node-id> 9001 :9001 From a second terminal issue $> curl localhost:9001 # TYPE ray_pull_manager_object_request_time_ms histogram ... ray_pull_manager_object_request_time_ms_sum { Component = \"raylet\" ,... ... Before we move on, first ensure that the required metrics port is also defined in the Ray's cluster Kubernetes service. This is done automatically via the Ray Operator if you define the metrics port containerPort: 9001 along with the name and protocol. $> kubectl get svc <ray-cluster-name>-head-svc -o yaml NAME TYPE ... PORT ( S ) ... ... ClusterIP ... 6379 /TCP,9001/TCP,10001/TCP,8265/TCP,8000/TCP ... We are now ready to create the required Prometheus CRDs to collect metrics","title":"Enable Ray Cluster Metrics"},{"location":"guidance/observability/#collect-head-node-metrics-with-servicemonitors","text":"Prometheus provides a CRD that targets Kubernetes services to collect metrics. The idea is that we will define a CRD that will have selectors that match the Ray Cluster Kubernetes service labels and ports, the metrics port. apiVersion : monitoring.coreos.com/v1 kind : ServiceMonitor metadata : name : <ray-cluster-name>-head-monitor <-- Replace <ray-cluster-name> with the actual Ray Cluster name namespace : <ray-cluster-namespace> <-- Add the namespace of your ray cluster spec : endpoints : - interval : 1m path : /metrics scrapeTimeout : 10s port : metrics jobLabel : <ray-cluster-name>-ray-head <-- Replace <ray-cluster-name> with the actual Ray Cluster name namespaceSelector : matchNames : - <ray-cluster-namespace> <-- Add the namespace of your ray cluster selector : matchLabels : ray.io/cluster : <ray-cluster-name> <-- Replace <ray-cluster-name> with the actual Ray Cluster name ray.io/identifier : <ray-cluster-name>-head <-- Replace <ray-cluster-name> with the actual Ray Cluster name ray.io/node-type : head targetLabels : - ray.io/cluster A notes for the targetLabels . We added spec.targetLabels[0].ray.io/cluster because we want to include the name of the ray cluster in the metrics that will be generated by this service monitor. The ray.io/cluster label is part of the Ray head node service and it will be transformed to a ray_io_cluster metric label. That is, any metric that will be imported, will also container the following label ray_io_cluster=<ray-cluster-name> . This may seem like optional but it becomes mandatory if you deploy multiple ray clusters. Create the above service monitor by issuing k apply -f serviceMonitor.yaml After a while, Prometheus should start scraping metrics from the head node. You can confirm that by visiting the Prometheus web ui and start typing ray_ . Prometheus should create a dropdown list with suggested Ray metrics. curl 'https://<prometheus-endpoint>/api/v1/query?query=ray_object_store_available_memory' -H 'Accept: */*'","title":"Collect Head Node metrics with ServiceMonitors"},{"location":"guidance/observability/#collect-worker-node-metrics-with-podmonitors","text":"Ray operator does not create a Kubernetes service for the ray workers, therefore we can not use a Prometheus ServiceMonitors to scrape the metrics from our workers. Note : We could create a Kubernetes service with selectors a common label subset from our worker pods, however this is not ideal because our workers are independent from each other, that is, they are not a collection of replicas spawned by replicaset controller. Due to that, we should avoid using a Kubernetes service for grouping them together. To collect worker metrics, we can use Prometheus PodMonitros CRD . apiVersion : monitoring.coreos.com/v1 kind : PodMonitor metadata : labels : ray.io/cluster : <ray-cluster-name> <-- Replace <ray-cluster-name> with the actual Ray Cluster name name : <ray-cluster-name>-workers-monitor <-- Replace <ray-cluster-name> with the actual Ray Cluster name namespace : <ray-cluster-namespace> <-- Add the namespace of your ray cluster spec : jobLabel : <ray-cluster-name>-ray-workers <-- Replace <ray-cluster-name> with the actual Ray Cluster name namespaceSelector : matchNames : - <ray-cluster-namespace> <-- Add the namespace of your ray cluster podMetricsEndpoints : - interval : 30s port : metrics scrapeTimeout : 10s podTargetLabels : - ray.io/cluster selector : matchLabels : ray.io/is-ray-node : \"yes\" ray.io/node-type : worker Since we are not selecting a Kubernetes service but pods, our matchLabels now define a set of labels that is common on all Ray workers. We also define metadata.labels by manually adding ray.io/cluster: <ray-cluster-name> and then instructing the PodMonitors resource to add that label in the scraped metrics via spec.podTargetLabels[0].ray.io/cluster . Apply the above PodMonitor manifest k apply -f podMonitor.yaml Last, wait a bit and then ensure that you can see Ray worker metrics in Prometheus curl 'https://<prometheus-endpoint>/api/v1/query?query=ray_object_store_available_memory' -H 'Accept: */*' The above http query should yield metrics from the head node and your worker nodes We have everything we need now and we can use Grafana to create some panels and visualize the scrapped metrics","title":"Collect Worker Node metrics with PodMonitors"},{"location":"guidance/observability/#grafana-visualize-ingested-ray-metrics","text":"You can use the json in config/grafana to import in Grafana the Ray dashboards.","title":"Grafana: Visualize ingested Ray metrics"},{"location":"guidance/observability/#custom-metrics-alerting","text":"We can also define custom metrics, and create alerts by using prometheusrules.monitoring.coreos.com CRD. Because custom metrics, and alerting is different for each team and setup, we have included an example under $kuberay/config/prometheus/rules that you can use to build custom metrics and alerts","title":"Custom Metrics &amp; Alerting"},{"location":"guidance/rayjob/","text":"Ray Job (alpha) \u00b6 Note: This is the alpha version of Ray Job Support in KubeRay. There will be ongoing improvements for Ray Job in the future releases. Prerequisites \u00b6 Ray 1.10 or higher KubeRay v0.3.0 What is a RayJob? \u00b6 RayJob is a new custom resource (CR) supported by KubeRay in v0.3.0. A RayJob manages 2 things: * Ray Cluster: Manages resources in a Kubernetes cluster. * Job: Manages jobs in a Ray Cluster. What does the RayJob provide? \u00b6 Kubernetes-native support for Ray clusters and Ray Jobs. You can use a Kubernetes config to define a Ray cluster and job, and use kubectl to create them. The cluster can be deleted automatically once the job is finished. Deploy KubeRay \u00b6 Make sure KubeRay v0.3.0 version is deployed in your cluster. For installation instructions, please follow the documentation . Run an example Job \u00b6 There is one example config file to deploy a RayJob included here: ray_v1alpha1_rayjob.yaml # Create a RayJob. $ kubectl apply -f config/samples/ray_v1alpha1_rayjob.yaml # List running RayJobs. $ kubectl get rayjob NAME AGE rayjob-sample 7s # RayJob sample will also create a raycluster. # raycluster will create few resources including pods and services. You can use the following commands to check them: $ kubectl get rayclusters $ kubectl get pod RayJob Configuration \u00b6 entrypoint - The shell command to run for this job. job_id. jobId - (Optional) Job ID to specify for the job. If not provided, one will be generated. metadata - Arbitrary user-provided metadata for the job. runtimeEnv - base64 string of the runtime json string. shutdownAfterJobFinishes - whether to recycle the cluster after job finishes. ttlSecondsAfterFinished - TTL to clean up the cluster. This only works if shutdownAfterJobFinishes is set. RayJob Observability \u00b6 You can use kubectl logs to check the operator logs or the head/worker nodes logs. You can also use kubectl describe rayjobs rayjob-sample to check the states and event logs of your RayJob instance: Status: Dashboard URL: rayjob-sample-raycluster-vnl8w-head-svc.ray-system.svc.cluster.local:8265 End Time: 2022-07-24T02:04:56Z Job Deployment Status: Complete Job Id: test-hehe Job Status: SUCCEEDED Message: Job finished successfully. Ray Cluster Name: rayjob-sample-raycluster-vnl8w Ray Cluster Status: Available Worker Replicas: 1 Endpoints: Client: 32572 Dashboard: 32276 Gcs - Server: 30679 Last Update Time: 2022-07-24T02:04:43Z State: ready Start Time: 2022-07-24T02:04:49Z Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Created 90s rayjob-controller Created cluster rayjob-sample-raycluster-vnl8w Normal Submitted 82s rayjob-controller Submit Job test-hehe Normal Deleted 15s rayjob-controller Deleted cluster rayjob-sample-raycluster-vnl8w If the job doesn't run successfully, the above describe command will provide information about that too: Status: Dashboard URL: rayjob-sample-raycluster-nrdm8-head-svc.ray-system.svc.cluster.local:8265 End Time: 2022-07-24T02:01:39Z Job Deployment Status: Complete Job Id: test-hehe Job Status: FAILED Message: Job failed due to an application error, last available logs: python: can't open file '/tmp/code/script.ppy': [Errno 2] No such file or directory Ray Cluster Name: rayjob-sample-raycluster-nrdm8 Ray Cluster Status: Available Worker Replicas: 1 Endpoints: Client: 31852 Dashboard: 32606 Gcs - Server: 32436 Last Update Time: 2022-07-24T02:01:30Z State: ready Start Time: 2022-07-24T02:01:38Z Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Created 2m9s rayjob-controller Created cluster rayjob-sample-raycluster-nrdm8 Normal Submitted 2m rayjob-controller Submit Job test-hehe Normal Deleted 58s rayjob-controller Deleted cluster rayjob-sample-raycluster-nrdm8 Delete the RayJob instance \u00b6 $ kubectl delete -f config/samples/ray_v1alpha1_rayjob.yaml","title":"RayJob"},{"location":"guidance/rayjob/#ray-job-alpha","text":"Note: This is the alpha version of Ray Job Support in KubeRay. There will be ongoing improvements for Ray Job in the future releases.","title":"Ray Job (alpha)"},{"location":"guidance/rayjob/#prerequisites","text":"Ray 1.10 or higher KubeRay v0.3.0","title":"Prerequisites"},{"location":"guidance/rayjob/#what-is-a-rayjob","text":"RayJob is a new custom resource (CR) supported by KubeRay in v0.3.0. A RayJob manages 2 things: * Ray Cluster: Manages resources in a Kubernetes cluster. * Job: Manages jobs in a Ray Cluster.","title":"What is a RayJob?"},{"location":"guidance/rayjob/#what-does-the-rayjob-provide","text":"Kubernetes-native support for Ray clusters and Ray Jobs. You can use a Kubernetes config to define a Ray cluster and job, and use kubectl to create them. The cluster can be deleted automatically once the job is finished.","title":"What does the RayJob provide?"},{"location":"guidance/rayjob/#deploy-kuberay","text":"Make sure KubeRay v0.3.0 version is deployed in your cluster. For installation instructions, please follow the documentation .","title":"Deploy KubeRay"},{"location":"guidance/rayjob/#run-an-example-job","text":"There is one example config file to deploy a RayJob included here: ray_v1alpha1_rayjob.yaml # Create a RayJob. $ kubectl apply -f config/samples/ray_v1alpha1_rayjob.yaml # List running RayJobs. $ kubectl get rayjob NAME AGE rayjob-sample 7s # RayJob sample will also create a raycluster. # raycluster will create few resources including pods and services. You can use the following commands to check them: $ kubectl get rayclusters $ kubectl get pod","title":"Run an example Job"},{"location":"guidance/rayjob/#rayjob-configuration","text":"entrypoint - The shell command to run for this job. job_id. jobId - (Optional) Job ID to specify for the job. If not provided, one will be generated. metadata - Arbitrary user-provided metadata for the job. runtimeEnv - base64 string of the runtime json string. shutdownAfterJobFinishes - whether to recycle the cluster after job finishes. ttlSecondsAfterFinished - TTL to clean up the cluster. This only works if shutdownAfterJobFinishes is set.","title":"RayJob Configuration"},{"location":"guidance/rayjob/#rayjob-observability","text":"You can use kubectl logs to check the operator logs or the head/worker nodes logs. You can also use kubectl describe rayjobs rayjob-sample to check the states and event logs of your RayJob instance: Status: Dashboard URL: rayjob-sample-raycluster-vnl8w-head-svc.ray-system.svc.cluster.local:8265 End Time: 2022-07-24T02:04:56Z Job Deployment Status: Complete Job Id: test-hehe Job Status: SUCCEEDED Message: Job finished successfully. Ray Cluster Name: rayjob-sample-raycluster-vnl8w Ray Cluster Status: Available Worker Replicas: 1 Endpoints: Client: 32572 Dashboard: 32276 Gcs - Server: 30679 Last Update Time: 2022-07-24T02:04:43Z State: ready Start Time: 2022-07-24T02:04:49Z Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Created 90s rayjob-controller Created cluster rayjob-sample-raycluster-vnl8w Normal Submitted 82s rayjob-controller Submit Job test-hehe Normal Deleted 15s rayjob-controller Deleted cluster rayjob-sample-raycluster-vnl8w If the job doesn't run successfully, the above describe command will provide information about that too: Status: Dashboard URL: rayjob-sample-raycluster-nrdm8-head-svc.ray-system.svc.cluster.local:8265 End Time: 2022-07-24T02:01:39Z Job Deployment Status: Complete Job Id: test-hehe Job Status: FAILED Message: Job failed due to an application error, last available logs: python: can't open file '/tmp/code/script.ppy': [Errno 2] No such file or directory Ray Cluster Name: rayjob-sample-raycluster-nrdm8 Ray Cluster Status: Available Worker Replicas: 1 Endpoints: Client: 31852 Dashboard: 32606 Gcs - Server: 32436 Last Update Time: 2022-07-24T02:01:30Z State: ready Start Time: 2022-07-24T02:01:38Z Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Created 2m9s rayjob-controller Created cluster rayjob-sample-raycluster-nrdm8 Normal Submitted 2m rayjob-controller Submit Job test-hehe Normal Deleted 58s rayjob-controller Deleted cluster rayjob-sample-raycluster-nrdm8","title":"RayJob Observability"},{"location":"guidance/rayjob/#delete-the-rayjob-instance","text":"$ kubectl delete -f config/samples/ray_v1alpha1_rayjob.yaml","title":"Delete the RayJob instance"},{"location":"guidance/rayservice/","text":"Ray Services (alpha) \u00b6 Note: This is the alpha version of Ray Services. There will be ongoing improvements for Ray Services in the future releases. Prerequisite \u00b6 Ray 2.0 is required. What is a RayService? \u00b6 RayService is a new custom resource (CR) supported by KubeRay in v0.3.0. A RayService manages 2 things: Ray Cluster : Manages resources in a Kubernetes cluster. Ray Serve Deployment Graph : Manages users' deployment graphs. What does the RayService provide? \u00b6 Kubernetes-native support for Ray clusters and Ray Serve deployment graphs. After using a Kubernetes config to define a Ray cluster and its Ray Serve deployment graphs, you can use kubectl to create the cluster and its graphs. In-place update for Ray Serve deployment graph. Users can update the Ray Serve deployment graph config in the RayService CR config and use kubectl apply to update the deployment graph. Zero downtime upgrade for Ray clusters. Users can update the Ray cluster config in the RayService CR config and use kubectl apply to update the cluster. RayService will temporarily create a pending cluster and wait for it to be ready, then switch traffic to the new cluster and terminate the old one. Services HA. RayService will monitor the Ray cluster and Serve deployments' health statuses. If RayService detects an unhealthy status for a period of time, RayService will try to create a new Ray cluster and switch traffic to the new cluster when it is ready. Deploy the Operator \u00b6 $ kubectl create -k \"github.com/ray-project/kuberay/ray-operator/config/default?ref=v0.3.0&timeout=90s\" Check that the controller is running. $ kubectl get deployments -n ray-system NAME READY UP-TO-DATE AVAILABLE AGE ray-operator 1 /1 1 1 40s $ kubectl get pods -n ray-system NAME READY STATUS RESTARTS AGE ray-operator-75dbbf8587-5lrvn 1 /1 Running 0 31s Run an Example Cluster \u00b6 An example config file to deploy RayService is included here: ray_v1alpha1_rayservice.yaml # Create a ray service and deploy fruit deployment graph. $ kubectl apply -f config/samples/ray_v1alpha1_rayservice.yaml # List running RayServices. $ kubectl get rayservice NAME AGE rayservice-sample 7s # The created RayService should include a head pod, a worker pod, and four services. $ kubectl get pods NAME READY STATUS RESTARTS AGE ervice-sample-raycluster-qd2vl-worker-small-group-bxpp6 1 /1 Running 0 24m rayservice-sample-raycluster-qd2vl-head-45hj4 1 /1 Running 0 24m $ kubectl get services NAME TYPE CLUSTER-IP EXTERNAL-IP PORT ( S ) AGE kubernetes ClusterIP 10 .100.0.1 <none> 443 /TCP 62d # A head node service maintained by the RayService. rayservice-sample-head-svc ClusterIP 10 .100.34.24 <none> 6379 /TCP,8265/TCP,10001/TCP,8000/TCP,52365/TCP 24m # A dashboard agent service maintained by the RayCluster. rayservice-sample-raycluster-qd2vl-dashboard-svc ClusterIP 10 .100.109.177 <none> 52365 /TCP 24m # A head node service maintained by the RayCluster. rayservice-sample-raycluster-qd2vl-head-svc ClusterIP 10 .100.180.221 <none> 6379 /TCP,8265/TCP,10001/TCP,8000/TCP,52365/TCP 24m # A serve service maintained by the RayService. rayservice-sample-serve-svc ClusterIP 10 .100.39.92 <none> 8000 /TCP 24m Note: Default ports and their definitions. Port Definition 6379 Ray GCS 8265 Ray Dashboard 10001 Ray Client 8000 Ray Serve 52365 Ray Dashboard Agent Get information about the RayService using its name. $ kubectl describe rayservices rayservice-sample Access User Services \u00b6 The users' traffic can go through the serve service (e.g. rayservice-sample-serve-svc ). Run a Curl Pod \u00b6 $ kubectl run curl --image = radial/busyboxplus:curl -i --tty Or if you already have a curl pod running, you can login using kubectl exec -it curl sh . For the fruit example deployment, you can try the following request: [ root@curl:/ ] $ curl -X POST -H 'Content-Type: application/json' rayservice-sample-serve-svc.default.svc.cluster.local:8000 -d '[\"MANGO\", 2]' > 6 You should get the response 6 . Use Port Forwarding \u00b6 Set up Kubernetes port forwarding. $ kubectl port-forward service/rayservice-sample-serve-svc 8000 For the fruit example deployment, you can try the following request: [ root@curl:/ ] $ curl -X POST -H 'Content-Type: application/json' localhost:8000 -d '[\"MANGO\", 2]' > 6 Note: serve-svc is HA in general. It will do traffic routing among all the workers which have serve deployments and will always try to point to the healthy cluster, even during upgrading or failing cases. You can set serviceUnhealthySecondThreshold to define the threshold of seconds that the serve deployments fail. You can also set deploymentUnhealthySecondThreshold to define the threshold of seconds that Ray fails to deploy any serve deployments. Access Ray Dashboard \u00b6 Set up Kubernetes port forwarding for the dashboard. $ kubectl port-forward service/rayservice-sample-head-svc 8265 Access the dashboard using a web browser at localhost:8265 . Update Ray Serve Deployment Graph \u00b6 You can update the serveConfig in your RayService config file. For example, update the price of mangos to 4 in ray_v1alpha1_rayservice.yaml : - name: MangoStand numReplicas: 1 userConfig: | price: 4 Use kubectl apply to update your RayService and kubectl describe rayservices rayservice-sample to take a look at the RayService's information. It should look similar to: serveDeploymentStatuses: - healthLastUpdateTime: \"2022-07-18T21:51:37Z\" lastUpdateTime: \"2022-07-18T21:51:41Z\" name: MangoStand status: UPDATING After it finishes deployment, let's send a request again. In the curl pod from earlier, run: [ root@curl:/ ] $ curl -X POST -H 'Content-Type: application/json' rayservice-sample-serve-svc.default.svc.cluster.local:8000 -d '[\"MANGO\", 2]' > 8 Or if using port forwarding: curl -X POST -H 'Content-Type: application/json' localhost:8000 -d '[\"MANGO\", 2]' > 8 You should now get 8 as a result. Upgrade RayService RayCluster Config \u00b6 You can update the rayClusterConfig in your RayService config file. For example, you can increase the number of workers to 2: workerGroupSpecs: # the pod replicas in this group typed worker - replicas: 2 Use kubectl apply to update your RayService and kubectl describe rayservices rayservice-sample to take a look at the RayService's information. It should look similar to: pendingServiceStatus: appStatus: {} dashboardStatus: healthLastUpdateTime: \"2022-07-18T21:54:53Z\" lastUpdateTime: \"2022-07-18T21:54:54Z\" rayClusterName: rayservice-sample-raycluster-bshfr rayClusterStatus: {} You can see the RayService is preparing a pending cluster. Once the pending cluster is healthy, the RayService will make it the active cluster and terminate the previous one. RayService Observability \u00b6 You can use kubectl logs to check the operator logs or the head/worker nodes logs. You can also use kubectl describe rayservices rayservice-sample to check the states and event logs of your RayService instance. For Ray Serve monitoring, you can refer to the Ray observability documentation . To run Ray state APIs, log in to the head pod by running kubectl exec -it <head-node-pod> bash and use the Ray CLI or you can run commands locally using kubectl exec -it <head-node-pod> -- <ray state api> . For example, kubectl exec -it <head-node-pod> -- ray summary tasks outputs the following: ======== Tasks Summary: 2022 -07-28 15 :10:24.801670 ======== Stats: ------------------------------------ total_actor_scheduled: 17 total_actor_tasks: 5 total_tasks: 0 Table ( group by func_name ) : ------------------------------------ FUNC_OR_CLASS_NAME STATE_COUNTS TYPE 0 ServeController.listen_for_change RUNNING: 5 ACTOR_TASK 1 ServeReplica:MangoStand.__init__ FINISHED: 3 ACTOR_CREATION_TASK 2 HTTPProxyActor.__init__ FINISHED: 2 ACTOR_CREATION_TASK 3 ServeReplica:PearStand.__init__ FINISHED: 3 ACTOR_CREATION_TASK 4 ServeReplica:OrangeStand.__init__ FINISHED: 3 ACTOR_CREATION_TASK 5 ServeReplica:FruitMarket.__init__ FINISHED: 3 ACTOR_CREATION_TASK 6 ServeReplica:DAGDriver.__init__ FINISHED: 2 ACTOR_CREATION_TASK 7 ServeController.__init__ FINISHED: 1 ACTOR_CREATION_TASK Delete the RayService Instance \u00b6 $ kubectl delete -f config/samples/ray_v1alpha1_rayservice.yaml Delete the Operator \u00b6 $ kubectl delete -k \"github.com/ray-project/kuberay/ray-operator/config/default\"","title":"RayService"},{"location":"guidance/rayservice/#ray-services-alpha","text":"Note: This is the alpha version of Ray Services. There will be ongoing improvements for Ray Services in the future releases.","title":"Ray Services (alpha)"},{"location":"guidance/rayservice/#prerequisite","text":"Ray 2.0 is required.","title":"Prerequisite"},{"location":"guidance/rayservice/#what-is-a-rayservice","text":"RayService is a new custom resource (CR) supported by KubeRay in v0.3.0. A RayService manages 2 things: Ray Cluster : Manages resources in a Kubernetes cluster. Ray Serve Deployment Graph : Manages users' deployment graphs.","title":"What is a RayService?"},{"location":"guidance/rayservice/#what-does-the-rayservice-provide","text":"Kubernetes-native support for Ray clusters and Ray Serve deployment graphs. After using a Kubernetes config to define a Ray cluster and its Ray Serve deployment graphs, you can use kubectl to create the cluster and its graphs. In-place update for Ray Serve deployment graph. Users can update the Ray Serve deployment graph config in the RayService CR config and use kubectl apply to update the deployment graph. Zero downtime upgrade for Ray clusters. Users can update the Ray cluster config in the RayService CR config and use kubectl apply to update the cluster. RayService will temporarily create a pending cluster and wait for it to be ready, then switch traffic to the new cluster and terminate the old one. Services HA. RayService will monitor the Ray cluster and Serve deployments' health statuses. If RayService detects an unhealthy status for a period of time, RayService will try to create a new Ray cluster and switch traffic to the new cluster when it is ready.","title":"What does the RayService provide?"},{"location":"guidance/rayservice/#deploy-the-operator","text":"$ kubectl create -k \"github.com/ray-project/kuberay/ray-operator/config/default?ref=v0.3.0&timeout=90s\" Check that the controller is running. $ kubectl get deployments -n ray-system NAME READY UP-TO-DATE AVAILABLE AGE ray-operator 1 /1 1 1 40s $ kubectl get pods -n ray-system NAME READY STATUS RESTARTS AGE ray-operator-75dbbf8587-5lrvn 1 /1 Running 0 31s","title":"Deploy the Operator"},{"location":"guidance/rayservice/#run-an-example-cluster","text":"An example config file to deploy RayService is included here: ray_v1alpha1_rayservice.yaml # Create a ray service and deploy fruit deployment graph. $ kubectl apply -f config/samples/ray_v1alpha1_rayservice.yaml # List running RayServices. $ kubectl get rayservice NAME AGE rayservice-sample 7s # The created RayService should include a head pod, a worker pod, and four services. $ kubectl get pods NAME READY STATUS RESTARTS AGE ervice-sample-raycluster-qd2vl-worker-small-group-bxpp6 1 /1 Running 0 24m rayservice-sample-raycluster-qd2vl-head-45hj4 1 /1 Running 0 24m $ kubectl get services NAME TYPE CLUSTER-IP EXTERNAL-IP PORT ( S ) AGE kubernetes ClusterIP 10 .100.0.1 <none> 443 /TCP 62d # A head node service maintained by the RayService. rayservice-sample-head-svc ClusterIP 10 .100.34.24 <none> 6379 /TCP,8265/TCP,10001/TCP,8000/TCP,52365/TCP 24m # A dashboard agent service maintained by the RayCluster. rayservice-sample-raycluster-qd2vl-dashboard-svc ClusterIP 10 .100.109.177 <none> 52365 /TCP 24m # A head node service maintained by the RayCluster. rayservice-sample-raycluster-qd2vl-head-svc ClusterIP 10 .100.180.221 <none> 6379 /TCP,8265/TCP,10001/TCP,8000/TCP,52365/TCP 24m # A serve service maintained by the RayService. rayservice-sample-serve-svc ClusterIP 10 .100.39.92 <none> 8000 /TCP 24m Note: Default ports and their definitions. Port Definition 6379 Ray GCS 8265 Ray Dashboard 10001 Ray Client 8000 Ray Serve 52365 Ray Dashboard Agent Get information about the RayService using its name. $ kubectl describe rayservices rayservice-sample","title":"Run an Example Cluster"},{"location":"guidance/rayservice/#access-user-services","text":"The users' traffic can go through the serve service (e.g. rayservice-sample-serve-svc ).","title":"Access User Services"},{"location":"guidance/rayservice/#run-a-curl-pod","text":"$ kubectl run curl --image = radial/busyboxplus:curl -i --tty Or if you already have a curl pod running, you can login using kubectl exec -it curl sh . For the fruit example deployment, you can try the following request: [ root@curl:/ ] $ curl -X POST -H 'Content-Type: application/json' rayservice-sample-serve-svc.default.svc.cluster.local:8000 -d '[\"MANGO\", 2]' > 6 You should get the response 6 .","title":"Run a Curl Pod"},{"location":"guidance/rayservice/#use-port-forwarding","text":"Set up Kubernetes port forwarding. $ kubectl port-forward service/rayservice-sample-serve-svc 8000 For the fruit example deployment, you can try the following request: [ root@curl:/ ] $ curl -X POST -H 'Content-Type: application/json' localhost:8000 -d '[\"MANGO\", 2]' > 6 Note: serve-svc is HA in general. It will do traffic routing among all the workers which have serve deployments and will always try to point to the healthy cluster, even during upgrading or failing cases. You can set serviceUnhealthySecondThreshold to define the threshold of seconds that the serve deployments fail. You can also set deploymentUnhealthySecondThreshold to define the threshold of seconds that Ray fails to deploy any serve deployments.","title":"Use Port Forwarding"},{"location":"guidance/rayservice/#access-ray-dashboard","text":"Set up Kubernetes port forwarding for the dashboard. $ kubectl port-forward service/rayservice-sample-head-svc 8265 Access the dashboard using a web browser at localhost:8265 .","title":"Access Ray Dashboard"},{"location":"guidance/rayservice/#update-ray-serve-deployment-graph","text":"You can update the serveConfig in your RayService config file. For example, update the price of mangos to 4 in ray_v1alpha1_rayservice.yaml : - name: MangoStand numReplicas: 1 userConfig: | price: 4 Use kubectl apply to update your RayService and kubectl describe rayservices rayservice-sample to take a look at the RayService's information. It should look similar to: serveDeploymentStatuses: - healthLastUpdateTime: \"2022-07-18T21:51:37Z\" lastUpdateTime: \"2022-07-18T21:51:41Z\" name: MangoStand status: UPDATING After it finishes deployment, let's send a request again. In the curl pod from earlier, run: [ root@curl:/ ] $ curl -X POST -H 'Content-Type: application/json' rayservice-sample-serve-svc.default.svc.cluster.local:8000 -d '[\"MANGO\", 2]' > 8 Or if using port forwarding: curl -X POST -H 'Content-Type: application/json' localhost:8000 -d '[\"MANGO\", 2]' > 8 You should now get 8 as a result.","title":"Update Ray Serve Deployment Graph"},{"location":"guidance/rayservice/#upgrade-rayservice-raycluster-config","text":"You can update the rayClusterConfig in your RayService config file. For example, you can increase the number of workers to 2: workerGroupSpecs: # the pod replicas in this group typed worker - replicas: 2 Use kubectl apply to update your RayService and kubectl describe rayservices rayservice-sample to take a look at the RayService's information. It should look similar to: pendingServiceStatus: appStatus: {} dashboardStatus: healthLastUpdateTime: \"2022-07-18T21:54:53Z\" lastUpdateTime: \"2022-07-18T21:54:54Z\" rayClusterName: rayservice-sample-raycluster-bshfr rayClusterStatus: {} You can see the RayService is preparing a pending cluster. Once the pending cluster is healthy, the RayService will make it the active cluster and terminate the previous one.","title":"Upgrade RayService RayCluster Config"},{"location":"guidance/rayservice/#rayservice-observability","text":"You can use kubectl logs to check the operator logs or the head/worker nodes logs. You can also use kubectl describe rayservices rayservice-sample to check the states and event logs of your RayService instance. For Ray Serve monitoring, you can refer to the Ray observability documentation . To run Ray state APIs, log in to the head pod by running kubectl exec -it <head-node-pod> bash and use the Ray CLI or you can run commands locally using kubectl exec -it <head-node-pod> -- <ray state api> . For example, kubectl exec -it <head-node-pod> -- ray summary tasks outputs the following: ======== Tasks Summary: 2022 -07-28 15 :10:24.801670 ======== Stats: ------------------------------------ total_actor_scheduled: 17 total_actor_tasks: 5 total_tasks: 0 Table ( group by func_name ) : ------------------------------------ FUNC_OR_CLASS_NAME STATE_COUNTS TYPE 0 ServeController.listen_for_change RUNNING: 5 ACTOR_TASK 1 ServeReplica:MangoStand.__init__ FINISHED: 3 ACTOR_CREATION_TASK 2 HTTPProxyActor.__init__ FINISHED: 2 ACTOR_CREATION_TASK 3 ServeReplica:PearStand.__init__ FINISHED: 3 ACTOR_CREATION_TASK 4 ServeReplica:OrangeStand.__init__ FINISHED: 3 ACTOR_CREATION_TASK 5 ServeReplica:FruitMarket.__init__ FINISHED: 3 ACTOR_CREATION_TASK 6 ServeReplica:DAGDriver.__init__ FINISHED: 2 ACTOR_CREATION_TASK 7 ServeController.__init__ FINISHED: 1 ACTOR_CREATION_TASK","title":"RayService Observability"},{"location":"guidance/rayservice/#delete-the-rayservice-instance","text":"$ kubectl delete -f config/samples/ray_v1alpha1_rayservice.yaml","title":"Delete the RayService Instance"},{"location":"guidance/rayservice/#delete-the-operator","text":"$ kubectl delete -k \"github.com/ray-project/kuberay/ray-operator/config/default\"","title":"Delete the Operator"},{"location":"guidance/volcano-integration/","text":"KubeRay integration with Volcano \u00b6 Volcano is a batch scheduling system built on Kubernetes. It provides a suite of mechanisms (gang scheduling, job queues, fair scheduling policies) currently missing from Kubernetes that are commonly required by many classes of batch and elastic workloads. KubeRay's Volcano integration enables more efficient scheduling of Ray pods in multi-tenant Kubernetes environments. Note that this is a new feature. Feedback and contributions welcome. Setup \u00b6 Install Volcano \u00b6 Volcano needs to be successfully installed in your Kubernetes cluster before enabling Volcano integration with KubeRay. Refer to the Quick Start Guide for Volcano installation instructions. Install KubeRay Operator with Batch Scheduling \u00b6 Deploy the KubeRay Operator with the --enable-batch-scheduler flag to enable Volcano batch scheduling support. When installing via Helm, you can set the following in your values.yaml file: batchScheduler: enabled: true Or on the command line: # helm install kuberay-operator --set batchScheduler.enabled=true Run Ray Cluster with Volcano scheduler \u00b6 Add the ray.io/scheduler-name: volcano label to your RayCluster CR to submit the cluster pods to Volcano for scheduling. Example: apiVersion: ray.io/v1alpha1 kind: RayCluster metadata: name: test-cluster labels: ray.io/scheduler-name: volcano volcano.sh/queue-name: kuberay-test-queue spec: rayVersion: '2.1.0' headGroupSpec: serviceType: ClusterIP rayStartParams: block: 'true' replicas: 1 template: spec: containers: - name: ray-head image: rayproject/ray:2.1.0 resources: limits: cpu: \"1\" memory: \"2Gi\" requests: cpu: \"1\" memory: \"2Gi\" workerGroupSpecs: [] The following labels can also be provided in the RayCluster metadata: ray.io/priority-class-name : the cluster priority class as defined by Kubernetes here . volcano.sh/queue-name : the Volcano queue name the cluster will be submitted to. If autoscaling is enabled, minReplicas will be used for gang scheduling, otherwise the desired replicas will be used. Example: Gang scheduling \u00b6 In this example, we'll walk through how gang scheduling works with Volcano and KubeRay. First, let's create a queue with a capacity of 4 CPUs and 6Gi of RAM: $ kubectl create -f - <<EOF apiVersion: scheduling.volcano.sh/v1beta1 kind: Queue metadata: name: kuberay-test-queue spec: weight: 1 capability: cpu: 4 memory: 6Gi EOF The weight in the definition above indicates the relative weight of a queue in cluster resource division. This is useful in cases where the total capability of all the queues in your cluster exceeds the total available resources, forcing the queues to share among themselves. Queues with higher weight will be allocated a proportionally larger share of the total resources. The capability is a hard constraint on the maximum resources the queue will support at any given time. It can be updated as needed to allow more or fewer workloads to run at a time. Next we'll create a RayCluster with a head node (1 CPU + 2Gi of RAM) and two workers (1 CPU + 1Gi of RAM each), for a total of 3 CPU and 4Gi of RAM: $ kubectl create -f - <<EOF apiVersion: ray.io/v1alpha1 kind: RayCluster metadata: name: test-cluster-0 labels: ray.io/scheduler-name: volcano volcano.sh/queue-name: kuberay-test-queue spec: rayVersion: '2.1.0' headGroupSpec: serviceType: ClusterIP rayStartParams: block: 'true' replicas: 1 template: spec: containers: - name: ray-head image: rayproject/ray:2.1.0 resources: limits: cpu: \"1\" memory: \"2Gi\" requests: cpu: \"1\" memory: \"2Gi\" workerGroupSpecs: - groupName: worker rayStartParams: block: 'true' replicas: 2 minReplicas: 2 maxReplicas: 2 template: spec: containers: - name: ray-head image: rayproject/ray:2.1.0 resources: limits: cpu: \"1\" memory: \"1Gi\" requests: cpu: \"1\" memory: \"1Gi\" EOF Because our queue has a capacity of 4 CPU and 6Gi of RAM, this resource should schedule successfully without any issues. We can verify this by checking the status of our cluster's Volcano PodGroup to see that the phase is Running and the last status is Scheduled : $ kubectl get podgroup ray-test-cluster-0-pg -o yaml apiVersion: scheduling.volcano.sh/v1beta1 kind: PodGroup metadata: creationTimestamp: \"2022-12-01T04:43:30Z\" generation: 2 name: ray-test-cluster-0-pg namespace: test ownerReferences: - apiVersion: ray.io/v1alpha1 blockOwnerDeletion: true controller: true kind: RayCluster name: test-cluster-0 uid: 7979b169-f0b0-42b7-8031-daef522d25cf resourceVersion: \"4427347\" uid: 78902d3d-b490-47eb-ba12-d6f8b721a579 spec: minMember: 3 minResources: cpu: \"3\" memory: 4Gi queue: kuberay-test-queue status: conditions: - lastTransitionTime: \"2022-12-01T04:43:31Z\" reason: tasks in gang are ready to be scheduled status: \"True\" transitionID: f89f3062-ebd7-486b-8763-18ccdba1d585 type: Scheduled phase: Running And checking the status of our queue to see that we have 1 running job: $ kubectl get queue kuberay-test-queue -o yaml apiVersion: scheduling.volcano.sh/v1beta1 kind: Queue metadata: creationTimestamp: \"2022-12-01T04:43:21Z\" generation: 1 name: kuberay-test-queue resourceVersion: \"4427348\" uid: a6c4f9df-d58c-4da8-8a58-e01c93eca45a spec: capability: cpu: 4 memory: 6Gi reclaimable: true weight: 1 status: reservation: {} running: 1 state: Open Next we'll add an additional RayCluster with the same configuration of head / worker nodes, but a different name: $ kubectl create -f - <<EOF apiVersion: ray.io/v1alpha1 kind: RayCluster metadata: name: test-cluster-1 labels: ray.io/scheduler-name: volcano volcano.sh/queue-name: kuberay-test-queue spec: rayVersion: '2.1.0' headGroupSpec: serviceType: ClusterIP rayStartParams: block: 'true' replicas: 1 template: spec: containers: - name: ray-head image: rayproject/ray:2.1.0 resources: limits: cpu: \"1\" memory: \"2Gi\" requests: cpu: \"1\" memory: \"2Gi\" workerGroupSpecs: - groupName: worker rayStartParams: block: 'true' replicas: 2 minReplicas: 2 maxReplicas: 2 template: spec: containers: - name: ray-head image: rayproject/ray:2.1.0 resources: limits: cpu: \"1\" memory: \"1Gi\" requests: cpu: \"1\" memory: \"1Gi\" EOF Now check the status of its PodGroup to see that its phase is Pending and the last status is Unschedulable : $ kubectl get podgroup ray-test-cluster-1-pg -o yaml apiVersion: scheduling.volcano.sh/v1beta1 kind: PodGroup metadata: creationTimestamp: \"2022-12-01T04:48:18Z\" generation: 2 name: ray-test-cluster-1-pg namespace: test ownerReferences: - apiVersion: ray.io/v1alpha1 blockOwnerDeletion: true controller: true kind: RayCluster name: test-cluster-1 uid: b3cf83dc-ef3a-4bb1-9c42-7d2a39c53358 resourceVersion: \"4427976\" uid: 9087dd08-8f48-4592-a62e-21e9345b0872 spec: minMember: 3 minResources: cpu: \"3\" memory: 4Gi queue: kuberay-test-queue status: conditions: - lastTransitionTime: \"2022-12-01T04:48:19Z\" message: '3/3 tasks in gang unschedulable: pod group is not ready, 3 Pending, 3 minAvailable; Pending: 3 Undetermined' reason: NotEnoughResources status: \"True\" transitionID: 3956b64f-fc52-4779-831e-d379648eecfc type: Unschedulable phase: Pending Because our new cluster requires more CPU and RAM than our queue will allow, even though we could fit one of the pods with the remaining 1 CPU and 2Gi of RAM, none of the cluster's pods will be placed until there is enough room for all the pods. Without using Volcano for gang scheduling in this way, one of the pods would ordinarily be placed, leading to the cluster being partially allocated, and some jobs (like Horovod training) getting stuck waiting for resources to become available. We can see the effect this has on scheduling the pods for our new RayCluster, which are listed as Pending : $ kubectl get pods NAME READY STATUS RESTARTS AGE test-cluster-0-worker-worker-ddfbz 1/1 Running 0 7m test-cluster-0-head-vst5j 1/1 Running 0 7m test-cluster-0-worker-worker-57pc7 1/1 Running 0 6m59s test-cluster-1-worker-worker-6tzf7 0/1 Pending 0 2m12s test-cluster-1-head-6668q 0/1 Pending 0 2m12s test-cluster-1-worker-worker-n5g8k 0/1 Pending 0 2m12s If we dig into the pod details, we'll see that this is indeed because Volcano cannot schedule the gang: $ kubectl describe pod test-cluster-1-head-6668q | tail -n 3 Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedScheduling 4m5s volcano 3/3 tasks in gang unschedulable: pod group is not ready, 3 Pending, 3 minAvailable; Pending: 3 Undetermined Let's go ahead and delete the first RayCluster to clear up space in the queue: $ kubectl delete raycluster test-cluster-0 The PodGroup for the second cluster has moved to the Running state, as there are now enough resources available to schedule the entire set of pods: $ kubectl get podgroup ray-test-cluster-1-pg -o yaml apiVersion: scheduling.volcano.sh/v1beta1 kind: PodGroup metadata: creationTimestamp: \"2022-12-01T04:48:18Z\" generation: 9 name: ray-test-cluster-1-pg namespace: test ownerReferences: - apiVersion: ray.io/v1alpha1 blockOwnerDeletion: true controller: true kind: RayCluster name: test-cluster-1 uid: b3cf83dc-ef3a-4bb1-9c42-7d2a39c53358 resourceVersion: \"4428864\" uid: 9087dd08-8f48-4592-a62e-21e9345b0872 spec: minMember: 3 minResources: cpu: \"3\" memory: 4Gi queue: kuberay-test-queue status: conditions: - lastTransitionTime: \"2022-12-01T04:54:04Z\" message: '3/3 tasks in gang unschedulable: pod group is not ready, 3 Pending, 3 minAvailable; Pending: 3 Undetermined' reason: NotEnoughResources status: \"True\" transitionID: db90bbf0-6845-441b-8992-d0e85f78db77 type: Unschedulable - lastTransitionTime: \"2022-12-01T04:55:10Z\" reason: tasks in gang are ready to be scheduled status: \"True\" transitionID: 72bbf1b3-d501-4528-a59d-479504f3eaf5 type: Scheduled phase: Running running: 2 Checking the pods again, we see that the second cluster is now up and running: $ kubectl get pods NAME READY STATUS RESTARTS AGE test-cluster-1-worker-worker-n5g8k 1/1 Running 0 9m4s test-cluster-1-head-6668q 1/1 Running 0 9m4s test-cluster-1-worker-worker-6tzf7 1/1 Running 0 9m4s Finally, we'll cleanup the remaining cluster and queue: $ kubectl delete raycluster test-cluster-1 $ kubectl delete queue kuberay-test-queue Questions \u00b6 Reach out to @tgaddair for questions regarding usage of this integration.","title":"KubeRay with Volcano"},{"location":"guidance/volcano-integration/#kuberay-integration-with-volcano","text":"Volcano is a batch scheduling system built on Kubernetes. It provides a suite of mechanisms (gang scheduling, job queues, fair scheduling policies) currently missing from Kubernetes that are commonly required by many classes of batch and elastic workloads. KubeRay's Volcano integration enables more efficient scheduling of Ray pods in multi-tenant Kubernetes environments. Note that this is a new feature. Feedback and contributions welcome.","title":"KubeRay integration with Volcano"},{"location":"guidance/volcano-integration/#setup","text":"","title":"Setup"},{"location":"guidance/volcano-integration/#install-volcano","text":"Volcano needs to be successfully installed in your Kubernetes cluster before enabling Volcano integration with KubeRay. Refer to the Quick Start Guide for Volcano installation instructions.","title":"Install Volcano"},{"location":"guidance/volcano-integration/#install-kuberay-operator-with-batch-scheduling","text":"Deploy the KubeRay Operator with the --enable-batch-scheduler flag to enable Volcano batch scheduling support. When installing via Helm, you can set the following in your values.yaml file: batchScheduler: enabled: true Or on the command line: # helm install kuberay-operator --set batchScheduler.enabled=true","title":"Install KubeRay Operator with Batch Scheduling"},{"location":"guidance/volcano-integration/#run-ray-cluster-with-volcano-scheduler","text":"Add the ray.io/scheduler-name: volcano label to your RayCluster CR to submit the cluster pods to Volcano for scheduling. Example: apiVersion: ray.io/v1alpha1 kind: RayCluster metadata: name: test-cluster labels: ray.io/scheduler-name: volcano volcano.sh/queue-name: kuberay-test-queue spec: rayVersion: '2.1.0' headGroupSpec: serviceType: ClusterIP rayStartParams: block: 'true' replicas: 1 template: spec: containers: - name: ray-head image: rayproject/ray:2.1.0 resources: limits: cpu: \"1\" memory: \"2Gi\" requests: cpu: \"1\" memory: \"2Gi\" workerGroupSpecs: [] The following labels can also be provided in the RayCluster metadata: ray.io/priority-class-name : the cluster priority class as defined by Kubernetes here . volcano.sh/queue-name : the Volcano queue name the cluster will be submitted to. If autoscaling is enabled, minReplicas will be used for gang scheduling, otherwise the desired replicas will be used.","title":"Run Ray Cluster with Volcano scheduler"},{"location":"guidance/volcano-integration/#example-gang-scheduling","text":"In this example, we'll walk through how gang scheduling works with Volcano and KubeRay. First, let's create a queue with a capacity of 4 CPUs and 6Gi of RAM: $ kubectl create -f - <<EOF apiVersion: scheduling.volcano.sh/v1beta1 kind: Queue metadata: name: kuberay-test-queue spec: weight: 1 capability: cpu: 4 memory: 6Gi EOF The weight in the definition above indicates the relative weight of a queue in cluster resource division. This is useful in cases where the total capability of all the queues in your cluster exceeds the total available resources, forcing the queues to share among themselves. Queues with higher weight will be allocated a proportionally larger share of the total resources. The capability is a hard constraint on the maximum resources the queue will support at any given time. It can be updated as needed to allow more or fewer workloads to run at a time. Next we'll create a RayCluster with a head node (1 CPU + 2Gi of RAM) and two workers (1 CPU + 1Gi of RAM each), for a total of 3 CPU and 4Gi of RAM: $ kubectl create -f - <<EOF apiVersion: ray.io/v1alpha1 kind: RayCluster metadata: name: test-cluster-0 labels: ray.io/scheduler-name: volcano volcano.sh/queue-name: kuberay-test-queue spec: rayVersion: '2.1.0' headGroupSpec: serviceType: ClusterIP rayStartParams: block: 'true' replicas: 1 template: spec: containers: - name: ray-head image: rayproject/ray:2.1.0 resources: limits: cpu: \"1\" memory: \"2Gi\" requests: cpu: \"1\" memory: \"2Gi\" workerGroupSpecs: - groupName: worker rayStartParams: block: 'true' replicas: 2 minReplicas: 2 maxReplicas: 2 template: spec: containers: - name: ray-head image: rayproject/ray:2.1.0 resources: limits: cpu: \"1\" memory: \"1Gi\" requests: cpu: \"1\" memory: \"1Gi\" EOF Because our queue has a capacity of 4 CPU and 6Gi of RAM, this resource should schedule successfully without any issues. We can verify this by checking the status of our cluster's Volcano PodGroup to see that the phase is Running and the last status is Scheduled : $ kubectl get podgroup ray-test-cluster-0-pg -o yaml apiVersion: scheduling.volcano.sh/v1beta1 kind: PodGroup metadata: creationTimestamp: \"2022-12-01T04:43:30Z\" generation: 2 name: ray-test-cluster-0-pg namespace: test ownerReferences: - apiVersion: ray.io/v1alpha1 blockOwnerDeletion: true controller: true kind: RayCluster name: test-cluster-0 uid: 7979b169-f0b0-42b7-8031-daef522d25cf resourceVersion: \"4427347\" uid: 78902d3d-b490-47eb-ba12-d6f8b721a579 spec: minMember: 3 minResources: cpu: \"3\" memory: 4Gi queue: kuberay-test-queue status: conditions: - lastTransitionTime: \"2022-12-01T04:43:31Z\" reason: tasks in gang are ready to be scheduled status: \"True\" transitionID: f89f3062-ebd7-486b-8763-18ccdba1d585 type: Scheduled phase: Running And checking the status of our queue to see that we have 1 running job: $ kubectl get queue kuberay-test-queue -o yaml apiVersion: scheduling.volcano.sh/v1beta1 kind: Queue metadata: creationTimestamp: \"2022-12-01T04:43:21Z\" generation: 1 name: kuberay-test-queue resourceVersion: \"4427348\" uid: a6c4f9df-d58c-4da8-8a58-e01c93eca45a spec: capability: cpu: 4 memory: 6Gi reclaimable: true weight: 1 status: reservation: {} running: 1 state: Open Next we'll add an additional RayCluster with the same configuration of head / worker nodes, but a different name: $ kubectl create -f - <<EOF apiVersion: ray.io/v1alpha1 kind: RayCluster metadata: name: test-cluster-1 labels: ray.io/scheduler-name: volcano volcano.sh/queue-name: kuberay-test-queue spec: rayVersion: '2.1.0' headGroupSpec: serviceType: ClusterIP rayStartParams: block: 'true' replicas: 1 template: spec: containers: - name: ray-head image: rayproject/ray:2.1.0 resources: limits: cpu: \"1\" memory: \"2Gi\" requests: cpu: \"1\" memory: \"2Gi\" workerGroupSpecs: - groupName: worker rayStartParams: block: 'true' replicas: 2 minReplicas: 2 maxReplicas: 2 template: spec: containers: - name: ray-head image: rayproject/ray:2.1.0 resources: limits: cpu: \"1\" memory: \"1Gi\" requests: cpu: \"1\" memory: \"1Gi\" EOF Now check the status of its PodGroup to see that its phase is Pending and the last status is Unschedulable : $ kubectl get podgroup ray-test-cluster-1-pg -o yaml apiVersion: scheduling.volcano.sh/v1beta1 kind: PodGroup metadata: creationTimestamp: \"2022-12-01T04:48:18Z\" generation: 2 name: ray-test-cluster-1-pg namespace: test ownerReferences: - apiVersion: ray.io/v1alpha1 blockOwnerDeletion: true controller: true kind: RayCluster name: test-cluster-1 uid: b3cf83dc-ef3a-4bb1-9c42-7d2a39c53358 resourceVersion: \"4427976\" uid: 9087dd08-8f48-4592-a62e-21e9345b0872 spec: minMember: 3 minResources: cpu: \"3\" memory: 4Gi queue: kuberay-test-queue status: conditions: - lastTransitionTime: \"2022-12-01T04:48:19Z\" message: '3/3 tasks in gang unschedulable: pod group is not ready, 3 Pending, 3 minAvailable; Pending: 3 Undetermined' reason: NotEnoughResources status: \"True\" transitionID: 3956b64f-fc52-4779-831e-d379648eecfc type: Unschedulable phase: Pending Because our new cluster requires more CPU and RAM than our queue will allow, even though we could fit one of the pods with the remaining 1 CPU and 2Gi of RAM, none of the cluster's pods will be placed until there is enough room for all the pods. Without using Volcano for gang scheduling in this way, one of the pods would ordinarily be placed, leading to the cluster being partially allocated, and some jobs (like Horovod training) getting stuck waiting for resources to become available. We can see the effect this has on scheduling the pods for our new RayCluster, which are listed as Pending : $ kubectl get pods NAME READY STATUS RESTARTS AGE test-cluster-0-worker-worker-ddfbz 1/1 Running 0 7m test-cluster-0-head-vst5j 1/1 Running 0 7m test-cluster-0-worker-worker-57pc7 1/1 Running 0 6m59s test-cluster-1-worker-worker-6tzf7 0/1 Pending 0 2m12s test-cluster-1-head-6668q 0/1 Pending 0 2m12s test-cluster-1-worker-worker-n5g8k 0/1 Pending 0 2m12s If we dig into the pod details, we'll see that this is indeed because Volcano cannot schedule the gang: $ kubectl describe pod test-cluster-1-head-6668q | tail -n 3 Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedScheduling 4m5s volcano 3/3 tasks in gang unschedulable: pod group is not ready, 3 Pending, 3 minAvailable; Pending: 3 Undetermined Let's go ahead and delete the first RayCluster to clear up space in the queue: $ kubectl delete raycluster test-cluster-0 The PodGroup for the second cluster has moved to the Running state, as there are now enough resources available to schedule the entire set of pods: $ kubectl get podgroup ray-test-cluster-1-pg -o yaml apiVersion: scheduling.volcano.sh/v1beta1 kind: PodGroup metadata: creationTimestamp: \"2022-12-01T04:48:18Z\" generation: 9 name: ray-test-cluster-1-pg namespace: test ownerReferences: - apiVersion: ray.io/v1alpha1 blockOwnerDeletion: true controller: true kind: RayCluster name: test-cluster-1 uid: b3cf83dc-ef3a-4bb1-9c42-7d2a39c53358 resourceVersion: \"4428864\" uid: 9087dd08-8f48-4592-a62e-21e9345b0872 spec: minMember: 3 minResources: cpu: \"3\" memory: 4Gi queue: kuberay-test-queue status: conditions: - lastTransitionTime: \"2022-12-01T04:54:04Z\" message: '3/3 tasks in gang unschedulable: pod group is not ready, 3 Pending, 3 minAvailable; Pending: 3 Undetermined' reason: NotEnoughResources status: \"True\" transitionID: db90bbf0-6845-441b-8992-d0e85f78db77 type: Unschedulable - lastTransitionTime: \"2022-12-01T04:55:10Z\" reason: tasks in gang are ready to be scheduled status: \"True\" transitionID: 72bbf1b3-d501-4528-a59d-479504f3eaf5 type: Scheduled phase: Running running: 2 Checking the pods again, we see that the second cluster is now up and running: $ kubectl get pods NAME READY STATUS RESTARTS AGE test-cluster-1-worker-worker-n5g8k 1/1 Running 0 9m4s test-cluster-1-head-6668q 1/1 Running 0 9m4s test-cluster-1-worker-worker-6tzf7 1/1 Running 0 9m4s Finally, we'll cleanup the remaining cluster and queue: $ kubectl delete raycluster test-cluster-1 $ kubectl delete queue kuberay-test-queue","title":"Example: Gang scheduling"},{"location":"guidance/volcano-integration/#questions","text":"Reach out to @tgaddair for questions regarding usage of this integration.","title":"Questions"},{"location":"release/helm-chart/","text":"Helm charts release \u00b6 We host all Helm charts on kuberay-helm . This document describes the process for release managers to release Helm charts. The end-to-end workflow \u00b6 Step 1: Update version in Chart.yaml \u00b6 Please update the value of version in ray-cluster/Chart.yaml , kuberay-operator/Chart.yaml , and kuberay-apiserver/Chart.yaml to the new release version (e.g. 0.4.0). Step 2: Copy the helm-chart directory from kuberay to kuberay-helm \u00b6 In kuberay-helm CI , helm/chart-releaser-action will create releases for all charts in the directory helm-chart and update index.yaml in the gh-pages branch when the PR is merged into main . Note that index.yaml is necessary when you run the command helm repo add . I recommend removing the helm-chart directory in the kuberay-helm repository and creating a new one by copying from the kuberay repository. Step 3: Check the correctness \u00b6 When the PR is merged into main , the releases and index.yaml will be generated. You can check the correctness by: Check whether the releases are created as expectation. Check whether index.yaml exists or not. Check whether index.yaml has metadata of all releases, including old versions. Check the creation/update time of all releases and index.yaml to ensure they are updated. Install charts from Helm repository. helm repo add kuberay https://ray-project.github.io/kuberay-helm/ # List all charts helm search repo kuberay # Install charts helm install kuberay-operator kuberay/kuberay-operator helm install kuberay-apiserver kuberay/kuberay-apiserver helm install ray-cluster kuberay/ray-cluster Delete the existing releases \u00b6 helm/chart-releaser-action does not encourage users to delete existing releases; thus, index.yaml will not be updated automatically after the deletion. If you really need to do that, please read this section carefully before you do that. Delete the releases Remove the related tags by the following command. If tags are not properly removed, ray-project/kuberay/#561 may occur. # git remote -v # upstream git@github.com:ray-project/kuberay-helm.git (fetch) # upstream git@github.com:ray-project/kuberay-helm.git (push) # The following command deletes the tag \"ray-cluster-0.4.0\". git push --delete upstream ray-cluster-0.4.0 * Remove index.yaml * Trigger kuberay-helm CI again to create new releases and new index.yaml. * Follow \"Step3: Check the correctness\" to test it.","title":"Helm charts release"},{"location":"release/helm-chart/#helm-charts-release","text":"We host all Helm charts on kuberay-helm . This document describes the process for release managers to release Helm charts.","title":"Helm charts release"},{"location":"release/helm-chart/#the-end-to-end-workflow","text":"","title":"The end-to-end workflow"},{"location":"release/helm-chart/#step-1-update-version-in-chartyaml","text":"Please update the value of version in ray-cluster/Chart.yaml , kuberay-operator/Chart.yaml , and kuberay-apiserver/Chart.yaml to the new release version (e.g. 0.4.0).","title":"Step 1: Update version in Chart.yaml"},{"location":"release/helm-chart/#step-2-copy-the-helm-chart-directory-from-kuberay-to-kuberay-helm","text":"In kuberay-helm CI , helm/chart-releaser-action will create releases for all charts in the directory helm-chart and update index.yaml in the gh-pages branch when the PR is merged into main . Note that index.yaml is necessary when you run the command helm repo add . I recommend removing the helm-chart directory in the kuberay-helm repository and creating a new one by copying from the kuberay repository.","title":"Step 2: Copy the helm-chart directory from kuberay to kuberay-helm"},{"location":"release/helm-chart/#step-3-check-the-correctness","text":"When the PR is merged into main , the releases and index.yaml will be generated. You can check the correctness by: Check whether the releases are created as expectation. Check whether index.yaml exists or not. Check whether index.yaml has metadata of all releases, including old versions. Check the creation/update time of all releases and index.yaml to ensure they are updated. Install charts from Helm repository. helm repo add kuberay https://ray-project.github.io/kuberay-helm/ # List all charts helm search repo kuberay # Install charts helm install kuberay-operator kuberay/kuberay-operator helm install kuberay-apiserver kuberay/kuberay-apiserver helm install ray-cluster kuberay/ray-cluster","title":"Step 3: Check the correctness"},{"location":"release/helm-chart/#delete-the-existing-releases","text":"helm/chart-releaser-action does not encourage users to delete existing releases; thus, index.yaml will not be updated automatically after the deletion. If you really need to do that, please read this section carefully before you do that. Delete the releases Remove the related tags by the following command. If tags are not properly removed, ray-project/kuberay/#561 may occur. # git remote -v # upstream git@github.com:ray-project/kuberay-helm.git (fetch) # upstream git@github.com:ray-project/kuberay-helm.git (push) # The following command deletes the tag \"ray-cluster-0.4.0\". git push --delete upstream ray-cluster-0.4.0 * Remove index.yaml * Trigger kuberay-helm CI again to create new releases and new index.yaml. * Follow \"Step3: Check the correctness\" to test it.","title":"Delete the existing releases"}]}